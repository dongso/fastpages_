{
  
    
        "post0": {
            "title": "How to classify Lego figures",
            "content": "What better way to improve your significant other? . Build a Lego Classifier with fastai . !pip install kaggle . We want to save the dataset into the folder /notebooks/storage/data/Lego-Classification: . !kaggle datasets download -d ihelon/lego-minifigures-classification -p /notebooks/storage/data/Lego-Classification . Unzip data using Pythons pathlib library . from pathlib import Path p = Path(&#39;/notebooks/storage/data/Lego-Classification&#39;) filename = Path(&#39;/notebooks/storage/data/Lego-Classification/lego-minifigures-classification.zip&#39;) . Just as before, we can use bash commands from within Jupyter Notebook. So let&#39;s do that to unzip our data. -q is quiet mode, -d points to the direction where to unzip the data. Just see how well Pythons pathlib and bash work together! . !unzip -q {str(filename)} -d {str(p/&quot;train&quot;)} . Imports . from fastbook import * from fastai.vision.widgets import * import pandas as pd . Let&#39;s now use fastai&#39;s &quot;get_image_files()&quot; function to see how the unzipped data looks like in our destination path: . fns = get_image_files(p/&quot;train&quot;) fns . (#316) [Path(&#39;/notebooks/storage/data/Lego-Classification/train/jurassic-world/0002/009.jpg&#39;),Path(&#39;/notebooks/storage/data/Lego-Classification/train/jurassic-world/0002/010.jpg&#39;),Path(&#39;/notebooks/storage/data/Lego-Classification/train/jurassic-world/0002/006.jpg&#39;),Path(&#39;/notebooks/storage/data/Lego-Classification/train/jurassic-world/0002/001.jpg&#39;),Path(&#39;/notebooks/storage/data/Lego-Classification/train/jurassic-world/0002/011.jpg&#39;),Path(&#39;/notebooks/storage/data/Lego-Classification/train/jurassic-world/0002/005.jpg&#39;),Path(&#39;/notebooks/storage/data/Lego-Classification/train/jurassic-world/0002/004.jpg&#39;),Path(&#39;/notebooks/storage/data/Lego-Classification/train/jurassic-world/0002/013.jpg&#39;),Path(&#39;/notebooks/storage/data/Lego-Classification/train/jurassic-world/0002/007.jpg&#39;),Path(&#39;/notebooks/storage/data/Lego-Classification/train/jurassic-world/0002/008.jpg&#39;)...] . Remember, we put the data into our directory &#39;/notebooks/storage/data/Lego-Classification&#39;. After having a quick look at our data it looks like the data is stored as follows: first the genre of our image (marvel/jurassic-world), then the classification of the figure (0001/0002 etc.). Within these folders we find many different pictures of that figure (001.jpg/002.jpg and so on). Let&#39;s confirm this by looking at the metadata. . df = pd.read_csv(f&#39;{p}/index.csv&#39;, index_col=0) df.tail(5) . path class_id train-valid . 311 marvel/0014/008.jpg | 28 | valid | . 312 marvel/0014/009.jpg | 28 | valid | . 313 marvel/0014/010.jpg | 28 | valid | . 314 marvel/0014/011.jpg | 28 | valid | . 315 marvel/0014/012.jpg | 28 | valid | . df_metadata = pd.read_csv(f&#39;{p}/metadata.csv&#39;, usecols=[&#39;class_id&#39;, &#39;lego_names&#39;, &#39;minifigure_name&#39;]) df_metadata.head() . class_id lego_names minifigure_name . 0 1 | [&#39;Spider Mech vs. Venom&#39;] | SPIDER-MAN | . 1 2 | [&#39;Spider Mech vs. Venom&#39;] | VENOM | . 2 3 | [&#39;Spider Mech vs. Venom&#39;] | AUNT MAY | . 3 4 | [&#39;Spider Mech vs. Venom&#39;] | GHOST SPIDER | . 4 5 | [&quot;Yoda&#39;s Hut&quot;] | YODA | . Indeed, that&#39;s how this dataset is structured. What we want is a data structure with which fastai&#39;s data block can easily work with. So what we need is something that gives us the filename, the label and a label which data is for training and which one is for validation. Luckily we can get exactly this by combining the meta-data: . datablock_df = pd.merge(df, df_metadata, left_on=&#39;class_id&#39;, right_on=&#39;class_id&#39;).loc[:,[&#39;path&#39;, &#39;class_id&#39;, &#39;minifigure_name&#39;, &#39;train-valid&#39;]] datablock_df[&#39;is_valid&#39;] = datablock_df[&#39;train-valid&#39;]==&#39;valid&#39; datablock_df.head() . path class_id minifigure_name train-valid is_valid . 0 marvel/0001/001.jpg | 1 | SPIDER-MAN | train | False | . 1 marvel/0001/002.jpg | 1 | SPIDER-MAN | valid | True | . 2 marvel/0001/003.jpg | 1 | SPIDER-MAN | train | False | . 3 marvel/0001/004.jpg | 1 | SPIDER-MAN | train | False | . 4 marvel/0001/005.jpg | 1 | SPIDER-MAN | train | False | . fastai gives us a brief overview of what to check before we can make optimal use of the datablock: . what are the types of our inputs and targets? Images and labels. where is the data? In a dataframe. how do we know if a sample is in the training or the validation set? A column of our dataframe. how do we get an image? By looking at the column path. how do we know the label of an image? By looking at the column minifigure_name. do we want to apply a function to a given sample? Yes, we need to resize everything to a given size. do we want to apply a function to a batch after it&#39;s created? Yes, we want data augmentation. . lego_block = DataBlock(blocks=(ImageBlock, CategoryBlock), splitter=ColSplitter(), get_x=lambda x:p/&quot;train&quot;/f&#39;{x[0]}&#39;, get_y=lambda x:x[2], item_tfms=Resize(224), batch_tfms=aug_transforms()) . Now our datablock is called lego_block. See how it perfectly matches together? . Let me briefly explain what the different steps within our lego_block are doing: first we tell the lego_block on what we want to split our data on (the default here is col=&#39;is_valid&#39;), then we simply put our path column (x[0]) and combine it with our path p and the folder &#39;train&#39; in which is is located in. get_y tells the lego_block where to find the labels in our dataset (x[2]), we then make all of our images the same size and apply transformation on them (checkout fastai for more information). . dls = lego_block.dataloaders(datablock_df) dls.show_batch() . Glorious! . fastai tries to make our life easier. This blog is intended to show you guys how to easily and quickly manage to get a great classifier with it. In the upcoming blogs I will try to better explain what is going on behind the scenes. But for now, let&#39;s enjoy how fast we can build our classifier with fastai! . learn = cnn_learner(dls, resnet34, metrics=error_rate) learn.fine_tune(20) . epoch train_loss valid_loss error_rate time . 0 | 5.044340 | 7.069784 | 0.980263 | 00:04 | . epoch train_loss valid_loss error_rate time . 0 | 4.333549 | 5.407881 | 0.960526 | 00:05 | . 1 | 4.193551 | 4.404543 | 0.947368 | 00:04 | . 2 | 3.994802 | 3.605752 | 0.907895 | 00:04 | . 3 | 3.721432 | 2.941005 | 0.802632 | 00:04 | . 4 | 3.428093 | 2.336661 | 0.638158 | 00:05 | . 5 | 3.092875 | 1.841397 | 0.532895 | 00:04 | . 6 | 2.779624 | 1.470707 | 0.434211 | 00:05 | . 7 | 2.484196 | 1.200388 | 0.348684 | 00:05 | . 8 | 2.216630 | 1.011226 | 0.263158 | 00:05 | . 9 | 1.988927 | 0.901224 | 0.236842 | 00:04 | . 10 | 1.794780 | 0.819948 | 0.217105 | 00:05 | . 11 | 1.624516 | 0.756500 | 0.184211 | 00:04 | . 12 | 1.478024 | 0.716581 | 0.157895 | 00:05 | . 13 | 1.354157 | 0.688189 | 0.164474 | 00:04 | . 14 | 1.244102 | 0.673431 | 0.164474 | 00:05 | . 15 | 1.149104 | 0.662224 | 0.164474 | 00:04 | . 16 | 1.062147 | 0.652154 | 0.164474 | 00:04 | . 17 | 0.985224 | 0.654423 | 0.177632 | 00:04 | . 18 | 0.917764 | 0.653068 | 0.177632 | 00:05 | . 19 | 0.858115 | 0.652137 | 0.184211 | 00:04 | . interp = ClassificationInterpretation.from_learner(learn) interp.plot_confusion_matrix(figsize=(12,12), dpi=60) . interp.most_confused(min_val=2) . [(&#39;RON WEASLEY&#39;, &#39;HARRY POTTER&#39;, 2), (&#39;SPIDER-MAN&#39;, &#39;FIREFIGHTER&#39;, 2)] . Not to bad I would say. However, seeing an image of Ronald Weasley and predicting it to be Harry Potter - I&#39;m not sure how much this will impress your significant other. On the other hand, Captain America is correctly predicted 100%. . But we can still try to improve our model by unfreezing the weights, to make the model even better. Let&#39;s check this out: . learn.fit_one_cycle(3, 3e-3) . epoch train_loss valid_loss error_rate time . 0 | 0.061034 | 0.536347 | 0.151316 | 00:05 | . 1 | 0.046480 | 0.631286 | 0.157895 | 00:04 | . 2 | 0.039729 | 0.572698 | 0.157895 | 00:05 | . Then we will unfreeze the parameters and learn at a slightly lower learning rate: . learn.unfreeze() . learn.fit_one_cycle(2, lr_max=1e-5) . epoch train_loss valid_loss error_rate time . 0 | 0.014817 | 0.483588 | 0.125000 | 00:05 | . 1 | 0.016834 | 0.425858 | 0.098684 | 00:04 | . Wow! Down to only 10% error rate. I think that&#39;s quite impressive! Let&#39;s see the confusion matrix: . interp = ClassificationInterpretation.from_learner(learn) interp.plot_confusion_matrix(figsize=(12,12), dpi=60) . With these results I am sure you will impress your significant other! . In one of the next posts I will show you how to use Jupyter to easily set up a small Web App with the help of Binder. So stay tuned! . Lasse .",
            "url": "https://lschmiddey.github.io/fastpages_/2020/09/16/Lego-Classification.html",
            "relUrl": "/2020/09/16/Lego-Classification.html",
            "date": " • Sep 16, 2020"
        }
        
    
  
    
        ,"post1": {
            "title": "How to get the kaggle API started",
            "content": "Easy way to download datasets from kaggle from your terminal . In this blog post I would like to show you how to use kaggles api. And not only that, I will show you how to directly use this API from Jupyter. It&#39;s straightforward and shouldn&#39;t take longer than 5 minutes. Let&#39;s get started! . First of all, log in into your kaggle account and go to &quot;Your Account&quot;. Scroll down until you find the section API. Click on &quot;Create New API Token&quot;. . . Next, upload your downloaded token into a directory to which you have access to. In this blogpost, I use my Cloud Working Space on Paperspace (how to easily set up your own working space in Paperspace click here. . . Note however, that kaggle expects your token to be at a specific folder: ~/.kaggle/kaggle.json on Linux, OSX, and other UNIX-based operating systems, and at C: Users&lt;Windows-username.kaggle kaggle.json on Windows. So that&#39;s what we will do next. Just open your Terminal and move your token to the expected folder. . . And that&#39;s it, you can now use the kaggle API! If you (like me) use a remote computing instance, we don&#39;t want other user to possible use our token. We can prevent this by typing: . . Let&#39;s see how the kaggle API works. First of all, we need to pip install the package. . . If you are looking for a specific dataset, you can now use the kaggle API and simply type: . . If you want to download data from this API, you write: . . In that way you can easily access kaggle datasets and make that work even on cloud computing instances. . Stay tuned for the next blogpost! . Lasse .",
            "url": "https://lschmiddey.github.io/fastpages_/2020/09/15/get-kaggle-api-started.html",
            "relUrl": "/2020/09/15/get-kaggle-api-started.html",
            "date": " • Sep 15, 2020"
        }
        
    
  
    
        ,"post2": {
            "title": "Setup Paperspace",
            "content": "Kostenlose (und bessere?) Alternative zu Google Colab . Die meisten Machine Learning bzw. Deep Learning Projekte will man nicht auf seinem eigenem PC/Laptop rechnen lassen. Dies hat viele gute Gründe. Zum einen hat nicht jeder Laptop eine geeignete Grafikkarte (GPU), auf der sich DeepLearning Modelle berechnen lassen. Außerdem ist das administrieren der verschiedenen Treiber und das Setup der GPU für Jupyter Notebooks nichts, was super einfach ist. Im Gegenteil. Zudem kostet eine gute Grafikkarte viel Geld. Alles Gründe, weswegen man sich lieber nach kostengünstigen Alternativen umsehen sollte, die einem den administrativen Aufwand abnehmen. . Eine solche Alternative ist Paperspace. Paperspace Gradient stellt ähnlich zu Google Colab eine kostenlose Alternative, wie sich in der Cloud Rechner mit GPUs benutzen lassen. Außerdem hat Paperspace Gradient den Vorteil, dass sich auch Daten wie Datensätze, Bilder, Modelle kostenlos speichern lassen, und nicht nach beenden der Instanz gelöscht werden (wie zum Beispiel in Google Colab). . In diesem Blog will ich zeigen, wie sich über Paperspace eine kostenlose Instanz anlegen lässt, die auch mit GPUs läuft, und wie sich die erstellten Notebooks einfach mit einem bestehenden github Repo verbinden lassen. . Zunächst muss man sich auf der Paperspace-Seite registrieren. Nach der einmaligen Registrierung öffnet sich Folgendes: . . Hier muss zunächst der Container gewählt werden. Das bedeutet nichts anderes, als dass man ein für ein bestimmtes Projekt benötigtes Grund-Setup schon für einen vorinstalliert bekommt - wie wunderbar! Man muss sich über keine Abhängigkeiten kümmern, ist sich sicher, dass die Packages auf dem aktuellsten Stand sind und falls benötigt kann man später immer noch selbst Packages hinzufügen. Was für ein Luxus! Wenn man z.B. ein Projekt mit PyTorch bauen will, so klickt man einfach auf den PyTorch Container. . . Als nächstes wählt man die Maschine, auf der das Projekt laufen soll. Das Beste hierbei: es gibt Maschinen, die von Paperspace komplett umsonst zur Verfügung gestellt werden, sogar mit GPU! Diese sind die letzten 3 Auswahlmöglichkeiten. Und wenn man mehr Power braucht, so kann man auch im Nachhinein noch aufrüsten. . Des weiteren kann man ganz einfach ein bestehendes eigenes git-Repo mit der Instanz verbinden. Dafür einfach den git-Link zum Repo einfügen. . . Zuletzt muss noch eine gültige Kreditkarte hinterlegt werden (wie schon beschrieben, die Kreditkarte wird nur belastet, wenn eine der nicht kotenlosen Alternativen gewählt wird). Danach kann auf &quot;Create new Instance&quot; geklickt werden und schon geht es los! . . Jetzt kann auf &quot;Open&quot; geklickt werden und schon startet sich ein Jupyter Notebook. Das Ganze sollte dann in etwa so aussehen (das README.md stammt schon aus dem verlinkten github-Repo): . . Wie erwähnt ist mein github Repo schon mit der Instanz verbunden. So sieht bislang mein neu angelegtes Repo in github aus: . . Dann lasst uns ein neues Jupyter Notebook anlegen. Einfach auf &quot;New&quot; -&gt; &quot;Python 3&quot; klicken, und es öffnet sich ein Notebook: . . Als nächstes will ich zeigen, wie sich mit Hilfe des Terminals ganz einfach neue packages installieren lassen (über pip), und wie sich das bestehende github Repo aus dem Terminal ansteuern lässt. Dafür muss man bei Jupyter einfach auf &quot;New&quot; und dann -&gt; &quot;Terminal&quot; klicken. . . Mit dem Befehl installieren wir aus fastai das fastbook. Dies funktioniert über pip install. . Jetzt will ich zeigen, wie sich das Terminal ganz einfach mit git verbinden lässt. Über git clone können wir öffentliche git-Repos direkt auf unsere Instanz klonen/kopieren: . . Dies finden wir auch direkt in Jupyter wieder: . . Jetzt wollen wir das Ganze in unser mit der Instanz verbundenem github Repo laden. Dies funktioniert über git add, git commit und git push im Terminal. . . Anschließend muss noch der User Name zum Repo angegeben werden und das dazugehörige Passwort. Das war&#39;s schon. Wie großartig ist das? So sieht das geupdatete github Repo aus: . . Als weitere großartige Möglichkeit bietet Paperspace in den extra dedizierten Ordnern &quot;datasets&quot; und &quot;storage&quot; an, eigene Dateien umsonst in Paperspace zu speichern. Das bedeutet, dass sich bei Neustarten der Instanzen oder neu anlegen der Instanzen diese Dateien immer da sind! Diese Funktionalität bietet Google Colab zum Beispiel nicht an. . Ich hoffe dieser Blog war hilfreich und ihr seid wenigstens halb so begeistert wie ich es bin. . Bleibt dran für die nächsten Posts! . Euer Lasse .",
            "url": "https://lschmiddey.github.io/fastpages_/2020/09/12/Setup-Paperspace.html",
            "relUrl": "/2020/09/12/Setup-Paperspace.html",
            "date": " • Sep 12, 2020"
        }
        
    
  
    
        ,"post3": {
            "title": "Was ist Gradient Descent und wie funktioniert es?",
            "content": "Eine Coding Anleitung . (dieser Beitrag basiert lose auf dem von fastai zur Verfügung gestellten fastbook) . Dieser Blog Post ist nicht dafür gedacht aufzuzeigen, wie die mathematische Berechnung hinter Gradient Descent funktioniert. Denn zum Glück gibt es genau dafür Computer, die das Ganze wahrscheinlich millionenfach schneller berechnen können als wir. Ich will eine intuitive Erklärung für Gradient Descent liefern, wofür wir Gradient Descent überhaupt brauchen und wie wir mit simplen Python Code unseren eigenen auf Gradient Descent beruhenden Algorithmus bauen können. . Ich erinnere mich, dass ich zu Schulzeiten (und mehr als Abi-Mathe wird für diesen Post wahrhaftig nicht gebraucht) die Ableitungsregeln gelernt und auf Funktionen angewandt habe, aber wirklich Sinn und Zweck habe ich in dem Ganzen nie gesehen. Im besten Fall hat sich die Lehrerin einen an den Haaren herbeigezogenen Fall ausgedacht, um nicht einfach stumpf die Funktion zu liefern, die abgeleitet werden soll. Ich hoffe nach diesem Blog wird klarer, weswegen Ableitungen bzw. die dazugehörigen Gradienten doch eine ziemlich coole und nützliche Sache sind. . Zunächst einmal möchte ich zeigen, was Gradient Descent kann: . . Ein Algorithmus, der erkennen kann, was für ein Bär auf einem gegebenem Bild zu sehen ist? Was zur Hölle hat das mit Gradient Descent zu tun? Wenn du es bis zum Ende des Posts aushältst, wirst du das hoffentlich verstehen. . Gradient Descent hilft Computern dabei zu lernen. Das Ganze sollten wir uns vielleicht in einem Schaubild einmal näher anschauen: . . Die Idee ist dabei wie folgt: Wir haben ein Modell, welches anhand von Bildern erkennen soll, welche Art von Bär hier zu sehen ist. Nachdem wir genügend Bilder von verschiedenen Bären gesammelt haben, fangen wir an unser Modell zu fragen, was es glaubt für eine Art von Bären zu sehen (predict). Wir können uns nun Metriken überlegen, an denen wir erkennen können, wie gut diese Vorhersage unseres Modells ist, zum Beispiel wie häufig das Modell die richtige Bärenart vorhergesagt hat und wie häufig es falsch lag. Wir können daraus einen sogenannten Loss berechnen, was nichts anderes ist als das, was die Lehrer uns immer als Funktion beschrieben haben. Wir haben also eine Funktion die uns angibt, wie gut/schlecht unser Modell Bärenarten vorhersagen kann. Diese Funktion kann zum Beispiel eine simple quadratische Funktion sein, sie kann aber theoretisch jede nur erdenkliche Form annehmen. . Wir wollen unseren Loss minimieren, sprich unsere Funktion soll so gut wie es nur kann die Funktion lernen, wie es möglichst gut Bärenarten voneinander unterscheiden kann. Lass uns eine Sekunde darüber nachdenken. Wir benutzen eine Loss-Funktion, damit wir unserem Modell Feedback geben, wie gut/schlecht es die bisherige Aufgabe gelöst hat. Mithilfe dieser Loss-Funktion lernt unser Modell, die verschiedenen Bärenarten besser zu unterscheiden. Doch wie &quot;lernt&quot; das Modell? Hier kommt Gradient Descent ins Spiel. . Der Gradient, also die Ableitung, gibt uns an, um wie viel die Funktion größer wird, wenn wir (optisch gesprochen) einen kleinen Schritt nach rechts bzw. einen kleinen Schritt nach links gehen von dem Punkt, an dem wir uns gerade befinden. Dies ist die Steigung von dem Punkt, an welchem wir uns gerade befinden. Doch was bringt uns das? . Ich hoffe, du hast einen Moment darüber nachgedacht. Was wir wollen, ist möglichst gut die Bärenarten voneinander zu unterscheiden. Dies steuern wir über unsere Loss-Funktion. Und je geringer unsere Loss-Funktion, desto besser sind wir im Vorhersagen, was für eine Bärenart wir hier gerade haben. Durch den Gradienten wissen wir, in welche Richtung wir uns bewegen müssen, um unsere Loss-Funktion kleiner zu machen. . Noch mag das Ganze recht abstrakt klingen, schon in Kürze folgt hier das Beispiel in Python. Ich will das Ganze aber noch einmal zusammenfassen. Wir wollen etwas optimieren, zum Beispiel möglichst genau die Bärenart vorhersagen. Um diese Funktion zu optimieren, brauchen wir die Loss-Funktion, die uns angibt, wie gut/schlecht unser Modell/unsere Zielfunktion performt. Diese Funktionen können jegliche erdenkliche Formen annehmen. Dem Gradienten ist dies jedoch egal. Der Gradient kann uns zu jedem Ort, an welchem wir uns in der Funktion befinden sagen, was mit unser Loss-Funktion passiert, wenn wir uns ein kleines Stück in eine beliebeige Richtung bewegen. Dies nutzen wir als Feedback, um die Parameter der Zielfunktion so anzupassen, dass die Loss-Funktion kleiner wird, wir also besser die Bärenarten voneinander unterscheiden können. . Dies sind die Schritte, die in dem Schaubild erklärt sind: wir initialisieren die Werte unserer Zielfunktion (anfangs zufällig, weil wir nicht wissen, wie die richtige Funktion aussieht), wir lassen unser Modell Vorhersagen treffen, berechnen daraufhin den Loss und die dazugehörigen Gradienten, um dann durch die Gradienten die Parameter des Modells anzupassen. Diesen Prozess wiederholen wir solange, bis wir mit dem Endergebnis zufrieden sind .Dies sollte auf einem sogenannten Validierungs-Set festgelegt werden, also auf Bildern von Bären, die unser Modell im Trainingsloop nicht sieht. Vielleicht wäre es hier angebracht einmal darüber nachzudenken, warum wir nicht einfach den Trainingsloop solange wiederholen, bis wir alle Bärenarten durch Gradient Descent korrekt vorhersagen können (Stichwort: Overfitting). . Genug geredet, jetzt wollen wir das Ganze auch in Code sehen! . Code Beispiel . Wir wollen mit Hilfe des oben beschriebenen Prozesses eine Funktion finden, die möglichst genau den Verlauf folgender Funktion beschrieben kann: . import torch import matplotlib.pyplot as plt . x = torch.arange(-5,20).float(); x y = 0.75*(x-4)**2 + 0.5*x + 1 plt.scatter(x,y); . Was wir wollen ist die Parameter dieser Funktion zu schätzen. Vom ansehen der Daten können wir bereits auf die funktionale Form schließen - ein Polynom 3ten Grades. Was wir an diesem Beispiel schon erkennen können ist, dass die angenommene Zielfunktion eine große Rolle spielt. Hätten wir von den Daten auf eine quadratische Funktion geschlossen, würden wir die &quot;wahre&quot; Form der Funktion nie richtig bestimmen können. Deep Learning überkommt dieses &quot;Problem&quot;, indem es jede nur erdenkliche Funktion annehmen kann (dazu mehr in einem späteren Post). . def f(x, params): a,b,c,d = params return a*(x-b)**2 + (c*x) + d . Jetzt benötigen wir noch unsere Loss-Funktion (und ich hoffe hier wird klar, wie Loss-Funktion und Zielfunktion miteinander &quot;kommunizieren&quot;): . def mse(preds, targets): return ((preds-targets)**2).mean() . params = torch.randn(4).requires_grad_() params . tensor([ 1.1514, 0.2004, -0.8726, 0.5281], requires_grad=True) . Wir starten unsere Vorhersagen: . preds = f(x, params) plt.scatter(x,preds.detach().numpy()) . &lt;matplotlib.collections.PathCollection at 0x7fd49eb1e580&gt; . Wie gut sehen unsere Vorhersagen aus? . def show_preds(preds, ax=None): if ax is None: ax=plt.subplots()[1] ax.scatter(x, y) ax.scatter(x, preds.detach().numpy(), color=&#39;red&#39;) ax.set_ylim(-10,100) ax.set_xlim(-5,20) . show_preds(preds) . Wow! Ziemlich miserabel. Wie miserabel zeigt uns unser loss. . loss = mse(preds, y) loss . tensor(8606.2266, grad_fn=&lt;MeanBackward0&gt;) . Auf geht&#39;s Gradient! Zeig uns, wie wir unsere Parameter updaten müssen, damit der Loss kleiner wird. . loss.backward() params.grad . tensor([26820.2754, -4137.0151, 1819.5073, 114.5496]) . Dann lass uns unsere Paramter anpassen (wir multiplizieren den Gradienten mit der sogenannten Learning Rate, dazu in einem weiteren Blog Posts mehr). . lr = 1e-5 params.data -= lr * params.grad.data params.grad = None params . tensor([ 0.8832, 0.2418, -0.8908, 0.5269], requires_grad=True) . Ist unser Loss geringer geworden? . preds = f(x,params) mse(preds, y) . tensor(2857.6997, grad_fn=&lt;MeanBackward0&gt;) . show_preds(preds) . Zum Glück ja. . Wir wollen die steps wiederholen, sodass wir langsam und mithilfe von Gradient Descent unsere Zielfunktion finden. . def apply_step(params, prn=True): preds = f(x, params) loss = mse(preds, y) loss.backward() params.data -= lr * params.grad.data params.grad = None if prn: print(loss.item()) return preds lr=1e-5 for i in range(20): apply_step(params) . 204.3289794921875 201.9536590576172 201.0904083251953 200.72898864746094 200.5342254638672 200.39480590820312 200.27386474609375 200.1591033935547 200.0463104248047 199.9343719482422 199.82254028320312 199.71095275878906 199.59934997558594 199.4879150390625 199.3763885498047 199.26504516601562 199.1535186767578 199.04220581054688 198.93089294433594 198.8196258544922 . _,axs = plt.subplots(1,6,figsize=(24,3)) for ax in axs: show_preds(apply_step(params, False), ax) plt.tight_layout() . Wie man sieht, passt sich die rote Kurve, also unsere Vorhersagen, immer mehr der wahren Kurve an. Alles aufgrund von Gradient Descent! Und genau diese Technik und diese Schritte, die hier in diesem Blog Post aufgezeigt wurden, sind auch die Schritte, die dabei helfen, Neuronale Netze zu trainieren. Die dann wiederum Bären auseinander halten können. . Ich hoffe, durch diesen Post ist die Idee hinter Gradient Descent ein wenig greifbarer geworden und der Sinn und Zweck von Ableitungen könnte von einer anderen Seite vielleicht ein wenig verständlicher betrachtet werden. . Bleibt dran für die nächsten Posts! . Euer Lasse .",
            "url": "https://lschmiddey.github.io/fastpages_/2020/09/01/Gradient-Descent.html",
            "relUrl": "/2020/09/01/Gradient-Descent.html",
            "date": " • Sep 1, 2020"
        }
        
    
  

  
  

  
      ,"page1": {
          "title": "About Me",
          "content": ". Ich bin Lasse, ein Data Science Enthusiast! .",
          "url": "https://lschmiddey.github.io/fastpages_/about/",
          "relUrl": "/about/",
          "date": ""
      }
      
  

  

  
  

  

  
  

  

  
  

  
  

  
  

  
      ,"page10": {
          "title": "",
          "content": "Sitemap: {{ “sitemap.xml” | absolute_url }} | .",
          "url": "https://lschmiddey.github.io/fastpages_/robots.txt",
          "relUrl": "/robots.txt",
          "date": ""
      }
      
  

}