{
  
    
        "post0": {
            "title": "Deep Tabular Augmentation for Regression Tasks",
            "content": "So far I did show how to use Deep Learning for Data Augmentation with the idea in mind to create data for an underrepresented class in your dataset. However, the Deep Tabular Augmenter can be used for more than just that. In this blogpost I want to show you how you can use the technique to create data for regression tasks. . First, we need a dataset. Here, I use the infamous Boston Housing Dataset. . import pandas as pd import numpy as np import torch from torch import nn from torch import optim from sklearn.preprocessing import StandardScaler from functools import partial import deep_tabular_augmentation as dta from sklearn.model_selection import train_test_split import matplotlib.pyplot as plt . device = torch.device(&#39;cuda&#39; if torch.cuda.is_available() else &#39;cpu&#39;) DATA_PATH = &#39;data/housing.csv&#39; header_list = [&#39;CRIM&#39;, &#39;ZN&#39;,&#39;INDUS&#39;, &#39;CHAS&#39;, &#39;NOX&#39;, &#39;RM&#39;, &#39;AGE&#39;, &#39;DIS&#39;, &#39;RAD&#39;, &#39;TAX&#39;, &#39;PTRATIO&#39;, &#39;B&#39;, &#39;LSTAT&#39;, &#39;MEDV&#39;] df = pd.read_csv(DATA_PATH, delim_whitespace=True, names=header_list) . df.head() . CRIM ZN INDUS CHAS NOX RM AGE DIS RAD TAX PTRATIO B LSTAT MEDV . 0 0.00632 | 18.0 | 2.31 | 0 | 0.538 | 6.575 | 65.2 | 4.0900 | 1 | 296.0 | 15.3 | 396.90 | 4.98 | 24.0 | . 1 0.02731 | 0.0 | 7.07 | 0 | 0.469 | 6.421 | 78.9 | 4.9671 | 2 | 242.0 | 17.8 | 396.90 | 9.14 | 21.6 | . 2 0.02729 | 0.0 | 7.07 | 0 | 0.469 | 7.185 | 61.1 | 4.9671 | 2 | 242.0 | 17.8 | 392.83 | 4.03 | 34.7 | . 3 0.03237 | 0.0 | 2.18 | 0 | 0.458 | 6.998 | 45.8 | 6.0622 | 3 | 222.0 | 18.7 | 394.63 | 2.94 | 33.4 | . 4 0.06905 | 0.0 | 2.18 | 0 | 0.458 | 7.147 | 54.2 | 6.0622 | 3 | 222.0 | 18.7 | 396.90 | 5.33 | 36.2 | . df.shape . (506, 14) . As we have only 506 entries, from which we can observe data, this example is a pretty good use case of using the Deep Tabular Augmenter. Usually, people use this dataset for predicting the MEDV, so the Median value of owner-occupied homes in $1000&#39;s. Let&#39;s first create train and test datasets: . X_train, X_test = train_test_split(df, test_size=0.1, random_state=42) x_scaler = StandardScaler() X_train_scaled = x_scaler.fit_transform(X_train) X_test_scaled = x_scaler.transform(X_test) . pd.DataFrame(X_train_scaled, columns=list(df.columns)).head() . CRIM ZN INDUS CHAS NOX RM AGE DIS RAD TAX PTRATIO B LSTAT MEDV . 0 -0.416942 | 0.344513 | -1.117966 | -0.270395 | -0.960137 | 0.943640 | -1.102673 | 0.654891 | -0.523106 | -1.144555 | -1.601746 | 0.398294 | -1.108176 | 1.365122 | . 1 -0.280002 | -0.499723 | -0.421068 | -0.270395 | -0.145806 | -0.222195 | 0.832605 | 0.069475 | -0.638367 | -0.601866 | 1.175568 | 0.448420 | 0.863237 | -0.805235 | . 2 -0.408091 | -0.499723 | -0.360216 | -0.270395 | -0.299938 | 0.679704 | 0.108207 | -0.448063 | -0.523106 | -0.142668 | 1.130038 | 0.434251 | -0.678455 | 0.408875 | . 3 -0.359270 | 0.344513 | -1.025240 | -0.270395 | 0.171021 | 1.652175 | -0.555824 | -0.440721 | -0.523106 | -0.858301 | -2.466811 | 0.377578 | -1.307689 | 2.235413 | . 4 -0.000352 | -0.499723 | 1.021988 | -0.270395 | 0.239524 | 0.017747 | -0.580681 | 0.076309 | 1.666847 | 1.539070 | 0.811330 | 0.359545 | -0.272453 | -0.160575 | . Then, we&#39;ll put the data into dataloaders, so our Deep Tabular Augmenter can do calculations on it. This time, we use a slightly different dataloader-function: dta.create_datasets_no_target_var. This is a convenience function for when we do not have a target-variable. Usually, for example in the fraud-detection case, we have a specific target vaiable at hand, for which we do not want to create fake data. This here is different, as we also want to create fake data for our (in later tasks used) MEDV variable. . Also, make sure to have at least version 0.5.0 of deep_tabular_augmentation, otherwise you won&#39;t have this function. If not, just go: pip install deep_tabular_augmentation --upgrade . datasets = dta.create_datasets_no_target_var(X_train_scaled, X_test_scaled) data = dta.DataBunch(*dta.create_loaders(datasets, bs=1024)) . From now on, everything should be very familiar. Let&#39;s start with the basic architecture of our model: . D_in = X_train_scaled.shape[1] VAE_arch = [50, 12, 12] df_cols = list(df.columns) model = dta.Autoencoder(D_in, VAE_arch, latent_dim=5).to(device) opt = optim.Adam(model.parameters(), lr=0.01) loss_func = dta.customLoss() . Put everything data related into the learner class: . learn = dta.Learner(model, opt, loss_func, data, cols=df_cols) run = dta.Runner(cb_funcs=[dta.LR_Find, dta.Recorder]) run.fit(100, learn) . run.recorder.plot(skip_last=5) . Set up a Learning Rate schema of your choice and train the model: . sched = dta.combine_scheds([0.3, 0.7], [dta.sched_cos(0.01, 0.1), dta.sched_cos(0.1, 0.01)]) . cbfs = [partial(dta.LossTracker, show_every=50), dta.Recorder, partial(dta.ParamScheduler, &#39;lr&#39;, sched)] model = dta.Autoencoder(D_in, VAE_arch, latent_dim=20).to(device) opt = optim.Adam(model.parameters(), lr=0.01) learn = dta.Learner(model, opt, loss_func, data, cols=df_cols) run = dta.Runner(cb_funcs=cbfs) run.fit(400, learn) . epoch: 50 train loss is: 13623.060546875 validation loss is: 612.1049194335938 epoch: 100 train loss is: 5125.99072265625 validation loss is: 439.03076171875 epoch: 150 train loss is: 4169.7734375 validation loss is: 519.6369018554688 epoch: 200 train loss is: 3732.431396484375 validation loss is: 511.1471862792969 epoch: 250 train loss is: 3492.6806640625 validation loss is: 468.2626953125 epoch: 300 train loss is: 3326.837646484375 validation loss is: 430.8256530761719 epoch: 350 train loss is: 3203.124267578125 validation loss is: 402.46844482421875 epoch: 400 train loss is: 3105.912109375 validation loss is: 380.48358154296875 . Let&#39;s have a look at the created data: . new_data_points = 1000 df_fake = run.predict_df(learn, no_samples=new_data_points, scaler=x_scaler) std_list = list(df[df_cols].std()/10) df_fake_with_noise = run.predict_with_noise_df(learn, no_samples=new_data_points, mu=0, sigma=std_list, scaler=x_scaler) df_fake_with_noise.head() . CRIM ZN INDUS CHAS NOX RM AGE DIS RAD TAX PTRATIO B LSTAT MEDV . 0 -0.061319 | 7.058959 | 8.945721 | 0.013245 | 0.488697 | 6.139548 | 58.205878 | 3.804640 | 4.543752 | 320.783396 | 18.403781 | 398.551691 | 11.238506 | 22.612332 | . 1 1.003866 | 6.856581 | 8.805585 | 0.025567 | 0.516702 | 6.069803 | 67.046331 | 3.949096 | 5.485925 | 326.843934 | 18.556644 | 381.434741 | 10.764693 | 20.467331 | . 2 0.976743 | 4.248924 | 8.800449 | -0.009408 | 0.509263 | 5.971862 | 54.597878 | 4.920510 | 4.968876 | 295.964594 | 18.648691 | 383.313037 | 12.274177 | 22.356870 | . 3 0.329469 | -2.955746 | 9.026785 | 0.000997 | 0.520971 | 6.012886 | 77.822414 | 3.400364 | 5.377612 | 335.715743 | 19.341018 | 374.741465 | 13.768394 | 19.288477 | . 4 -0.808149 | 1.374236 | 8.696051 | -0.025238 | 0.544275 | 6.043268 | 77.303222 | 3.288870 | 3.969855 | 363.377079 | 19.962985 | 370.265762 | 15.021694 | 17.637887 | . As RAD and CHAS are not continuous, let&#39;s just round it to the nearest number. . df_fake_with_noise[&#39;RAD&#39;] = df_fake_with_noise[&#39;RAD&#39;].round() df_fake_with_noise[&#39;CHAS&#39;] = df_fake_with_noise[&#39;CHAS&#39;].round() . Now that we have that, let&#39;s come to the evaluation part. Training is all fun and good, but we want to see some results. So let&#39;s plot it: . fig, ax = plt.subplots() fig.set_size_inches(15.5, 8.5) ax.scatter(df[&#39;MEDV&#39;], df[&#39;AGE&#39;], alpha=0.5) ax.set_xlabel(&#39;MEDV&#39;, fontsize=15) ax.set_ylabel(&#39;AGE&#39;, fontsize=15) ax.set_title(&#39;Real Data: MEDV vs AGE&#39;, fontsize=15) ax.grid(True) fig.tight_layout() plt.show() . fig, ax = plt.subplots() fig.set_size_inches(15.5, 8.5) ax.scatter(df_fake_with_noise[&#39;MEDV&#39;], df_fake_with_noise[&#39;AGE&#39;], alpha=0.5) ax.set_xlabel(&#39;MEDV&#39;, fontsize=15) ax.set_ylabel(&#39;AGE&#39;, fontsize=15) ax.set_title(&#39;Fake Data: MEDV vs AGE&#39;, fontsize=15) ax.grid(True) fig.tight_layout() plt.show() . fig, ax = plt.subplots() fig.set_size_inches(15.5, 8.5) ax.scatter(df[&#39;MEDV&#39;], df[&#39;RM&#39;], c=df[&#39;LSTAT&#39;], alpha=0.5) ax.set_xlabel(&#39;MEDV&#39;, fontsize=15) ax.set_ylabel(&#39;RM&#39;, fontsize=15) ax.set_title(&#39;Real Data: MEDV vs avg no of rooms by percentage of lower status of population&#39;, fontsize=15) ax.grid(True) fig.tight_layout() plt.show() . fig, ax = plt.subplots() fig.set_size_inches(15.5, 8.5) ax.scatter(df_fake_with_noise[&#39;MEDV&#39;], df_fake_with_noise[&#39;RM&#39;], c=df_fake_with_noise[&#39;LSTAT&#39;], alpha=0.5) ax.set_xlabel(&#39;MEDV&#39;, fontsize=15) ax.set_ylabel(&#39;RM&#39;, fontsize=15) ax.set_title(&#39;Fake Data: MEDV vs avg no of rooms by percentage of lower status of population&#39;, fontsize=15) ax.grid(True) fig.tight_layout() plt.show() . I think that looks pretty awesome! So remember, whenever you have just not enough data for your model to train properly, you can try the Deep Tabular Augmenter to create enough fake data, so your model is actually able to learn something. I hope this helps and stay tuned for more! . Lasse .",
            "url": "https://lschmiddey.github.io/fastpages_/2022/04/23/DataAugmentation_for_Regression_Tasks.ipynb.html",
            "relUrl": "/2022/04/23/DataAugmentation_for_Regression_Tasks.ipynb.html",
            "date": " • Apr 23, 2022"
        }
        
    
  
    
        ,"post1": {
            "title": "Comparison of RandomForest with SMOTE vs Augmented Data",
            "content": "In this blog I&#39;d like to show the difference deep tabular augmentation can have when training a Random Forest on a highly biased data base. In this case, we have a look at credit card fraud, where fraud itself is is way less represented than non-fraud. I want to compare the popular SMOTE technique with the Deep Learning Augmentation. . import pandas as pd import numpy as np import torch from torch import nn from torch import optim from sklearn.preprocessing import StandardScaler from functools import partial import mlprepare as mlp import deep_tabular_augmentation as dta from sklearn.model_selection import train_test_split from sklearn.ensemble import RandomForestClassifier from sklearn.metrics import confusion_matrix . device = torch.device(&#39;cuda&#39; if torch.cuda.is_available() else &#39;cpu&#39;) DATA_PATH = &#39;data/creditcard.csv&#39; df = pd.read_csv(DATA_PATH) . Let&#39;s have a short look at the data: . df.head() . Time V1 V2 V3 V4 V5 V6 V7 V8 V9 ... V21 V22 V23 V24 V25 V26 V27 V28 Amount Class . 0 0.0 | -1.359807 | -0.072781 | 2.536347 | 1.378155 | -0.338321 | 0.462388 | 0.239599 | 0.098698 | 0.363787 | ... | -0.018307 | 0.277838 | -0.110474 | 0.066928 | 0.128539 | -0.189115 | 0.133558 | -0.021053 | 149.62 | 0 | . 1 0.0 | 1.191857 | 0.266151 | 0.166480 | 0.448154 | 0.060018 | -0.082361 | -0.078803 | 0.085102 | -0.255425 | ... | -0.225775 | -0.638672 | 0.101288 | -0.339846 | 0.167170 | 0.125895 | -0.008983 | 0.014724 | 2.69 | 0 | . 2 1.0 | -1.358354 | -1.340163 | 1.773209 | 0.379780 | -0.503198 | 1.800499 | 0.791461 | 0.247676 | -1.514654 | ... | 0.247998 | 0.771679 | 0.909412 | -0.689281 | -0.327642 | -0.139097 | -0.055353 | -0.059752 | 378.66 | 0 | . 3 1.0 | -0.966272 | -0.185226 | 1.792993 | -0.863291 | -0.010309 | 1.247203 | 0.237609 | 0.377436 | -1.387024 | ... | -0.108300 | 0.005274 | -0.190321 | -1.175575 | 0.647376 | -0.221929 | 0.062723 | 0.061458 | 123.50 | 0 | . 4 2.0 | -1.158233 | 0.877737 | 1.548718 | 0.403034 | -0.407193 | 0.095921 | 0.592941 | -0.270533 | 0.817739 | ... | -0.009431 | 0.798278 | -0.137458 | 0.141267 | -0.206010 | 0.502292 | 0.219422 | 0.215153 | 69.99 | 0 | . 5 rows × 31 columns . Also, let&#39;s have a look of how many more non-fraud cases we have compared to fraud cases: . difference_in_class_occurences = df[&#39;Class&#39;].value_counts()[0]-df[&#39;Class&#39;].value_counts()[1] difference_in_class_occurences . 283823 . In order to make use of the deep tabular augmentation we need to scale the data and then use only those cases, in which class we are interested in, in this case &quot;Class&quot; is equal to 1. . X_train, X_test, y_train, y_test = mlp.split_df(df, dep_var=&#39;Class&#39;, test_size=0.3, split_mode=&#39;random&#39;) x_scaler = StandardScaler() X_train_scaled = x_scaler.fit_transform(X_train) X_test_scaled = x_scaler.transform(X_test) X_train_fraud = X_train_scaled[np.where(y_train==1)[0]] X_test_fraud = X_test_scaled[np.where(y_test==1)[0]] . For our model to work we need to put our data in a DataLoader (here I use the DataBunch Class from deep data augmentation). . datasets = dta.create_datasets(X_train_fraud, y_train.values[np.where(y_train==1)], X_test_fraud, y_test.values[np.where(y_test==1)]) data = dta.DataBunch(*dta.create_loaders(datasets, bs=1024)) . Now we&#39;re already good to go. We can define our Variational Encoder Architecture (here: 50-&gt;12-&gt;12-&gt;5-&gt;12-&gt;12-&gt;50) and then use the LearningRate Finder to tell us the best Learning rate: . D_in = X_train_fraud.shape[1] VAE_arch = [50, 12, 12] target_name = &#39;Class&#39; target_class = 1 df_cols = list(df.columns) model = dta.Autoencoder(D_in, VAE_arch, latent_dim=5).to(device) opt = optim.Adam(model.parameters(), lr=0.01) loss_func = dta.customLoss() . learn = dta.Learner(model, opt, loss_func, data, target_name, target_class, df_cols) run = dta.Runner(cb_funcs=[dta.LR_Find, dta.Recorder]) run.fit(100, learn) . run.recorder.plot(skip_last=5) . We set up a desirable learning rate and scheduler for our learning rate: . sched = dta.combine_scheds([0.3, 0.7], [dta.sched_cos(0.01, 0.1), dta.sched_cos(0.1, 0.01)]) . Now, let&#39;s train the model: . cbfs = [partial(dta.LossTracker, show_every=50), dta.Recorder, partial(dta.ParamScheduler, &#39;lr&#39;, sched)] model = dta.Autoencoder(D_in, VAE_arch, latent_dim=20).to(device) opt = optim.Adam(model.parameters(), lr=0.01) learn = dta.Learner(model, opt, loss_func, data, target_name, target_class, df_cols) run = dta.Runner(cb_funcs=cbfs) run.fit(400, learn) . epoch: 50 train loss is: 235061.25 validation loss is: 106866.8203125 epoch: 100 train loss is: 170239.125 validation loss is: 75203.1640625 epoch: 150 train loss is: 120978.515625 validation loss is: 149698.640625 epoch: 200 train loss is: 87892.9296875 validation loss is: 129409.578125 epoch: 250 train loss is: 69032.921875 validation loss is: 100179.2109375 epoch: 300 train loss is: 57270.7421875 validation loss is: 81863.3671875 epoch: 350 train loss is: 49296.77734375 validation loss is: 69471.0546875 epoch: 400 train loss is: 43532.91015625 validation loss is: 60559.10546875 . Let&#39;s see how the created data looks like: . # take 25% of real standard deviation sigma = list(df[df[&#39;Class&#39;]==1][df_cols].std()*0.25) df_fake_with_noise = run.predict_with_noise_df(learn, no_samples=1000, mu=0, sigma=sigma, scaler=x_scaler) . df_fake_with_noise.describe().loc[[&#39;mean&#39;]] . Time V1 V2 V3 V4 V5 V6 V7 V8 V9 ... V21 V22 V23 V24 V25 V26 V27 V28 Amount Class . mean 92906.046144 | -2.386666 | 1.423976 | -4.081175 | 2.416863 | -1.921564 | -1.03062 | -3.456801 | 1.271546 | -1.98204 | ... | 1.012225 | 0.446317 | 0.208623 | -0.239074 | -0.014651 | 0.049692 | 0.773771 | -0.056647 | 131.269742 | 1.0 | . 1 rows × 31 columns . Now we use SMOTE for creating data . from imblearn.over_sampling import SMOTE sm = SMOTE(random_state=42) X_res, y_res = sm.fit_resample(X_train, y_train) . y_train.value_counts() . 0 199032 1 332 Name: Class, dtype: int64 . y_res.value_counts() . 0 199032 1 199032 Name: Class, dtype: int64 . So basically SMOTE creates as many entries of the minority class until we have the same amount of cases in both classes. We can do this with the DeepLearning Augmenter as well: . difference_in_trainset = y_train.value_counts()[0]-y_train.value_counts()[1] df_fake_with_noise = run.predict_with_noise_df(learn, no_samples=difference_in_trainset, mu=0, sigma=sigma, scaler=x_scaler) df_fake_with_noise.shape . (198700, 31) . While SMOTE creates these synthetic data in almost no-time, the DeepLearning Augmentation takes about a minute. . Train Random Forest . We want to compare how the built-in class_weight functionality performs vs the new approach vs SMOTE. So we will build three trainsets: the original one, the one with additional data from SMOTE, and the one with additional data from DeepLearning Augmentation. . train_df, test_df = train_test_split(df, test_size=0.3, random_state=42) train_df_fake_with_noise = pd.concat([train_df, df_fake_with_noise]) . To make things easier to understand, let&#39;s define the datasets on which to train and on which to assess the results: . X_train, X_test, X_train_aug = train_df.iloc[:,:30].values, test_df.iloc[:,:30].values, train_df_fake_with_noise.iloc[:,:30].values y_train, y_test, y_train_aug = train_df.iloc[:,30].values, test_df.iloc[:,30].values, train_df_fake_with_noise.iloc[:,30].values . X_train.shape, X_train_aug.shape, X_res.shape . ((199364, 30), (398064, 30), (398064, 30)) . y_train.shape, y_train_aug.shape, y_res.shape . ((199364,), (398064,), (398064,)) . First, let&#39;s train model on the original data while using the differences in class occurences as weights. . def rf(xs, y, n_estimators=40, max_samples=500, max_features=0.5, min_samples_leaf=5, **kwargs): return RandomForestClassifier(n_jobs=-1, n_estimators=n_estimators, max_samples=max_samples, max_features=max_features, min_samples_leaf=min_samples_leaf, oob_score=True, class_weight={0:1,1:difference_in_class_occurences}).fit(xs, y) . m = rf(X_train, y_train) confusion_matrix(y_test, np.round(m.predict(X_test))) . array([[85304, 3], [ 132, 4]]) . Then we use the SMOTE data: . def rf_aug(xs, y, n_estimators=40, max_samples=500, max_features=0.5, min_samples_leaf=5, **kwargs): return RandomForestClassifier(n_jobs=-1, n_estimators=n_estimators, max_samples=max_samples, max_features=max_features, min_samples_leaf=min_samples_leaf, oob_score=True).fit(xs, y) . m_smote = rf_aug(X_res.values, y_res) confusion_matrix(y_test, np.round(m_smote.predict(X_test))) . array([[84024, 1283], [ 11, 125]]) . Finally, we use the augmented dataframe: . m_aug = rf_aug(X_train_aug, y_train_aug) confusion_matrix(y_test, np.round(m_aug.predict(X_test))) . array([[85249, 58], [ 29, 107]]) . Let&#39;s have a look at the Classification Reports: . from sklearn.metrics import classification_report target_names = [&#39;no-fraud&#39;, &#39;fraud&#39;] print(classification_report(y_test, np.round(m.predict(X_test)), target_names=target_names)) . precision recall f1-score support no-fraud 1.00 1.00 1.00 85307 fraud 0.57 0.03 0.06 136 accuracy 1.00 85443 macro avg 0.78 0.51 0.53 85443 weighted avg 1.00 1.00 1.00 85443 . print(classification_report(y_test, np.round(m_smote.predict(X_test)), target_names=target_names)) . precision recall f1-score support no-fraud 1.00 0.98 0.99 85307 fraud 0.09 0.92 0.16 136 accuracy 0.98 85443 macro avg 0.54 0.95 0.58 85443 weighted avg 1.00 0.98 0.99 85443 . print(classification_report(y_test, np.round(m_aug.predict(X_test)), target_names=target_names)) . precision recall f1-score support no-fraud 1.00 1.00 1.00 85307 fraud 0.65 0.79 0.71 136 accuracy 1.00 85443 macro avg 0.82 0.89 0.86 85443 weighted avg 1.00 1.00 1.00 85443 . We see quite huge differences between the three approaches. Simply attaching a higher weight to the fraud-class didn&#39;t help at all, we were only able to identify 4 fraud cases correctly. The SMOTE approach lead to way more identified fraud cases, it found 125 cases out of 136. This leads to an recall of 0.92. However, this comes at a cost: we have astonishing 1283 missclassified fraud cases, leading to a precision in the fraud case of 0.09. The Deep Learning Augmentation correctly predicted 107 out of the 136 cases while only misclassifying 58 cases - this leads to a precision of 0.65 in the fraud case. . To conclude, I think this blog was able to show the merits of Deep Learning Augmentation. While increasing the correctly identified fraud cases we were also able to keep a high precision in this case, meaning we only have a few misclassified cases. While SMOTE was able to correctly identify a few more fraud cases it did also create a huge amount of misclassified fraud cases which might be costly when it comes to resource allocation. . Lasse .",
            "url": "https://lschmiddey.github.io/fastpages_/2022/02/19/DataAugmentation_vs_SMOTE.html",
            "relUrl": "/2022/02/19/DataAugmentation_vs_SMOTE.html",
            "date": " • Feb 19, 2022"
        }
        
    
  
    
        ,"post2": {
            "title": "Understand Latent Factors in Deep Tabular Augmentation",
            "content": "This blogpost should give an overview of how different amount of latent factors affects the data created by the Deep Tabular Augmenter. . This blogpost is basedon version 0.4.0 of deep_tabular_augmentation. Again, we use the credit-card fraud dataset from kaggle. . #!pip install deep_tabular_augmentation==0.4.0 . from config import * import pandas as pd import numpy as np import torch from torch import nn from torch import optim from sklearn.preprocessing import StandardScaler from functools import partial import mlprepare as mlp import deep_tabular_augmentation as dta import matplotlib.pyplot as plt . device = torch.device(&#39;cuda&#39; if torch.cuda.is_available() else &#39;cpu&#39;) DATA_PATH = &#39;data/creditcard.csv&#39; df = pd.read_csv(DATA_PATH, sep=&#39;,&#39;) df.head() . Time V1 V2 V3 V4 V5 V6 V7 V8 V9 ... V21 V22 V23 V24 V25 V26 V27 V28 Amount Class . 0 0.0 | -1.359807 | -0.072781 | 2.536347 | 1.378155 | -0.338321 | 0.462388 | 0.239599 | 0.098698 | 0.363787 | ... | -0.018307 | 0.277838 | -0.110474 | 0.066928 | 0.128539 | -0.189115 | 0.133558 | -0.021053 | 149.62 | 0 | . 1 0.0 | 1.191857 | 0.266151 | 0.166480 | 0.448154 | 0.060018 | -0.082361 | -0.078803 | 0.085102 | -0.255425 | ... | -0.225775 | -0.638672 | 0.101288 | -0.339846 | 0.167170 | 0.125895 | -0.008983 | 0.014724 | 2.69 | 0 | . 2 1.0 | -1.358354 | -1.340163 | 1.773209 | 0.379780 | -0.503198 | 1.800499 | 0.791461 | 0.247676 | -1.514654 | ... | 0.247998 | 0.771679 | 0.909412 | -0.689281 | -0.327642 | -0.139097 | -0.055353 | -0.059752 | 378.66 | 0 | . 3 1.0 | -0.966272 | -0.185226 | 1.792993 | -0.863291 | -0.010309 | 1.247203 | 0.237609 | 0.377436 | -1.387024 | ... | -0.108300 | 0.005274 | -0.190321 | -1.175575 | 0.647376 | -0.221929 | 0.062723 | 0.061458 | 123.50 | 0 | . 4 2.0 | -1.158233 | 0.877737 | 1.548718 | 0.403034 | -0.407193 | 0.095921 | 0.592941 | -0.270533 | 0.817739 | ... | -0.009431 | 0.798278 | -0.137458 | 0.141267 | -0.206010 | 0.502292 | 0.219422 | 0.215153 | 69.99 | 0 | . 5 rows × 31 columns . The deep_tabular_augmentation works on the simple idea, that we want to keep the data in a dedicated class (which we call the Learner) together with the model. The data has to come as a dataloader object, which I store in the DataBunch class. In it are the dataloaders for the training and test data. The runner class then defines the flow. . We first scale the data and only keep the data of the class we want to augment: . X_train, X_test, y_train, y_test = mlp.split_df(df, dep_var=&#39;Class&#39;, test_size=0.3, split_mode=&#39;random&#39;) x_scaler = StandardScaler() X_train_scaled = x_scaler.fit_transform(X_train) X_test_scaled = x_scaler.transform(X_test) X_train_fraud = X_train_scaled[np.where(y_train==1)[0]] X_test_fraud = X_test_scaled[np.where(y_test==1)[0]] . As mentioned, I then put the train and testloader into a class called DataBunch, which is just a container for the data. You can easily create your own dataloaders and put them in a DataBunch. . device = DEVICE datasets = dta.create_datasets(X_train_fraud, y_train.values[np.where(y_train==1)], X_test_fraud, y_test.values[np.where(y_test==1)]) data = dta.DataBunch(*dta.create_loaders(datasets, bs=1024)) . To make use of the deep_data_augmentation, we need to specify the input shape (so basically how many variables are in the dataset), the column name of the target-class we want to augment and the corresponding number, and lastly the column names of the input variables. . Then, wen can define whatever model architecture we would like to have. We just pass it as a list into the model. We can also define how many latent dimension we would like to add to our Autoencoder. As I want to compare the results of different latent factors, I will build four models only different in how many latent factors we set up. . Also, the model allows to control the variance you want to add per each column. If desired, you can add as many variance so that the variance of the real data matches the variance of the designed data. However, this is most of the time not desired, since this adds so much noise that the model will not support you as good as it can when it comes to predictions. I recommend using around 10%-25% of the real standard deviance of the data. . D_in = X_train_fraud.shape[1] VAE_arch = [50, 12, 12] target_name = &#39;Class&#39; target_class = 1 df_cols = list(df.columns) # take 10% of real standard deviation sigma = list(df[df[&#39;Class&#39;]==1][df_cols].std()*0.25) sched = dta.combine_scheds([0.3, 0.7], [dta.sched_cos(0.01, 0.1), dta.sched_cos(0.1, 0.01)]) cbfs = [partial(dta.LossTracker, show_every=500), dta.Recorder, partial(dta.ParamScheduler, &#39;lr&#39;, sched)] latent_factors = [1, 3, 5, 10, 20, 30] loss_func = dta.customLoss() models = [dta.Autoencoder(D_in, VAE_arch, latent_dim=i).to(device) for i in latent_factors] opts = [optim.Adam(models[i].parameters(), lr=0.01) for i in range(len(models))] learners = [dta.Learner(models[i], opts[i], loss_func, data, target_name, target_class, df_cols) for i in range(len(models))] runners = [dta.Runner(cb_funcs=cbfs) for i in range(len(models))] . Let&#39;s train all four models and predict fake data from each of them: . runners[0].fit(100, learners[0]) df_fake_with_noise_1l = runners[0].predict_with_noise_df(learners[0], no_samples=1000, mu=0, sigma=sigma, scaler=x_scaler) . epoch: 500 train loss is: 242759.03125 validation loss is: 98488.9609375 . runners[1].fit(100, learners[1]) df_fake_with_noise_3l = runners[1].predict_with_noise_df(learners[1], no_samples=1000, mu=0, sigma=sigma, scaler=x_scaler) . epoch: 500 train loss is: 242125.296875 validation loss is: 99636.6484375 . runners[2].fit(100, learners[2]) df_fake_with_noise_5l = runners[2].predict_with_noise_df(learners[2], no_samples=1000, mu=0, sigma=sigma, scaler=x_scaler) . epoch: 500 train loss is: 240940.15625 validation loss is: 98626.25 . runners[3].fit(100, learners[3]) df_fake_with_noise_10l = runners[3].predict_with_noise_df(learners[3], no_samples=1000, mu=0, sigma=sigma, scaler=x_scaler) . epoch: 500 train loss is: 242187.625 validation loss is: 97300.4609375 . runners[4].fit(100, learners[4]) df_fake_with_noise_20l = runners[4].predict_with_noise_df(learners[4], no_samples=1000, mu=0, sigma=sigma, scaler=x_scaler) . epoch: 500 train loss is: 242573.765625 validation loss is: 98810.9453125 . runners[5].fit(100, learners[5]) df_fake_with_noise_30l = runners[5].predict_with_noise_df(learners[5], no_samples=1000, mu=0, sigma=sigma, scaler=x_scaler) . epoch: 500 train loss is: 245696.984375 validation loss is: 99198.0546875 . fig, axs = plt.subplots(4, 2) # Defining custom &#39;xlim&#39; and &#39;ylim&#39; values. custom_xlim = (-30, 5) custom_ylim = (-40, 22) # Setting the values for all axes. plt.setp(axs, xlim=custom_xlim, ylim=custom_ylim) fig.set_size_inches(25.5, 17.5) axs[0, 0].scatter(df[df[&#39;Class&#39;]==0][&#39;V1&#39;].values, df[df[&#39;Class&#39;]==0][&#39;V2&#39;].values, alpha=0.5) axs[0, 0].set_title(&#39;V1 vs V2 for Class==0&#39;) axs[0, 1].scatter(df[df[&#39;Class&#39;]==1][&#39;V1&#39;].values, df[df[&#39;Class&#39;]==1][&#39;V2&#39;].values, alpha=0.5) axs[0, 1].set_title(&#39;V1 vs V2 for Class==1&#39;) axs[1, 0].scatter(df_fake_with_noise_1l[&#39;V1&#39;].values, df_fake_with_noise_1l[&#39;V2&#39;].values, alpha=0.5) axs[1, 0].set_title(&#39;Fake Data with latent_factors=1&#39;) axs[1, 1].scatter(df_fake_with_noise_3l[&#39;V1&#39;].values, df_fake_with_noise_3l[&#39;V2&#39;].values, alpha=0.5) axs[1, 1].set_title(&#39;Fake Data with latent_factors=3&#39;) axs[2, 0].scatter(df_fake_with_noise_5l[&#39;V1&#39;].values, df_fake_with_noise_5l[&#39;V2&#39;].values, alpha=0.5) axs[2, 0].set_title(&#39;Fake Data with latent_factors=5&#39;) axs[2, 1].scatter(df_fake_with_noise_10l[&#39;V1&#39;].values, df_fake_with_noise_10l[&#39;V2&#39;].values, alpha=0.5) axs[2, 1].set_title(&#39;Fake Data with latent_factors=10&#39;) axs[3, 0].scatter(df_fake_with_noise_20l[&#39;V1&#39;].values, df_fake_with_noise_20l[&#39;V2&#39;].values, alpha=0.5) axs[3, 0].set_title(&#39;Fake Data with latent_factors=20&#39;) axs[3, 1].scatter(df_fake_with_noise_30l[&#39;V1&#39;].values, df_fake_with_noise_30l[&#39;V2&#39;].values, alpha=0.5) axs[3, 1].set_title(&#39;Fake Data with latent_factors=30&#39;) ; . &#39;&#39; . fig, axs = plt.subplots(4, 2) # Defining custom &#39;xlim&#39; and &#39;ylim&#39; values. custom_xlim = (-60, 20) custom_ylim = (-40, 10) # Setting the values for all axes. plt.setp(axs, xlim=custom_xlim, ylim=custom_ylim) fig.set_size_inches(25.5, 17.5) axs[0, 0].scatter(df[df[&#39;Class&#39;]==0][&#39;V2&#39;].values, df[df[&#39;Class&#39;]==0][&#39;V3&#39;].values, alpha=0.5) axs[0, 0].set_title(&#39;V2 vs V3 for Class==0&#39;) axs[0, 1].scatter(df[df[&#39;Class&#39;]==1][&#39;V2&#39;].values, df[df[&#39;Class&#39;]==1][&#39;V3&#39;].values, alpha=0.5) axs[0, 1].set_title(&#39;V2 vs V3 for Class==1&#39;) axs[1, 0].scatter(df_fake_with_noise_1l[&#39;V2&#39;].values, df_fake_with_noise_1l[&#39;V3&#39;].values, alpha=0.5) axs[1, 0].set_title(&#39;Fake Data with latent_factors=1&#39;) axs[1, 1].scatter(df_fake_with_noise_3l[&#39;V2&#39;].values, df_fake_with_noise_3l[&#39;V3&#39;].values, alpha=0.5) axs[1, 1].set_title(&#39;Fake Data with latent_factors=3&#39;) axs[2, 0].scatter(df_fake_with_noise_5l[&#39;V2&#39;].values, df_fake_with_noise_5l[&#39;V3&#39;].values, alpha=0.5) axs[2, 0].set_title(&#39;Fake Data with latent_factors=5&#39;) axs[2, 1].scatter(df_fake_with_noise_10l[&#39;V2&#39;].values, df_fake_with_noise_10l[&#39;V3&#39;].values, alpha=0.5) axs[2, 1].set_title(&#39;Fake Data with latent_factors=10&#39;) axs[3, 0].scatter(df_fake_with_noise_20l[&#39;V2&#39;].values, df_fake_with_noise_20l[&#39;V3&#39;].values, alpha=0.5) axs[3, 0].set_title(&#39;Fake Data with latent_factors=20&#39;) axs[3, 1].scatter(df_fake_with_noise_30l[&#39;V2&#39;].values, df_fake_with_noise_30l[&#39;V3&#39;].values, alpha=0.5) axs[3, 1].set_title(&#39;Fake Data with latent_factors=30&#39;) ; . &#39;&#39; . fig, axs = plt.subplots(4, 2) # Defining custom &#39;xlim&#39; and &#39;ylim&#39; values. custom_xlim = (-15, 25) custom_ylim = (-20, 40) # Setting the values for all axes. plt.setp(axs, xlim=custom_xlim, ylim=custom_ylim) fig.set_size_inches(25.5, 17.5) axs[0, 0].scatter(df[df[&#39;Class&#39;]==0][&#39;V10&#39;].values, df[df[&#39;Class&#39;]==0][&#39;V6&#39;].values, alpha=0.5) axs[0, 0].set_title(&#39;V10 vs V6 for Class==0&#39;) axs[0, 1].scatter(df[df[&#39;Class&#39;]==1][&#39;V10&#39;].values, df[df[&#39;Class&#39;]==1][&#39;V6&#39;].values, alpha=0.5) axs[0, 1].set_title(&#39;V10 vs V6 for Class==1&#39;) axs[1, 0].scatter(df_fake_with_noise_1l[&#39;V10&#39;].values, df_fake_with_noise_1l[&#39;V6&#39;].values, alpha=0.5) axs[1, 0].set_title(&#39;Fake Data with latent_factors=1&#39;) axs[1, 1].scatter(df_fake_with_noise_3l[&#39;V10&#39;].values, df_fake_with_noise_3l[&#39;V6&#39;].values, alpha=0.5) axs[1, 1].set_title(&#39;Fake Data with latent_factors=3&#39;) axs[2, 0].scatter(df_fake_with_noise_5l[&#39;V10&#39;].values, df_fake_with_noise_5l[&#39;V6&#39;].values, alpha=0.5) axs[2, 0].set_title(&#39;Fake Data with latent_factors=5&#39;) axs[2, 1].scatter(df_fake_with_noise_10l[&#39;V10&#39;].values, df_fake_with_noise_10l[&#39;V6&#39;].values, alpha=0.5) axs[2, 1].set_title(&#39;Fake Data with latent_factors=10&#39;) axs[3, 0].scatter(df_fake_with_noise_20l[&#39;V10&#39;].values, df_fake_with_noise_20l[&#39;V6&#39;].values, alpha=0.5) axs[3, 0].set_title(&#39;Fake Data with latent_factors=20&#39;) axs[3, 1].scatter(df_fake_with_noise_30l[&#39;V10&#39;].values, df_fake_with_noise_30l[&#39;V6&#39;].values, alpha=0.5) axs[3, 1].set_title(&#39;Fake Data with latent_factors=30&#39;) ; . &#39;&#39; . These results look really promising. Also, it seems like when comparing 2 variables it does not really matter how many latent factors you choose although 30 latent factors seem to provide the most compelling results. What if we have a look at 3 different variables: . fig = plt.figure(figsize=(12, 12)) ax = fig.add_subplot(projection=&#39;3d&#39;) ax.scatter(df[df[&#39;Class&#39;]==0][&#39;V1&#39;].values, df[df[&#39;Class&#39;]==0][&#39;V2&#39;].values, df[df[&#39;Class&#39;]==0][&#39;V3&#39;].values) ax.set_title(&#39;V1 vs V2 vs V3 for Class==0&#39;) plt.show() . fig = plt.figure(figsize=(12, 12)) ax = fig.add_subplot(projection=&#39;3d&#39;) ax.scatter(df[df[&#39;Class&#39;]==1][&#39;V1&#39;].values, df[df[&#39;Class&#39;]==1][&#39;V2&#39;].values, df[df[&#39;Class&#39;]==1][&#39;V3&#39;].values) ax.set_title(&#39;V1 vs V2 vs V3 for Class==1&#39;) plt.show() . fig = plt.figure(figsize=(12, 12)) ax = fig.add_subplot(projection=&#39;3d&#39;) ax.scatter(df_fake_with_noise_1l[&#39;V1&#39;].values, df_fake_with_noise_1l[&#39;V2&#39;].values, df_fake_with_noise_1l[&#39;V3&#39;].values) ax.set_title(&#39;V1 vs V2 vs V3 for latent factors=1&#39;) plt.show() . fig = plt.figure(figsize=(12, 12)) ax = fig.add_subplot(projection=&#39;3d&#39;) ax.scatter(df_fake_with_noise_10l[&#39;V1&#39;].values, df_fake_with_noise_10l[&#39;V2&#39;].values, df_fake_with_noise_10l[&#39;V3&#39;].values) ax.set_title(&#39;V1 vs V2 vs V3 for latent factors=10&#39;) plt.show() . fig = plt.figure(figsize=(12, 12)) ax = fig.add_subplot(projection=&#39;3d&#39;) ax.scatter(df_fake_with_noise_30l[&#39;V1&#39;].values, df_fake_with_noise_30l[&#39;V2&#39;].values, df_fake_with_noise_30l[&#39;V3&#39;].values) ax.set_title(&#39;V1 vs V2 vs V3 for latent factors=30&#39;) plt.show() . When comparing the 3d plots it becomes more clearly that fewer latent factors seem to further split the data apart. The more latent factors the better it seems the relations between the variables can be better captured. . If you have any questions or want anything added to the package, just ask me. . Lasse .",
            "url": "https://lschmiddey.github.io/fastpages_/2022/02/06/Understand-Latent-Factors.html",
            "relUrl": "/2022/02/06/Understand-Latent-Factors.html",
            "date": " • Feb 6, 2022"
        }
        
    
  
    
        ,"post3": {
            "title": "Comparison - RandomForest with Oversampling vs Augmented Data",
            "content": "In this blog I&#39;d like to show the difference deep tabular augmentation can have when training a Random Forest on a highly biased data base. In this case, we have a look at credit card fraud, where fraud itself is is way less represented than non-fraud. . import pandas as pd import numpy as np import torch from torch import nn from torch import optim from sklearn.preprocessing import StandardScaler from functools import partial import mlprepare as mlp import deep_tabular_augmentation as dta from sklearn.model_selection import train_test_split from sklearn.ensemble import RandomForestClassifier from sklearn.metrics import confusion_matrix . device = torch.device(&#39;cuda&#39; if torch.cuda.is_available() else &#39;cpu&#39;) DATA_PATH = &#39;data/creditcard.csv&#39; df = pd.read_csv(DATA_PATH) . Let&#39;s have a short look at the data: . df.head() . Time V1 V2 V3 V4 V5 V6 V7 V8 V9 ... V21 V22 V23 V24 V25 V26 V27 V28 Amount Class . 0 0.0 | -1.359807 | -0.072781 | 2.536347 | 1.378155 | -0.338321 | 0.462388 | 0.239599 | 0.098698 | 0.363787 | ... | -0.018307 | 0.277838 | -0.110474 | 0.066928 | 0.128539 | -0.189115 | 0.133558 | -0.021053 | 149.62 | 0 | . 1 0.0 | 1.191857 | 0.266151 | 0.166480 | 0.448154 | 0.060018 | -0.082361 | -0.078803 | 0.085102 | -0.255425 | ... | -0.225775 | -0.638672 | 0.101288 | -0.339846 | 0.167170 | 0.125895 | -0.008983 | 0.014724 | 2.69 | 0 | . 2 1.0 | -1.358354 | -1.340163 | 1.773209 | 0.379780 | -0.503198 | 1.800499 | 0.791461 | 0.247676 | -1.514654 | ... | 0.247998 | 0.771679 | 0.909412 | -0.689281 | -0.327642 | -0.139097 | -0.055353 | -0.059752 | 378.66 | 0 | . 3 1.0 | -0.966272 | -0.185226 | 1.792993 | -0.863291 | -0.010309 | 1.247203 | 0.237609 | 0.377436 | -1.387024 | ... | -0.108300 | 0.005274 | -0.190321 | -1.175575 | 0.647376 | -0.221929 | 0.062723 | 0.061458 | 123.50 | 0 | . 4 2.0 | -1.158233 | 0.877737 | 1.548718 | 0.403034 | -0.407193 | 0.095921 | 0.592941 | -0.270533 | 0.817739 | ... | -0.009431 | 0.798278 | -0.137458 | 0.141267 | -0.206010 | 0.502292 | 0.219422 | 0.215153 | 69.99 | 0 | . 5 rows × 31 columns . Also, let&#39;s have a look of how many more non-frauf cases we have compared to fraud cases: . difference_in_class_occurences = df[&#39;Class&#39;].value_counts()[0]-df[&#39;Class&#39;].value_counts()[1] difference_in_class_occurences . 283823 . In order to make use of the deep tabular augmentation we need to scale the data and then use only those cases, in which class we are interested in, in this case &quot;Class&quot; is equal to 1. . X_train, X_test, y_train, y_test = mlp.split_df(df, dep_var=&#39;Class&#39;, test_size=0.3, split_mode=&#39;random&#39;) x_scaler = StandardScaler() X_train_scaled = x_scaler.fit_transform(X_train) X_test_scaled = x_scaler.transform(X_test) X_train_fraud = X_train_scaled[np.where(y_train==1)[0]] X_test_fraud = X_test_scaled[np.where(y_test==1)[0]] . For our model to work we need to put our data in a DataLoader (here I use the DataBunch Class from deep data augmentation). . datasets = dta.create_datasets(X_train_fraud, y_train.values[np.where(y_train==1)], X_test_fraud, y_test.values[np.where(y_test==1)]) data = dta.DataBunch(*dta.create_loaders(datasets, bs=1024)) . Now we&#39;re already good to go. We can define our Variational Encoder Architecture (here: 50 - 12 - 12 - 5 - 12 - 12 - 50) and then use the LearningRate Finder to tell us the best Learning rate: . D_in = X_train_fraud.shape[1] target_name = &#39;Class&#39; target_class = 1 df_cols = list(df.columns) model = dta.Autoencoder(nn.Sequential(*dta.get_lin_layers(D_in, [50, 12, 12])), nn.Sequential(*dta.get_lin_layers_rev(D_in, [50, 12, 12])), latent_dim=5).to(device) opt = optim.Adam(model.parameters(), lr=0.01) loss_func = dta.customLoss() . learn = dta.Learner(model, opt, loss_func, data, target_name, target_class, df_cols) run = dta.Runner(cb_funcs=[dta.LR_Find, dta.Recorder]) run.fit(100, learn) . run.recorder.plot(skip_last=5) . We set up a desirable learning rate and scheduler for our learning rate: . sched = dta.combine_scheds([0.3, 0.7], [dta.sched_cos(0.01, 0.1), dta.sched_cos(0.1, 0.01)]) . Now, let&#39;s train the model: . cbfs = [partial(dta.LossTracker, show_every=50), dta.Recorder, partial(dta.ParamScheduler, &#39;lr&#39;, sched)] model = dta.Autoencoder(nn.Sequential(*dta.get_lin_layers(D_in, [50, 12, 12])), nn.Sequential(*dta.get_lin_layers_rev(D_in, [50, 12, 12])), latent_dim=5).to(device) opt = optim.Adam(model.parameters(), lr=0.01) learn = dta.Learner(model, opt, loss_func, data, target_name, target_class, df_cols) run = dta.Runner(cb_funcs=cbfs) run.fit(400, learn) . epoch: 50 train loss is: 250777.15625 validation loss is: 89807.21875 epoch: 100 train loss is: 184203.078125 validation loss is: 71237.8828125 epoch: 150 train loss is: 129945.9765625 validation loss is: 81472.5078125 epoch: 200 train loss is: 95360.5859375 validation loss is: 260343.4375 epoch: 250 train loss is: 75559.625 validation loss is: 208241.1875 epoch: 300 train loss is: 63336.73828125 validation loss is: 168084.046875 epoch: 350 train loss is: 55019.421875 validation loss is: 141231.15625 epoch: 400 train loss is: 48957.48046875 validation loss is: 121973.09375 . Let&#39;s see how the created data looks like: . df_fake = run.predict_df(learn, no_samples=difference_in_class_occurences, scaler=x_scaler) df_fake_with_noise = run.predict_with_noise_df(learn, no_samples=difference_in_class_occurences, mu=0, sigma=0.1, scaler=x_scaler) df_fake_with_noise.head() . Time V1 V2 V3 V4 V5 V6 V7 V8 V9 ... V21 V22 V23 V24 V25 V26 V27 V28 Amount Class . 0 107547.656250 | -1.175546 | 3.190463 | -5.880084 | 5.172310 | -0.201045 | -2.110816 | -2.554305 | 0.789000 | -2.931453 | ... | 0.680436 | -0.063858 | 0.295163 | -0.333722 | 0.318315 | 0.305315 | 0.570651 | 0.418477 | 59.745529 | 1 | . 1 105570.804688 | -1.411785 | 2.465464 | -4.638255 | 3.691925 | -1.264926 | -1.476137 | -2.528746 | 0.799087 | -2.038979 | ... | 0.874525 | 0.115001 | 0.530135 | -0.186685 | 0.258670 | 0.213698 | 0.545221 | 0.412415 | 103.826714 | 1 | . 2 104763.757812 | -1.315135 | 2.079836 | -3.970082 | 2.974885 | -1.478414 | -1.190014 | -2.352298 | 0.718098 | -1.687526 | ... | 0.794227 | 0.149139 | 0.566353 | -0.152397 | 0.244498 | 0.140893 | 0.520099 | 0.307183 | 114.956940 | 1 | . 3 106964.625000 | -1.133216 | 2.987270 | -5.564784 | 4.863543 | -0.300885 | -1.990756 | -2.479523 | 0.771097 | -2.773068 | ... | 0.650077 | -0.045114 | 0.288558 | -0.310352 | 0.305301 | 0.276039 | 0.575313 | 0.383283 | 70.325348 | 1 | . 4 105466.343750 | -1.274740 | 2.423632 | -4.584245 | 3.720120 | -1.073872 | -1.501573 | -2.430743 | 0.760877 | -2.088018 | ... | 0.771964 | 0.084755 | 0.460291 | -0.201218 | 0.260977 | 0.201086 | 0.546640 | 0.366659 | 101.931236 | 1 | . 5 rows × 31 columns . df_fake_with_noise.describe().loc[[&#39;mean&#39;]] . Time V1 V2 V3 V4 V5 V6 V7 V8 V9 ... V21 V22 V23 V24 V25 V26 V27 V28 Amount Class . mean 105288.890625 | -1.479125 | 2.557713 | -4.819775 | 3.855684 | -1.171547 | -1.542699 | -2.576222 | 0.791697 | -2.12214 | ... | 0.860909 | 0.103987 | 0.481285 | -0.208098 | 0.249638 | 0.217605 | 0.525674 | 0.399994 | 99.816528 | 1.0 | . 1 rows × 31 columns . Train Random Forest . We want to compare how the built-in class_weight functionality performs vs the new approach (spoiler: if you do not use any weights the RandomForest will always predict 0). Hence, we create three dataframes: the original, the original appended with fake_data, the original appended with fake data with noise. . train_df, test_df = train_test_split(df, test_size=0.3, random_state=42) train_df_fake = pd.concat([train_df, df_fake]) train_df_fake_with_noise = pd.concat([train_df, df_fake_with_noise]) . To make things easier to understand, let&#39;s define the datasets on which to train and on which to assess the results: . X_train, X_test, X_train_aug = train_df.iloc[:,:30].values, test_df.iloc[:,:30].values, train_df_fake_with_noise.iloc[:,:30].values y_train, y_test, y_train_aug = train_df.iloc[:,30].values, test_df.iloc[:,30].values, train_df_fake_with_noise.iloc[:,30].values . First, let&#39;s train model on the original data while using the differences in class occurences as weights. . def rf(xs, y, n_estimators=40, max_samples=500, max_features=0.5, min_samples_leaf=5, **kwargs): return RandomForestClassifier(n_jobs=-1, n_estimators=n_estimators, max_samples=max_samples, max_features=max_features, min_samples_leaf=min_samples_leaf, oob_score=True, class_weight={0:1,1:difference_in_class_occurences}).fit(xs, y) . m = rf(X_train, y_train) confusion_matrix(y_test, np.round(m.predict(X_test))) . array([[85300, 7], [ 99, 37]]) . Then, we use the augmented dataframe: . def rf_aug(xs, y, n_estimators=40, max_samples=500, max_features=0.5, min_samples_leaf=5, **kwargs): return RandomForestClassifier(n_jobs=-1, n_estimators=n_estimators, max_samples=max_samples, max_features=max_features, min_samples_leaf=min_samples_leaf, oob_score=True).fit(xs, y) . m_aug = rf_aug(X_train_aug, y_train_aug) confusion_matrix(test_df.iloc[:,30].values, np.round(m_aug.predict(test_df.iloc[:,:30].values))) . array([[85288, 19], [ 46, 90]]) . Wow, I think that is quite astonishing. We managed to highly increase the number of fraud cases we are able to detect. Moreover, we achieved these results without any finetuning of the model architecture and simply using the default structure of the VAE. . I hope this blog shed some light on why using this approach on highly biased data is worth a shot trying. . Lasse .",
            "url": "https://lschmiddey.github.io/fastpages_/2022/01/24/Comparison-RandomForest-with-Oversampling-vs-Augmented-Data.html",
            "relUrl": "/2022/01/24/Comparison-RandomForest-with-Oversampling-vs-Augmented-Data.html",
            "date": " • Jan 24, 2022"
        }
        
    
  
    
        ,"post4": {
            "title": "How to use deep_tabular_augmentation",
            "content": "The main idea of why and how to use Deep Learning to create data augmentation on tabular data is decribed in my previous blogpost on this topic. Since then quite some time has passed and I decided to rewrite the Code so it is easier to use. In this blogpost I want to show you how to use the new approach, how flexible it is regarding the model you want to use and how you can use your own custom Callbacks to better see what the model does in the background. Some of these features I already built-in and here&#39;s how to use them. . Again, we use the credit-card fraud dataset from kaggle. . from config import * import pandas as pd import numpy as np import torch from torch import nn from torch import optim from sklearn.preprocessing import StandardScaler from functools import partial import mlprepare as mlp import deep_tabular_augmentation as dta . device = torch.device(&#39;cuda&#39; if torch.cuda.is_available() else &#39;cpu&#39;) DATA_PATH = &#39;data/creditcard.csv&#39; df = pd.read_csv(DATA_PATH, sep=&#39;,&#39;) df.head() . Time V1 V2 V3 V4 V5 V6 V7 V8 V9 ... V21 V22 V23 V24 V25 V26 V27 V28 Amount Class . 0 0.0 | -1.359807 | -0.072781 | 2.536347 | 1.378155 | -0.338321 | 0.462388 | 0.239599 | 0.098698 | 0.363787 | ... | -0.018307 | 0.277838 | -0.110474 | 0.066928 | 0.128539 | -0.189115 | 0.133558 | -0.021053 | 149.62 | 0 | . 1 0.0 | 1.191857 | 0.266151 | 0.166480 | 0.448154 | 0.060018 | -0.082361 | -0.078803 | 0.085102 | -0.255425 | ... | -0.225775 | -0.638672 | 0.101288 | -0.339846 | 0.167170 | 0.125895 | -0.008983 | 0.014724 | 2.69 | 0 | . 2 1.0 | -1.358354 | -1.340163 | 1.773209 | 0.379780 | -0.503198 | 1.800499 | 0.791461 | 0.247676 | -1.514654 | ... | 0.247998 | 0.771679 | 0.909412 | -0.689281 | -0.327642 | -0.139097 | -0.055353 | -0.059752 | 378.66 | 0 | . 3 1.0 | -0.966272 | -0.185226 | 1.792993 | -0.863291 | -0.010309 | 1.247203 | 0.237609 | 0.377436 | -1.387024 | ... | -0.108300 | 0.005274 | -0.190321 | -1.175575 | 0.647376 | -0.221929 | 0.062723 | 0.061458 | 123.50 | 0 | . 4 2.0 | -1.158233 | 0.877737 | 1.548718 | 0.403034 | -0.407193 | 0.095921 | 0.592941 | -0.270533 | 0.817739 | ... | -0.009431 | 0.798278 | -0.137458 | 0.141267 | -0.206010 | 0.502292 | 0.219422 | 0.215153 | 69.99 | 0 | . 5 rows × 31 columns . The deep_tabular_augmentation works on the simple idea, that we want to keep the data in a dedicated class (which we call the Learner) together with the model. The data has to come as a dataloader object, which I store in the DataBunch class. In it are the dataloaders for the training and test data. The runner class then defines the flow. . We first scale the data and only keep the data of the class we want to augment: . X_train, X_test, y_train, y_test = mlp.split_df(df, dep_var=&#39;Class&#39;, test_size=0.3, split_mode=&#39;random&#39;) x_scaler = StandardScaler() X_train_scaled = x_scaler.fit_transform(X_train) X_test_scaled = x_scaler.transform(X_test) X_train_fraud = X_train_scaled[np.where(y_train==1)[0]] X_test_fraud = X_test_scaled[np.where(y_test==1)[0]] . As mentioned, I then put the train and testloader into a class called DataBunch, which is just a container for the data. You can easily create your own dataloaders and put them in a DataBunch. . device = DEVICE datasets = dta.create_datasets(X_train_fraud, y_train.values[np.where(y_train==1)], X_test_fraud, y_test.values[np.where(y_test==1)]) data = dta.DataBunch(*dta.create_loaders(datasets, bs=1024)) . To make use of the deep_data_augmentation, we need to specify the input shape (so basically how many variables are in the dataset), the column name of the target-class we want to augment and the corresponding number, and lastly the column names of the input variables. . Then, wen can define whatever model architecture we would like to have. We just pass it as a list into the model. We can also define how many latent dimension we would like to add to our Autoencoder. . D_in = X_train_fraud.shape[1] target_name = &#39;Class&#39; target_class = 1 df_cols = list(df.columns) model = dta.Autoencoder(nn.Sequential(*dta.get_lin_layers(D_in, [50, 12, 12])), nn.Sequential(*dta.get_lin_layers_rev(D_in, [50, 12, 12])), latent_dim=5).to(device) opt = optim.Adam(model.parameters(), lr=0.01) loss_func = dta.customLoss() . We put all these information within the Learner class. This is where we keep everything attached to the data and model: . learn = dta.Learner(model, opt, loss_func, data, target_name, target_class, df_cols) . The runner class then provides us with the flow of the data and also let&#39;s you add Callbacks. One of the built-in Classbacks is a Learning Rate Finder, and this is how you can use it: . run = dta.Runner(cb_funcs=[dta.LR_Find, dta.Recorder]) run.fit(100, learn) . run.recorder.plot(skip_last=5) . We can also use the callbacks to create a learning rate scheduler. Here is an example: use 30% of the budget to go from 0.01 to 0.1 following a cosine, then the last 70% of the budget to go from 0.1 to 0.01, still following a cosine. . sched = dta.combine_scheds([0.3, 0.7], [dta.sched_cos(0.01, 0.05), dta.sched_cos(0.05, 0.01)]) . Now we can train our Autoencoder. We want to keep track of the loss, we want to be able to do some loss plotting and we want to add our learning-rate scheduling: . cbfs = [partial(dta.LossTracker, show_every=200), dta.Recorder, partial(dta.ParamScheduler, &#39;lr&#39;, sched)] model = dta.Autoencoder(nn.Sequential(*dta.get_lin_layers(D_in, [50, 12, 12])), nn.Sequential(*dta.get_lin_layers_rev(D_in, [50, 12, 12])), latent_dim=5).to(device) opt = optim.Adam(model.parameters(), lr=0.01) learn = dta.Learner(model, opt, loss_func, data, target_name, target_class, df_cols) run = dta.Runner(cb_funcs=cbfs) run.fit(1000, learn) . epoch: 200 train loss is: 225114.875 validation loss is: 115246.5859375 epoch: 400 train loss is: 106772.5546875 validation loss is: 63919.203125 epoch: 600 train loss is: 61763.24609375 validation loss is: 43108.23046875 epoch: 800 train loss is: 44581.90625 validation loss is: 33015.5390625 epoch: 1000 train loss is: 35748.265625 validation loss is: 27532.025390625 . We can have a look at the training loss: . run.recorder.plot_loss() . And the learnig rate over the epochs: . run.recorder.plot_lr() . You can create any kind of Callbacks you want and pass them to the training. Within the runner I created some hooks after which you can directly link your Callback, for example begin_batch, begin_epoch, after_pred, after_fit and quite a few more. When you create your Callback you can directly refer to these to pinpoint where your Callback should do specific tasks. This is how the LossTracker looks like: . class LossTracker(dta.Callback): def __init__(self, show_every): self.show_every = show_every def begin_fit(self): self.train_losses = [] self.val_losses = [] def after_batch(self): if self.in_train: self.train_losses.append(self.loss.detach().cpu()) else: self.val_losses.append(self.loss.detach().cpu()) def after_epoch(self): if self.run.epoch % self.show_every==0: print(f&#39;epoch: {self.run.epoch + self.show_every}&#39;) print(f&#39;train loss is: {sum(self.train_losses)/len(self.train_losses)}&#39;) print(f&#39;validation loss is: {sum(self.val_losses)/len(self.val_losses)}&#39;) . When beginning the training, I start with an empty list, and after each batch I add the loss. After each epoch then I print the loss. . Moreover, the runner also provides you with the possibility to create augmented data by the trained model. You can specify how many samples of the specified class you want, and you can also add some noise to it, which I found to create better input for later use. . df_fake = run.predict_df(learn, no_samples=10000, scaler=x_scaler) df_fake_with_noise = run.predict_with_noise_df(learn, no_samples=10000, mu=0, sigma=0.1, scaler=x_scaler) df_fake.describe().loc[[&#39;mean&#39;]] . Time V1 V2 V3 V4 V5 V6 V7 V8 V9 ... V21 V22 V23 V24 V25 V26 V27 V28 Amount Class . mean 84246.492188 | -3.907873 | 3.267383 | -3.435851 | 4.335964 | -2.274521 | 1.734463 | -8.014628 | -10.251186 | -1.38874 | ... | -4.401209 | 2.359375 | 0.597872 | -0.423079 | -0.59408 | -0.067904 | 0.246678 | 0.08693 | 82.072906 | 1.0 | . 1 rows × 31 columns . df[df[&#39;Class&#39;]==1].groupby(&#39;Class&#39;).describe().loc[:,(slice(None),[&#39;mean&#39;])] . Time V1 V2 V3 V4 V5 V6 V7 V8 V9 ... V20 V21 V22 V23 V24 V25 V26 V27 V28 Amount . mean mean mean mean mean mean mean mean mean mean ... mean mean mean mean mean mean mean mean mean mean . Class . 1 80746.806911 | -4.771948 | 3.623778 | -7.033281 | 4.542029 | -3.151225 | -1.397737 | -5.568731 | 0.570636 | -2.581123 | ... | 0.372319 | 0.713588 | 0.014049 | -0.040308 | -0.10513 | 0.041449 | 0.051648 | 0.170575 | 0.075667 | 122.211321 | . 1 rows × 30 columns . df[df[&#39;Class&#39;]==0].groupby(&#39;Class&#39;).describe().loc[:,(slice(None),[&#39;mean&#39;])] . Time V1 V2 V3 V4 V5 V6 V7 V8 V9 ... V20 V21 V22 V23 V24 V25 V26 V27 V28 Amount . mean mean mean mean mean mean mean mean mean mean ... mean mean mean mean mean mean mean mean mean mean . Class . 0 94838.202258 | 0.008258 | -0.006271 | 0.012171 | -0.00786 | 0.005453 | 0.002419 | 0.009637 | -0.000987 | 0.004467 | ... | -0.000644 | -0.001235 | -0.000024 | 0.00007 | 0.000182 | -0.000072 | -0.000089 | -0.000295 | -0.000131 | 88.291022 | . 1 rows × 30 columns . Let&#39;s see how our model does when it comes to replicating the fraud cases. First we plot V1 against V2 on the non-fraud cases, then we do the same for the fraud cases: . import matplotlib.pyplot as plt plt.scatter(df[df[&#39;Class&#39;]==0][&#39;V1&#39;].values, df[df[&#39;Class&#39;]==0][&#39;V2&#39;].values, alpha=0.5) plt.show() . plt.scatter(df[df[&#39;Class&#39;]==1][&#39;V1&#39;].values, df[df[&#39;Class&#39;]==1][&#39;V2&#39;].values, alpha=0.5) plt.show() . They look quite different. Let&#39;s see how our fake data does: . plt.scatter(df_fake[&#39;V1&#39;].values, df_fake[&#39;V2&#39;].values, alpha=0.5) plt.show() . plt.scatter(df_fake_with_noise[&#39;V1&#39;].values, df_fake_with_noise[&#39;V2&#39;].values, alpha=0.5) plt.show() . This looks actually quite amazing. If you have any questions or want anything added to the package, just ask me. . Lasse .",
            "url": "https://lschmiddey.github.io/fastpages_/2021/11/07/DeepLearning_TabularDataAugmentation_Refactored.html",
            "relUrl": "/2021/11/07/DeepLearning_TabularDataAugmentation_Refactored.html",
            "date": " • Nov 7, 2021"
        }
        
    
  
    
        ,"post5": {
            "title": "How to use Software Engineering to improve Data Science Code",
            "content": "Why Data Science has to stop producing Spaghetti Code . As a common Data Scientist, I know the pain. Usually, what we do is pretty straight forward processwise, but somehow this almost always end up with a code that has become so complex, it&#39;s hard to keep track. Moreover, most Data Scientist do not really care about Software Engineering and use functions and classes all over the place, without any proper thinking about it first. Admittedly, I also did code like that. . For some time now I wanted to change this. After reading some books and articles about Software Engineering and watching a ton of YouTube tutorials on it (thanks so much internet!) I came up with a few ideas how every Data Scientist can and should improve her code. Let&#39;s start with the basic design pattern I found helpful for each of my Data Science projects. . The Information Expert Principle . This principle is pretty straightforward, but when applying it from the start of your project it will help you a lot writing cleaner and more beautiful code. It means that the design of your software (which, in the end, is what we are writing) should follow the data pipeline. What does this mean in action? Let me give you a brief example: . from common import * import numpy as np class BaseData(): def __init__(self): pass def load_data(self, data_path:str): self.df_train = pd.read_csv(f&#39;{data_path}/ItalyPowerDemand_TRAIN.txt&#39;, header=None,delim_whitespace=True) self.df_test = pd.read_csv(f&#39;{data_path}/ItalyPowerDemand_TEST.txt&#39;, header=None, delim_whitespace=True) def make_fake_cat_vars(self): &quot;&quot;&quot;Takes dataframe as input and transforms data&quot;&quot;&quot; # let&#39;s add a categorical variable countries = [&#39;Germany&#39;, &#39;US&#39;] household_income = [&#39;low&#39;, &#39;high&#39;] self.df_train[&quot;country&quot;] = np.random.choice(countries, len(self.df_train)) self.df_test[&quot;country&quot;] = np.random.choice(countries, len(self.df_test)) self.df_train[&quot;household_income&quot;] = np.random.choice(household_income, len(self.df_train)) self.df_test[&quot;household_income&quot;] = np.random.choice(household_income, len(self.df_test)) def transform_data(self): self.x_train = self.df_train.iloc[:, 1:-2].values.reshape(-1, 1, 24) self.x_test = self.df_test.iloc[:, 1:-2].values.reshape(-1, 1, 24) self.y_train = self.df_train.iloc[:, 0].values-1 self.y_test = self.df_test.iloc[:, 0].values-1 self.emb_vars_train = self.df_train.iloc[:, -2:].values self.emb_vars_test = self.df_test.iloc[:, -2:].values def categorize_variables(self): self.emb_vars_train, self.emb_vars_test, self.dict_embs, self.dict_inv_embs = cat_transform(self.emb_vars_train, self.emb_vars_test) . base_data = BaseData() base_data.load_data(&#39;data&#39;) base_data.make_fake_cat_vars() base_data.transform_data() base_data.categorize_variables() . base_data.df_train.head() . 0 1 2 3 4 5 6 7 8 9 ... 17 18 19 20 21 22 23 24 country household_income . 0 1.0 | -0.710518 | -1.183320 | -1.372442 | -1.593083 | -1.467002 | -1.372442 | -1.088760 | 0.045967 | 0.928532 | ... | -0.206195 | 0.613330 | 1.369815 | 1.464375 | 1.054613 | 0.581810 | 0.172048 | -0.269235 | Germany | low | . 1 1.0 | -0.993009 | -1.426786 | -1.579884 | -1.605401 | -1.630917 | -1.375754 | -1.018526 | -0.355102 | 0.716583 | ... | 0.614518 | 0.308322 | 0.257289 | 1.099327 | 1.048295 | 0.691066 | -0.048906 | -0.380618 | Germany | high | . 2 2.0 | 1.319067 | 0.569774 | 0.195128 | -0.085856 | -0.179518 | -0.273180 | -0.085856 | -1.397118 | -1.116134 | ... | -0.741487 | -0.741487 | -1.116134 | -0.460503 | 0.476113 | 2.349344 | 2.255682 | 1.600052 | Germany | low | . 3 2.0 | -0.812444 | -1.157553 | -1.416385 | -1.531421 | -1.502662 | -1.416385 | -1.646458 | -0.467335 | 0.654269 | ... | 0.884342 | 0.683028 | 0.625510 | 0.424197 | -0.007190 | -0.035949 | 0.107847 | -0.266022 | Germany | low | . 4 1.0 | -0.972840 | -1.390518 | -1.536705 | -1.620240 | -1.620240 | -1.453169 | -0.993724 | 0.050469 | 0.635218 | ... | 0.614334 | 1.303502 | 1.240850 | 1.073779 | 0.551682 | 0.426379 | -0.179253 | -0.638698 | Germany | low | . 5 rows × 27 columns . base_data.dict_embs . [{0: &#39;US&#39;, 1: &#39;Germany&#39;}, {0: &#39;low&#39;, 1: &#39;high&#39;}] . base_data.emb_vars_train[1:10] . array([[1, 1], [1, 0], [1, 0], [1, 0], [0, 0], [1, 1], [1, 1], [0, 0], [1, 0]]) . What happens here is that everything connected to the data is now stored in the BaseData class. Each and every function within this class needs the data where it is and gets the data directly, so there is no jumping to other objects or methods to make this happen. So my first take away: keep your data together! . Next I will use this data to pass it on to the next point within our pipeline. Just to keep you informed, what I do here is actually a refactoring of an earlier project of mine, where I will use a convolutional neural network in PyTorch to classify a timeseries. So in order to use PyTorches power, the data needs to be in so called Dataloaders. . from config import * from dataloaders import * device = DEVICE datasets = create_datasets(base_data.x_train, base_data.emb_vars_train, base_data.y_train, base_data.x_test, base_data.emb_vars_test, base_data.y_test, valid_pct=VAL_SIZE, seed=1234) data = DataBunch(*create_loaders(datasets, bs=1024)) . If you want to have a closer look at what this exactly does, just go inside the dataloaders.py file. Basically it splits the train_data into train and validation and then creates a PyTorch dataset from it. This then can be put into a dataloader. Now I could have used three different dataloaders, but again, I want to keep my data together, which is why I created a class called DataBunch (naming and idea stolen from fastai), where I have all of my data in one place. . Furthermore, realize that I use one, and only one config file. I often see Code with different kind of constants aka configurations all over different files, which makes it extremely hard to later on debug the code or change settings. So please keep your constants in one place. . Now let&#39;s have a closer how we can use a clever way of building models in a more flexible way: . import torch from torch import nn class Flatten(nn.Module): &quot;&quot;&quot;Converts N-dimensional tensor into &#39;flat&#39; one.&quot;&quot;&quot; def __init__(self, keep_batch_dim=True): super().__init__() self.keep_batch_dim = keep_batch_dim def forward(self, x): if self.keep_batch_dim: return x.view(x.size(0), -1) return x.view(-1) def conv1d(ni, nf, ks, stride): return nn.Sequential( nn.Conv1d(ni, nf, ks, stride=stride, padding=0), nn.BatchNorm1d(nf), nn.ReLU()) def get_cnn_layers(input_shape, output_shapes:list, kernels:list, strides:list, drop=.5): output_shapes = [input_shape] + output_shapes return [ conv1d(output_shapes[i], output_shapes[i+1], kernels[i], strides[i]) for i in range(len(output_shapes)-1) ] + [nn.MaxPool1d(2, stride=2), Flatten(), nn.Dropout(drop), nn.Linear(output_shapes[-1], 64), nn.ReLU(inplace=True), nn.Dropout(drop), nn.Linear(64, 64), nn.ReLU(inplace=True)] class Classifier(nn.Module): &quot;&quot;&quot;Model Baseclass.&quot;&quot;&quot; def __init__(self, conv_layers, emb_dims, no): super().__init__() self.raw = conv_layers self.embeddings = nn.ModuleList([nn.Embedding(x, y) for x, y in emb_dims]) no_of_embs = sum([y for x, y in emb_dims]) self.no_of_embs = no_of_embs self.emb_dims = emb_dims self.emb_out = nn.Sequential( nn.Linear(no_of_embs, 64), nn.ReLU(inplace=True), nn.Linear(64, 64)) self.out = nn.Sequential( nn.Linear(64 + 64, 64), nn.ReLU(inplace=True), nn.Linear(64, no)) def forward(self, t_raw, embeddings): # this is where the data flows in later in the training raw_out = self.raw(t_raw) emb = [emb_layer(embeddings[:, i].long()) for i, emb_layer in enumerate(self.embeddings)] # we want to concatenate convolutions and embeddings. Embeddings are of size (batch_size, no_of_embs), # convolution of size (batch, 256, 1) so we need to add another dimension to the embeddings at dimension 2 ( # counting starts from 0) emb_cat = torch.cat(emb, 1) emb_cat = self.emb_out(emb_cat) t_in = torch.cat([raw_out, emb_cat], dim=1) out = self.out(t_in) return out . First thing to notice here is that I combined the basic structure of a Conv1d layer in one function. Every Conv1d layer should have a BatchNorm followed by a ReLU. You can adjust this just as you like. Then, in the next step I created a function which basically makes the Conv1d layer repetitive, given a list of arguments you provide. So based on that list of arguments, you can have 1, 2, 3, 4 or as many layer as you would like. This then in turn is then used in the Classifier class, which is our main model. The convolutional part, here called self.raw is then build given on what we specify how the architecture should look like. The rest of the model I kept rather inflexible, which you could if you want also change. But let&#39;s see this in action: . from torch import optim raw_feat = base_data.x_train.shape[1] emb_dims = [(len(base_data.dict_embs[0]), EMB_DIMS), (len(base_data.dict_embs[1]), EMB_DIMS)] NUM_CLASSES = 2 # model layers OUTPUT_SHAPES = [128] KERNELS = [23] STRIDES = [1] # create model model = Classifier(nn.Sequential( *get_cnn_layers(raw_feat, OUTPUT_SHAPES, KERNELS, STRIDES) ), emb_dims, NUM_CLASSES).to(device) opt = optim.Adam(model.parameters(), lr=0.01) loss_func = nn.CrossEntropyLoss() . Everything written in all caps is actually defined within the config file, but for seeing what&#39;s going on here I just put them into this code snippet. So if I wanted to add another layer, I could just go into my config file and change that, so that I have three layers with different kernels and strides. When doing experiments, you can just provide different settings in your config and then use them for your second model. Do not underestimate the idea of having parameters in one place. . The next big part is directly connected to the Information Expert principle. Let&#39;s start with the Learner, a simple idea based on that principle. When training the model, we need another class which keeps all the information needed, the Learner. And what information does the Learner need? The data, the model, the loss function and the optimizer: . class Learner(): def __init__(self, model, opt, loss_func, data): self.model,self.opt,self.loss_func,self.data = model,opt,loss_func,data learn = Learner(model, opt, loss_func, data) . Next, we need to build the pipeline for our process, let&#39;s call it runner. We pass in the Learner, which is responsible for the data and modelling part. The runner itself only guides the data flow: . class Runner(): def __init__(self, cbs=None, cb_funcs=None): self.in_train = False cbs = listify(cbs) for cbf in listify(cb_funcs): cb = cbf() setattr(self, cb.name, cb) cbs.append(cb) self.stop,self.cbs = False,[TrainEvalCallback()]+cbs @property def opt(self): return self.learn.opt @property def model(self): return self.learn.model @property def loss_func(self): return self.learn.loss_func @property def data(self): return self.learn.data def one_batch(self, xb, emb, yb): try: self.xb,self.emb,self.yb = xb,emb,yb self(&#39;begin_batch&#39;) self.pred = self.model(self.xb,self.emb) self(&#39;after_pred&#39;) self.loss = self.loss_func(self.pred, self.yb) self(&#39;after_loss&#39;) if not self.in_train: return self.loss.backward() self(&#39;after_backward&#39;) self.opt.step() self(&#39;after_step&#39;) self.opt.zero_grad() except CancelBatchException: self(&#39;after_cancel_batch&#39;) finally: self(&#39;after_batch&#39;) def all_batches(self, dl): self.iters = len(dl) try: for xb,emb,yb in dl: self.one_batch(xb, emb, yb) except CancelEpochException: self(&#39;after_cancel_epoch&#39;) def fit(self, epochs, learn): self.epochs,self.learn,self.loss = epochs,learn,torch.tensor(0.) try: for cb in self.cbs: cb.set_runner(self) self(&#39;begin_fit&#39;) for epoch in range(epochs): self.epoch = epoch if not self(&#39;begin_epoch&#39;): self.all_batches(self.data.train_dl) with torch.no_grad(): if not self(&#39;begin_validate&#39;): self.all_batches(self.data.valid_dl) self(&#39;after_epoch&#39;) except CancelTrainException: self(&#39;after_cancel_train&#39;) finally: self(&#39;after_fit&#39;) self.learn = None def __call__(self, cb_name): res = False for cb in sorted(self.cbs, key=lambda x: x._order): res = cb(cb_name) or res return res . The last idea I want every Data Scientist to know about are Callbacks. Basically that means we&#39;re calling a different function and make use of their behaviour. To be able to clearly pinpoint where the Callback should be applied, I added things like self(&#39;after_epoch&#39;). This then let&#39;s us easily create our own Callbacks which we can use exactly where we want to: . import matplotlib.pyplot as plt class Callback(): _order=0 def set_runner(self, run): self.run=run def __getattr__(self, k): return getattr(self.run, k) @property def name(self): name = re.sub(r&#39;Callback$&#39;, &#39;&#39;, self.__class__.__name__) return camel2snake(name or &#39;callback&#39;) def __call__(self, cb_name): f = getattr(self, cb_name, None) if f and f(): return True return False class Recorder(Callback): def begin_fit(self): self.lrs = [[] for _ in self.opt.param_groups] self.losses = [] def after_batch(self): if not self.in_train: return for pg,lr in zip(self.opt.param_groups,self.lrs): lr.append(pg[&#39;lr&#39;]) self.losses.append(self.loss.detach().cpu()) def plot_lr (self, pgid=-1): plt.plot(self.lrs[pgid]) def plot_loss(self, skip_last=0): plt.plot(self.losses[:len(self.losses)-skip_last]) def plot(self, skip_last=0, pgid=-1): losses = [o.item() for o in self.losses] lrs = self.lrs[pgid] n = len(losses)-skip_last plt.xscale(&#39;log&#39;) plt.plot(lrs[:n], losses[:n]) class LR_Find(Callback): _order=1 def __init__(self, max_iter=100, min_lr=1e-6, max_lr=10): self.max_iter,self.min_lr,self.max_lr = max_iter,min_lr,max_lr self.best_loss = 1e9 def begin_batch(self): if not self.in_train: return pos = self.n_iter/self.max_iter lr = self.min_lr * (self.max_lr/self.min_lr) ** pos for pg in self.opt.param_groups: pg[&#39;lr&#39;] = lr def after_step(self): if self.n_iter&gt;=self.max_iter or self.loss&gt;self.best_loss*10: raise CancelTrainException() if self.loss &lt; self.best_loss: self.best_loss = self.loss . After creating the base Callback class, each and every Callback we want to use inherits from it. Take the LR_Find Callback: This will be applied after a batch begins and after each step. These we have defined within our Runner class. Now we can use these Callbacks like so: . from callbacks import * run = Runner(cb_funcs=[LR_Find, Recorder]) run.fit(100, learn) run.recorder.plot(skip_last=5) . We can add all sorts of Callbacks, we can also trigger a Tensorboard run as a Callback: . from functools import partial model = Classifier(nn.Sequential( *get_cnn_layers(raw_feat, OUTPUT_SHAPES, KERNELS, STRIDES) ), emb_dims, NUM_CLASSES).to(device) opt = optim.Adam(model.parameters(), lr=2e-3) cbfs = [Recorder, partial(AvgStatsCallback,adjusted_accu), partial(Tracker, RUN_PATH)] learn = Learner(model, opt, loss_func, data) run = Runner(cb_funcs=cbfs) run.fit(40, learn) . epoch: 10 train: [0.6974158377017615, tensor(0.3962)] valid: [0.6996233122689384, tensor(0.3571)] epoch: 20 train: [0.2831651039843289, tensor(0.9434)] valid: [0.3708829198564802, tensor(1.)] epoch: 30 train: [0.06155696904884195, tensor(0.9811)] valid: [0.00996389878647668, tensor(1.)] epoch: 40 train: [0.013252086234542559, tensor(1.)] valid: [0.00019769343946661268, tensor(1.)] . This now has triggered a run for Tensorboard and saved it in this folder. We can now have a look at this by typing tensorboard --logdir=runs in the Terminal: . . And that&#39;s it for now. I hope the idea of Information Expert Principle is now a bit more familiar, and I could give you some ideas of how to refactor your existing Data Science projects. . Lasse .",
            "url": "https://lschmiddey.github.io/fastpages_/2021/10/27/How-to-use-software-engineering-to-improve-data-science.html",
            "relUrl": "/2021/10/27/How-to-use-software-engineering-to-improve-data-science.html",
            "date": " • Oct 27, 2021"
        }
        
    
  
    
        ,"post6": {
            "title": "Why it makes a difference how to standardize training and test set",
            "content": "In this tutorial I want to briefly show why it is important to correctly scale you train and test data. Although I think most machine learning practicioners automatically avoid the fallacy of not scaling the test data with the learned scaler from the trainset, I think many practitioners do not know exactly why. Here, I will give a concrete example of why you need to use the scaler from the trainset for the testset as well. . import numpy as np import pandas as pd from sklearn.linear_model import LinearRegression from sklearn.preprocessing import StandardScaler . Let&#39;s first create some dummy data. For example, we can assume the following are 3 different users, decribes by three variables. We also create the targets, which for example we can think of different clusters each user belongs to: . train_data = np.array([[0.8, 0.1, 0.1], [0.7, 0.2, 0.1], [0.85, 0.15, 0.]]) train_targets = np.array([2, 1, 0]) test_data = np.array([[0.8, 0.1, 0.1], [0.3, 0.5, 0.2], [0.85, 0.15, 0.]]) . You see that in the test_data user 1 and user 3 are exactly alike. This is on purpose. Let&#39;s create two standard scalers, meaning we will substract the mean and divide by the variance. . train_scaler = StandardScaler() test_scaler = StandardScaler() scaled_train_data = train_scaler.fit_transform(train_data) scaled_test_data = test_scaler.fit_transform(test_data) correctly_scaled_test_data = train_scaler.transform(test_data) . You can already see the difference between the two approaches. The first two scaled_data are built with the fit_transform method from the StandardScaler, while the last approach uses the &quot;trained&quot; scaler from the trainset to scale the test_dataset. Let&#39;s have a look at the different means and variance: . train_scaler.mean_, train_scaler.var_ . (array([0.78333333, 0.15 , 0.06666667]), array([0.00388889, 0.00166667, 0.00222222])) . test_scaler.mean_, test_scaler.var_ . (array([0.65, 0.25, 0.1 ]), array([0.06166667, 0.03166667, 0.00666667])) . And this is how the data looks like: . pd.DataFrame(scaled_train_data) . 0 1 2 . 0 0.267261 | -1.224745e+00 | 0.707107 | . 1 -1.336306 | 1.224745e+00 | 0.707107 | . 2 1.069045 | -6.798700e-16 | -1.414214 | . pd.DataFrame(scaled_test_data) . 0 1 2 . 0 0.604040 | -0.842927 | -1.699675e-16 | . 1 -1.409428 | 1.404879 | 1.224745e+00 | . 2 0.805387 | -0.561951 | -1.224745e+00 | . pd.DataFrame(correctly_scaled_test_data) . 0 1 2 . 0 0.267261 | -1.224745e+00 | 0.707107 | . 1 -7.750576 | 8.573214e+00 | 2.828427 | . 2 1.069045 | -6.798700e-16 | -1.414214 | . From first glance, the correctly scaled test data looks wrong, simply because the numbers seem so far off. However, let&#39;s have a look what happens when we fit a simple Linear Regression on our trainset and make predictions on the testsets: . lin_model = LinearRegression().fit(scaled_train_data, train_targets) . Remember, in our testset, we expect user 1 and user 3 to be classified as 2 and 0 respectively. . lin_model.predict(scaled_test_data) . array([1.33714607, 1.23420957, 0.42864436]) . But this did not happen at all here. We see that neither the first user nor the third user are classified correctly, even though they are exactly the same. Let&#39;s see what the results are, when using the scaler from our trainset: . lin_model.predict(correctly_scaled_test_data) . array([ 2.00000000e+00, -5.00000000e-01, -1.11022302e-16]) . This time, the Linear Model correctly classified user 1 and user 3. So you see what a difference wrongly used scaling makes. So keep this in mind when using train and testset. . Lasse .",
            "url": "https://lschmiddey.github.io/fastpages_/2021/10/25/How-to-correctly-standardize-your-data.html",
            "relUrl": "/2021/10/25/How-to-correctly-standardize-your-data.html",
            "date": " • Oct 25, 2021"
        }
        
    
  
    
        ,"post7": {
            "title": "Timeseries classification with CNN and Embeddings",
            "content": "from common import * from config import * from dataloaders import * from transform_data import * from model_part import * from callbacks import * from functools import partial from scipy.io import arff import matplotlib.pyplot as plt . # Read data data_train = arff.loadarff(&#39;data/LargeKitchenAppliances_TRAIN.arff&#39;) data_test = arff.loadarff(&#39;data/LargeKitchenAppliances_TEST.arff&#39;) df_test = pd.DataFrame(data_test[0]) df_train = pd.DataFrame(data_train[0]) # let&#39;s add a categorical variable countries = [&#39;Germany&#39;, &#39;US&#39;] household_income = [&#39;low&#39;, &#39;high&#39;] df_train[&quot;country&quot;] = np.random.choice(countries, len(df_train)) df_test[&quot;country&quot;] = np.random.choice(countries, len(df_test)) df_train[&quot;household_income&quot;] = np.random.choice(household_income, len(df_train)) df_test[&quot;household_income&quot;] = np.random.choice(household_income, len(df_test)) df_train.head() . att1 att2 att3 att4 att5 att6 att7 att8 att9 att10 ... att714 att715 att716 att717 att718 att719 att720 target country household_income . 0 -0.099108 | -0.099108 | -0.099108 | -0.099108 | -0.099108 | -0.099108 | -0.099108 | -0.099108 | -0.099108 | -0.099108 | ... | -0.099108 | -0.099108 | -0.099108 | -0.099108 | -0.099108 | -0.099108 | -0.099108 | b&#39;1&#39; | US | low | . 1 -0.155256 | -0.155256 | -0.155256 | -0.155256 | -0.155256 | -0.155256 | -0.155256 | -0.155256 | -0.155256 | -0.155256 | ... | -0.155256 | -0.155256 | -0.155256 | -0.155256 | -0.155256 | -0.155256 | -0.155256 | b&#39;1&#39; | Germany | high | . 2 -0.100082 | -0.100082 | -0.100082 | -0.100082 | -0.100082 | -0.100082 | -0.100082 | -0.100082 | -0.100082 | -0.100082 | ... | -0.100082 | -0.100082 | -0.100082 | -0.100082 | -0.100082 | -0.100082 | -0.100082 | b&#39;1&#39; | Germany | high | . 3 -0.140671 | -0.140671 | -0.140671 | -0.140671 | -0.140671 | -0.140671 | -0.140671 | -0.140671 | -0.140671 | -0.140671 | ... | -0.140671 | -0.140671 | -0.140671 | -0.140671 | -0.140671 | -0.140671 | -0.140671 | b&#39;1&#39; | US | high | . 4 -0.140576 | -0.140576 | -0.140576 | -0.140576 | -0.140576 | -0.140576 | -0.140576 | -0.140576 | -0.140576 | -0.140576 | ... | -0.140576 | -0.140576 | -0.140576 | -0.140576 | -0.140576 | -0.140576 | -0.140576 | b&#39;1&#39; | Germany | high | . 5 rows × 723 columns . df_train.shape, df_test.shape . ((375, 723), (375, 723)) . The first 720 columns represent the time-dependent variables, the second last is our target_variable and the last is our (fake) categorical variable. . x_train = df_train.iloc[:, :-3].values.reshape(-1, 1, 720) x_test = df_test.iloc[:, :-3].values.reshape(-1, 1, 720) y_train = df_train.iloc[:, -3].values y_test = df_test.iloc[:, -3].values emb_vars_train = df_train.iloc[:, -2:].values emb_vars_test = df_test.iloc[:, -2:].values . Let&#39;s plot some of these: . df_train.iloc[0, :-3].plot.line(title=f&#39;time series with class = {df_train.iloc[0, -3]} in {df_train.iloc[0, -2]}&#39;); . df_train.iloc[10, :-3].plot.line(title=f&#39;time series with class = {df_train.iloc[10, -3]} in {df_train.iloc[10, -2]}&#39;); . Let&#39;s check the means and variance of our variables: . plt.plot(x_train.mean(axis=2).reshape(-1)) . [&lt;matplotlib.lines.Line2D at 0x7f2e8d70e3d0&gt;] . plt.plot(x_train.var(axis=2).reshape(-1)) . [&lt;matplotlib.lines.Line2D at 0x7f2e8d684460&gt;] . Note the 1e-8 on top, meaning we&#39;re dealing here with numbers almost being 0 for the mean and almost being 1 for the variance, so we do not need to normalize them, because they already are. Still, I want to show you a neat trick of how to use broadcasting to quickly normalize each column to have mean of zero and variance of 1: . def normalize(x, m, s): return (x-m)/s means_ = x_train.mean(axis=2) vars_ = x_train.var(axis=2) . means_.shape, vars_.shape, x_train.shape . ((375, 1), (375, 1), (375, 1, 720)) . Only the last dimensions does not match, therefore we can use broadcasting to normalize over all columns: . normalize(x_train, means_, vars_).shape . (375, 375, 720) . Again, in this case our data already looks as it should. Also, the kind of function like normalize I put into a .py file with the name common, which can then be imported by any other python-file or notebook, just as I did right on top of this notebook. So whenever in this notebook there appears a function which is not defined so far, look into the common.py file. . As a next step, we need to transform the target variable and the categorical variable into something the computer can actuelly work with, meaning a number. We can do this using the cat_transform function: . y_train, y_test, dict_y, dict_inv_y = cat_transform(y_train, y_test) emb_vars_train, emb_vars_test, dict_embs, dict_inv_embs = cat_transform(emb_vars_train, emb_vars_test) . y_train[:10], emb_vars_train[:10], dict_y, dict_embs . (array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1]), array([[0, 1], [1, 0], [1, 0], [0, 0], [1, 0], [1, 0], [1, 1], [0, 0], [0, 0], [1, 1]]), [{0: b&#39;2&#39;, 1: b&#39;1&#39;, 2: b&#39;3&#39;}], [{0: &#39;US&#39;, 1: &#39;Germany&#39;}, {0: &#39;high&#39;, 1: &#39;low&#39;}]) . dict_y, dict_embs . ([{0: b&#39;2&#39;, 1: b&#39;1&#39;, 2: b&#39;3&#39;}], [{0: &#39;US&#39;, 1: &#39;Germany&#39;}, {0: &#39;high&#39;, 1: &#39;low&#39;}]) . Next, we will use PyTorch to create dataset and dataloader, which we will put into a class called DataBunch (idea stolen from fastai). . device = DEVICE datasets = create_datasets(x_train, emb_vars_train, y_train, x_test, emb_vars_test, y_test, valid_pct=VAL_SIZE, seed=1234) data = DataBunch(*create_loaders(datasets, bs=1024)) . Next, we define our model. First, we need to make sure that the final convolution ends up with 1 as the last dimension, so we can put it through a linear layer. . # define model raw_feat = x_train.shape[1] emb_dims = [(len(dict_embs[0]), EMB_DIMS), (len(dict_embs[1]), EMB_DIMS)] num_classes = len(dict_y[0]) . Let&#39;s grab a batch from our data and see how the convolutions work on our timeseries data: . x_raw, _, _ = next(iter(data.train_dl)) x_raw.shape . torch.Size([300, 1, 720]) . raw_ni=x_train.shape[1] # no of input features (here:1) drop=0.3 m = nn.Conv1d(raw_ni, 128, 28, 7, 0) output_ = m(x_raw) print(output_.shape) m = nn.Conv1d(128, 32, 14, 7, 0) output_ = m(output_) print(output_.shape) m = nn.Conv1d(32, 64, 5, 2, 0) output_ = m(output_) print(output_.shape) # m = nn.Conv1d(64, 32, 3, 8, 0) # output_ = m(output_) # print(output_.shape) m = nn.MaxPool1d(2, stride=4) output_ = m(output_) print(output_.shape) . torch.Size([300, 128, 99]) torch.Size([300, 32, 13]) torch.Size([300, 64, 5]) torch.Size([300, 64, 1]) . To easily try different kind of architectures, I created a helper function which creates the CNN part of our model. How the complete architecture works will be part of the following tutorial, where I will show in more detail how the code works. But for now, let&#39;s see how the final architecture of the model looks like: . . output_shapes = [128, 32, 64] kernels_shape = [28, 14, 5] strides = [7, 7, 2] model = Classifier_CNN(nn.Sequential( *get_cnn_layers(raw_feat, output_shapes, kernels_shape, strides) ), emb_dims, num_classes).to(device) opt = optim.Adam(model.parameters(), lr=0.01) loss_func = nn.CrossEntropyLoss() . This is how the CNN-Part from our model looks like: . model.raw . Sequential( (0): Sequential( (0): Conv1d(1, 128, kernel_size=(28,), stride=(7,)) (1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True) (2): ReLU() ) (1): Sequential( (0): Conv1d(128, 32, kernel_size=(14,), stride=(7,)) (1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True) (2): ReLU() ) (2): Sequential( (0): Conv1d(32, 64, kernel_size=(5,), stride=(2,)) (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True) (2): ReLU() ) (3): MaxPool1d(kernel_size=2, stride=4, padding=0, dilation=1, ceil_mode=False) (4): Flatten() (5): Dropout(p=0.5, inplace=False) (6): Linear(in_features=64, out_features=64, bias=True) (7): ReLU(inplace=True) (8): Dropout(p=0.5, inplace=False) (9): Linear(in_features=64, out_features=64, bias=True) (10): ReLU(inplace=True) ) . And this is how the embedding part looks like: . model.embeddings . ModuleList( (0): Embedding(2, 5) (1): Embedding(2, 5) ) . A pretty neat technique of how to enhance a class with different behaviour is called a Callback. For example, we can use a function to calculate the best learning rate, and use a Callback to use our model with it. Again, how this exactly works will be covered in the next tutorial: . learn = Learner(model, opt, loss_func, data) run = Runner(cb_funcs=[LR_Find, Recorder]) run.fit(1000, learn) run.recorder.plot(skip_last=5) . We should take the learning rate with the steepest drop, so somewhere between 1e-3 and 1e-2. . model = Classifier_CNN(nn.Sequential( *get_cnn_layers(raw_feat, output_shapes, kernels_shape, strides) ), emb_dims, num_classes).to(device) opt = optim.Adam(model.parameters(), lr=2e-2) cbfs = [Recorder, partial(AvgStatsCallback,adjusted_accu)] learn = Learner(model, opt, loss_func, data) run = Runner(cb_funcs=cbfs) run.fit(50, learn) . epoch: 10 train: [1.095929463704427, tensor(0.3967)] valid: [1.3562200927734376, tensor(0.3600)] epoch: 20 train: [0.8562827555338541, tensor(0.5500)] valid: [1.3453341674804689, tensor(0.3333)] epoch: 30 train: [0.5564550272623698, tensor(0.7400)] valid: [1.2367724609375, tensor(0.6133)] epoch: 40 train: [0.4498468017578125, tensor(0.8100)] valid: [1.7772005208333332, tensor(0.4667)] epoch: 50 train: [0.428627675374349, tensor(0.8333)] valid: [1.9154888916015624, tensor(0.5333)] . Even though this specific model didn&#39;t turn out to be too good, being correct in only approximately 60% of the time (there are 3 classes of which to choose), you can see how I again used a Callback to forward a metric which showed here as the accuracy. . run.recorder.plot_loss() . Next to the validation set I also use the testset to check how good our predictions actually are. . outs = run.predict(learn, learn.data.test_dl) outs[:10] . array([1, 0, 1, 1, 1, 1, 1, 1, 1, 1]) . (outs == y_test).mean() . 0.48 . run.predict_metrics(learn, learn.data.test_dl, list(dict_y[0].values())) . We&#39;re pretty good at identifying class b1, however the model completely fails when it comes to classifying b2. . df_test.iloc[0, :-3].plot.line(title=f&#39;time series with class = {df_test.iloc[0, -3]}, predicted to be class {outs[0]}&#39;); . df_test.iloc[10, :-3].plot.line(title=f&#39;time series with class = {df_test.iloc[10, -3]}, predicted to be class {outs[10]}&#39;); . df_test.iloc[8, :-3].plot.line(title=f&#39;time series with class = {df_test.iloc[8, -3]}, predicted to be class {outs[8]}&#39;); . df_test.iloc[57, :-3].plot.line(title=f&#39;time series with class = {df_test.iloc[57, -3]}, predicted to be class {outs[57]}&#39;); . df_test.iloc[326, :-3].plot.line(title=f&#39;time series with class = {df_test.iloc[326, -3]}, predicted to be class {outs[326]}&#39;); . Also one particular interesting measure is to look inside the model, meaning having a look at the means and standard-deviations of our activations. ideally the mean should be around 0 and the standard-variance about 1. . def append_stats(i, mod, inp, outp): act_means[i].append(outp.data.mean()) act_stds [i].append(outp.data.std()) . output_shapes = [128, 32, 64] kernels_shape = [28, 14, 5] strides = [7, 7, 2] model = Classifier_CNN(nn.Sequential( *get_cnn_layers(raw_feat, output_shapes, kernels_shape, strides) ), emb_dims, num_classes).to(device) model.raw[0][0].register_forward_hook(partial(append_stats, 0)) model.raw[1][0].register_forward_hook(partial(append_stats, 1)) model.raw[2][0].register_forward_hook(partial(append_stats, 2)) cbfs = [Recorder] learn = Learner(model, opt, loss_func, data) run = Runner(cb_funcs=cbfs) act_means = [[] for _ in range(3)] act_stds = [[] for _ in range(3)] run.fit(50, learn) . for o in act_means: plt.plot(o) plt.legend(range(3)); . for o in act_stds: plt.plot(o) plt.legend(range(3)); . This is really interesting, this zigzag pattern in the later layers meaning we&#39;re actually not learning really well here. Let&#39;s try another, much simpler architecture and compare the results: . output_shapes = [128] kernels_shape = [719] strides = [1] model = Classifier_CNN(nn.Sequential( *get_cnn_layers(raw_feat, output_shapes, kernels_shape, strides) ), emb_dims, num_classes).to(device) opt = optim.Adam(model.parameters(), lr=0.001) cbfs = [Recorder] learn = Learner(model, opt, loss_func, data) run = Runner(cb_funcs=cbfs) act_means = [[] for _ in range(1)] act_stds = [[] for _ in range(1)] model.raw[0][0].register_forward_hook(partial(append_stats, 0)) run.fit(50, learn) . for o in act_means: plt.plot(o) plt.legend(range(1)); . for o in act_stds: plt.plot(o) plt.legend(range(1)); . This looks better. However, we can also try a different initilization. . def init_weights(m): if isinstance(m, nn.Conv1d): torch.nn.init.kaiming_uniform_(m.weight) m.bias.data.fill_(0.01) output_shapes = [128, 32, 64] kernels_shape = [28, 14, 5] strides = [7, 7, 2] model = Classifier_CNN(nn.Sequential( *get_cnn_layers(raw_feat, output_shapes, kernels_shape, strides) ), emb_dims, num_classes).to(device) model.apply(init_weights) model.raw[0][0].register_forward_hook(partial(append_stats, 0)) model.raw[1][0].register_forward_hook(partial(append_stats, 1)) model.raw[2][0].register_forward_hook(partial(append_stats, 2)) cbfs = [Recorder] learn = Learner(model, opt, loss_func, data) run = Runner(cb_funcs=cbfs) act_means = [[] for _ in range(3)] act_stds = [[] for _ in range(3)] run.fit(50, learn) . for o in act_means: plt.plot(o) plt.legend(range(3)); . for o in act_stds: plt.plot(o) plt.legend(range(3)); . This looks way more promising when it comes to the 3 convolutional layers. Admittingly, this still is not perfect. . model = Classifier_CNN(nn.Sequential( *get_cnn_layers(raw_feat, output_shapes, kernels_shape, strides) ), emb_dims, num_classes).to(device) model.apply(init_weights) opt = optim.Adam(model.parameters(), lr=2e-2) cbfs = [Recorder, partial(AvgStatsCallback,adjusted_accu)] learn = Learner(model, opt, loss_func, data) run = Runner(cb_funcs=cbfs) run.fit(80, learn) . epoch: 10 train: [1.0968295288085939, tensor(0.3433)] valid: [1.9732820638020834, tensor(0.3867)] epoch: 20 train: [0.7535211690266927, tensor(0.6067)] valid: [1.5353872680664062, tensor(0.3867)] epoch: 30 train: [0.5347029622395834, tensor(0.7467)] valid: [1.365126953125, tensor(0.5333)] epoch: 40 train: [0.4531549580891927, tensor(0.8067)] valid: [2.0907596842447917, tensor(0.5600)] epoch: 50 train: [0.36646458943684895, tensor(0.8233)] valid: [3.187868448893229, tensor(0.4667)] epoch: 60 train: [0.3460370127360026, tensor(0.8533)] valid: [3.073258463541667, tensor(0.5333)] epoch: 70 train: [0.3205308024088542, tensor(0.8467)] valid: [3.1966796875, tensor(0.4933)] epoch: 80 train: [0.3039264933268229, tensor(0.8500)] valid: [3.1939200846354168, tensor(0.5867)] . outs = run.predict(learn, learn.data.test_dl) (outs == y_test).mean() . 0.448 . This is the end of the first part of this tutorial. In the next tutorial I will show you how the code behind this looks like and how it works. . Lasse .",
            "url": "https://lschmiddey.github.io/fastpages_/2021/10/18/Timeseries-Classification_with_CNN-and_Embeddings.html",
            "relUrl": "/2021/10/18/Timeseries-Classification_with_CNN-and_Embeddings.html",
            "date": " • Oct 18, 2021"
        }
        
    
  
    
        ,"post8": {
            "title": "Transform a PyTorch model to onnx",
            "content": "In this tutorial, I want to show how easily you can transform a PyTorch model to the onnx format. But first of all, why would you want to do that? There are several reasons in my experience when this might come in handy for you: . your development area is different from your production area. In my experience, this is often the case. When we have huge data on which to do inference in batches, it is often not the best idea to first shift your data from one source towards your python-server, do the inference there and then put the data back again. onnx can make you use your Deep Learning models directly where your data is stored which is a huge benefit. | onnx runs on Java via their API, meaning you can train your model with Python but deploy it on Java. This makes a huge difference because you can then deploy your model for example directly in your cluster. | onnx supports all of the popular Deep Learning frameworks like PyTorch, TensorFlow or Caffe (and a lot more). That means in teams where some feel more confortable using TensorFlow and other feel more comfortable using PyTorch, the deployment process can still be the same. | . import pandas as pd import numpy as np import torch from torch import nn import torch.onnx import matplotlib.pyplot as plt . In a previous tutorial I already showed you how powerful convolutional neural networks are when it comes to timeseries. I used the Italy Power demand dataset to do a classification task, which was to distinguish which day stems from. To show you how to deploy your model I will use this model trained on CPU with PyTorch and show you how then to save it as an onnx model. The way onnx works is that it first needs a &quot;sample&quot; of one example data point (tensor) with which we once do the inference part. So let&#39;s first load the data and just take the first example for which we want to make a prediction. . df_train = pd.read_csv(&#39;Data/ItalyPowerDemand_TRAIN.txt&#39;, header=None,delim_whitespace=True) x_train = df_train.iloc[:, 1:].values.reshape(-1, 1, 24) x_train[0] . array([[-0.71051757, -1.1833204 , -1.3724416 , -1.5930829 , -1.4670021 , -1.3724416 , -1.0887599 , 0.04596695, 0.92853223, 1.0861332 , 1.2752543 , 0.96005242, 0.61333034, 0.01444676, -0.6474772 , -0.26923494, -0.20619456, 0.61333034, 1.3698149 , 1.4643754 , 1.054613 , 0.58181015, 0.1720477 , -0.26923494]]) . Just as a reminder, this numpy array represents the power usage within 24 hours, and we tried to predict whether this day is from Oct to March (inclusive) or from April to September. . df_train.iloc[0, 1:].plot.line(title=f&#39;time series with class = {df_train.iloc[0, 0]}&#39;); . We now transform this numpy array to a PyTorch tensor. The only thing we need to keep in mind from building our model is that the tensor has to follow a certain shape. Right now this shape looks like so: . x_train[0].shape . (1, 24) . However, the model expects the shape like so: [batch_size, no_of_variables, no_of_observations]. In our case, we want the batch_size to be 1, we only have 1 variable over which we want to predict (power usage) and we have 24 observations, one for each hour. Also, we need to make the tensor of type float in this case, because when training the model we used the float type as input. . x_tensor = torch.from_numpy(x_train[0].reshape(1, 1, 24)).float() . Now we need to reload our model. Best practice for saving models is to only save the state_dict(). This however means when realoding the model, we first need to define the &quot;skeleton&quot; of the model if you will, which will then be updated by the corresponding weights and biases from the saved state_dict(). Again, if you haven&#39;t read the tutorial on how to build the model, I highly recommend to read that again. . class CostumConv1d(nn.Module): &quot;&quot;&quot;Implementes a 1-d convolution with &#39;batteries included&#39;. The module adds (optionally) activation function and dropout layers right after a separable convolution layer. &quot;&quot;&quot; def __init__(self, ni, no, kernel, stride, pad, drop=None, activ=lambda: nn.ReLU(inplace=True)): super().__init__() assert drop is None or (0.0 &lt; drop &lt; 1.0) layers = [nn.Conv1d(ni, no, kernel, stride, pad)] if activ: layers.append(activ()) if drop is not None: layers.append(nn.Dropout(drop)) self.layers = nn.Sequential(*layers) def forward(self, x): return self.layers(x) class Flatten(nn.Module): &quot;&quot;&quot;Converts N-dimensional tensor into &#39;flat&#39; one.&quot;&quot;&quot; def __init__(self, keep_batch_dim=True): super().__init__() self.keep_batch_dim = keep_batch_dim def forward(self, x): if self.keep_batch_dim: return x.view(x.size(0), -1) return x.view(-1) class Classifier(nn.Module): def __init__(self, raw_ni, no, drop=.5): super().__init__() self.raw = nn.Sequential( CostumConv1d(raw_ni, 128, 23, 1, 0, drop=drop), nn.MaxPool1d(2, stride=2), Flatten(), nn.Dropout(drop), nn.Linear(128, 64), nn.ReLU(inplace=True), nn.Dropout(drop), nn.Linear( 64, 64), nn.ReLU(inplace=True)) self.out = nn.Sequential( nn.Linear(64, 64), nn.ReLU(inplace=True), nn.Linear(64, no)) def forward(self, t_raw): raw_out = self.raw(t_raw) out = self.out(raw_out) return out . Remember, we only have one variable with which we predict one of two classes (either 0 or 1). . device = torch.device(&#39;cpu&#39;) no_variables = 1 num_classes = 2 model = Classifier(no_variables, num_classes).to(device) model.load_state_dict(torch.load(&#39;best.pth&#39;)) . &lt;All keys matched successfully&gt; . We&#39;re already almost done. Last thing missing is the inference part. To do so, we first have to put the mode in evaluation mode (otherwise it expects the target variable as an input to the model as well) and we also for faster inference later on tell the model not to calculate the gradients each time. . model.eval() with torch.no_grad(): output = model(x_tensor.to(device)) . output . tensor([[0.0232, 0.0089]]) . Now we&#39;re ready to save our model as a onnx model. Keep in mind that any changes done to the output (like applying a sigmoid function for example) will not be saved in the onnx model. Later operations then need to be done where you apply the model, for example when using it in a Java set up you need to use the Java functionality for sigmoid. . torch.onnx.export(model, x_tensor, &#39;onnx_model.onnx&#39;, export_params=True, opset_version=10) . d: PythonProjects python_to_onnx venv_onnx lib site-packages torch nn functional.py:652: UserWarning: Named tensors and all their associated APIs are an experimental feature and subject to change. Please do not use them for anything important until they are released as stable. (Triggered internally at .. c10/core/TensorImpl.h:1156.) return torch.max_pool1d(input, kernel_size, stride, padding, dilation, ceil_mode) . The UserWarning we&#39;re getting here is outdated, with pytorch 1.9 the version is stable and you can savely use this model. (this warning should be removed with version 1.9.1, current date: 2021-08-28) . And that&#39;s it! We now have saved our model with onnx, ready to be deployed on other frameworks directly. In the next tutorial, I want to show you how to use this onnx model and make it run on Java. . Lasse .",
            "url": "https://lschmiddey.github.io/fastpages_/2021/08/28/Transform-PyTorch-model-to-onnx.html",
            "relUrl": "/2021/08/28/Transform-PyTorch-model-to-onnx.html",
            "date": " • Aug 28, 2021"
        }
        
    
  
    
        ,"post9": {
            "title": "Time Series Classification with Convolutions",
            "content": "How a simple 1d Convolutional Neural Net is able to find time patterns without further feature engineering and achieve impressive results. . import pandas as pd import numpy as np import matplotlib.pyplot as plt from sklearn.model_selection import train_test_split from datetime import datetime, timedelta import torch from torch import nn from torch import optim from torch.nn import functional as F from torch.optim.lr_scheduler import _LRScheduler from torch.utils.data import TensorDataset, DataLoader . For this blog, I will use the Italy Power demand dataset. The classification task is to distinguish days from Oct to March (inclusive) from April to September. The dataset can be found here: http://www.timeseriesclassification.com/description.php?Dataset=ItalyPowerDemand. The best accuracy so far is stated by the webpage as 97%. . df_train = pd.read_csv(&#39;Data/ItalyPowerDemand_TRAIN.txt&#39;, header=None,delim_whitespace=True) df_test = pd.read_csv(&#39;Data/ItalyPowerDemand_TEST.txt&#39;, header=None, delim_whitespace=True) . df_train.head() . 0 1 2 3 4 5 6 7 8 9 ... 15 16 17 18 19 20 21 22 23 24 . 0 1.0 | -0.710518 | -1.183320 | -1.372442 | -1.593083 | -1.467002 | -1.372442 | -1.088760 | 0.045967 | 0.928532 | ... | -0.647477 | -0.269235 | -0.206195 | 0.613330 | 1.369815 | 1.464375 | 1.054613 | 0.581810 | 0.172048 | -0.269235 | . 1 1.0 | -0.993009 | -1.426786 | -1.579884 | -1.605401 | -1.630917 | -1.375754 | -1.018526 | -0.355102 | 0.716583 | ... | 0.486936 | 0.563485 | 0.614518 | 0.308322 | 0.257289 | 1.099327 | 1.048295 | 0.691066 | -0.048906 | -0.380618 | . 2 2.0 | 1.319067 | 0.569774 | 0.195128 | -0.085856 | -0.179518 | -0.273180 | -0.085856 | -1.397118 | -1.116134 | ... | -0.554164 | -0.741487 | -0.741487 | -0.741487 | -1.116134 | -0.460503 | 0.476113 | 2.349344 | 2.255682 | 1.600052 | . 3 2.0 | -0.812444 | -1.157553 | -1.416385 | -1.531421 | -1.502662 | -1.416385 | -1.646458 | -0.467335 | 0.654269 | ... | 0.740547 | 0.884342 | 0.884342 | 0.683028 | 0.625510 | 0.424197 | -0.007190 | -0.035949 | 0.107847 | -0.266022 | . 4 1.0 | -0.972840 | -1.390518 | -1.536705 | -1.620240 | -1.620240 | -1.453169 | -0.993724 | 0.050469 | 0.635218 | ... | 0.321960 | 0.489031 | 0.614334 | 1.303502 | 1.240850 | 1.073779 | 0.551682 | 0.426379 | -0.179253 | -0.638698 | . 5 rows × 25 columns . len(df_train), len(df_test) . (67, 1029) . The first column represents the target, the rest is one feature over the course of 24 days. The task then is to correctly classify, whether this month is in winter or in summer. . x_train = df_train.iloc[:, 1:].values.reshape(-1, 1, 24) x_test = df_test.iloc[:, 1:].values.reshape(-1, 1, 24) . y_train = df_train.iloc[:, 0].values-1 y_test = df_test.iloc[:, 0].values-1 . x_train.shape, x_test.shape, y_train.shape, y_test.shape . ((67, 1, 24), (1029, 1, 24), (67,), (1029,)) . Plot some time series . df_train.iloc[0, 1:].plot.line(title=f&#39;time series with class = {df_train.iloc[0, 0]}&#39;); . &lt;!DOCTYPE svg PUBLIC &quot;-//W3C//DTD SVG 1.1//EN&quot; &quot;http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd&quot;&gt; 2021-04-30T18:11:52.616116 image/svg+xml Matplotlib v3.4.1, https://matplotlib.org/ df_train.iloc[1, 1:].plot.line(title=f&#39;time series with class = {df_train.iloc[1, 0]}&#39;); . &lt;!DOCTYPE svg PUBLIC &quot;-//W3C//DTD SVG 1.1//EN&quot; &quot;http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd&quot;&gt; 2021-04-30T18:12:05.971556 image/svg+xml Matplotlib v3.4.1, https://matplotlib.org/ df_train.iloc[2, 1:].plot.line(title=f&#39;time series with class = {df_train.iloc[2, 0]}&#39;); . &lt;!DOCTYPE svg PUBLIC &quot;-//W3C//DTD SVG 1.1//EN&quot; &quot;http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd&quot;&gt; 2021-04-30T18:12:31.203784 image/svg+xml Matplotlib v3.4.1, https://matplotlib.org/ to dataset and dataloader . def create_datasets(train, test, train_target, test_target, valid_pct=0.1, seed=None): &quot;&quot;&quot;Converts NumPy arrays into PyTorch datsets.&quot;&quot;&quot; train, test, train_target, test_target = train, test, train_target, test_target assert len(train)==len(train_target) idx = np.arange(len(train)) trn_idx, val_idx = train_test_split( idx, test_size=valid_pct, random_state=seed) trn_ds = TensorDataset( torch.tensor(train[trn_idx]).float(), torch.tensor(train_target[trn_idx]).long()) val_ds = TensorDataset( torch.tensor(train[val_idx]).float(), torch.tensor(train_target[val_idx]).long()) tst_ds = TensorDataset( torch.tensor(test).float(), torch.tensor(test_target).long()) return trn_ds, val_ds, tst_ds . def create_loaders(data, bs=128, jobs=0): &quot;&quot;&quot;Wraps the datasets returned by create_datasets function with data loaders.&quot;&quot;&quot; trn_ds, val_ds, tst_ds = data trn_dl = DataLoader(trn_ds, batch_size=bs, shuffle=True, num_workers=jobs) val_dl = DataLoader(val_ds, batch_size=bs, shuffle=False, num_workers=jobs) tst_dl = DataLoader(tst_ds, batch_size=bs, shuffle=False, num_workers=jobs) return trn_dl, val_dl, tst_dl . device = torch.device(&#39;cuda:0&#39; if torch.cuda.is_available() else &#39;cpu&#39;) datasets = create_datasets(x_train, x_test, y_train, y_test, seed=1234) trn_dl, val_dl, tst_dl = create_loaders(datasets, bs=256) . class CostumConv1d(nn.Module): &quot;&quot;&quot;Implementes a 1-d convolution with &#39;batteries included&#39;. The module adds (optionally) activation function and dropout layers right after a separable convolution layer. &quot;&quot;&quot; def __init__(self, ni, no, kernel, stride, pad, drop=None, activ=lambda: nn.ReLU(inplace=True)): super().__init__() assert drop is None or (0.0 &lt; drop &lt; 1.0) layers = [nn.Conv1d(ni, no, kernel, stride, pad)] if activ: layers.append(activ()) if drop is not None: layers.append(nn.Dropout(drop)) self.layers = nn.Sequential(*layers) def forward(self, x): return self.layers(x) . class Flatten(nn.Module): &quot;&quot;&quot;Converts N-dimensional tensor into &#39;flat&#39; one.&quot;&quot;&quot; def __init__(self, keep_batch_dim=True): super().__init__() self.keep_batch_dim = keep_batch_dim def forward(self, x): if self.keep_batch_dim: return x.view(x.size(0), -1) return x.view(-1) . When it comes to Convolutions, we can freely choose the output dimension, however, the length of the newly created tensor after the convolution is pre-defined and calculated as follows: . . After our convolutions we want the L-dimension to be equal to 1, so we can flatten it. We have a sequence of 24. According to the formula we can calculate how the convolution L changes when setting kernel_size, padding and dilation accordingly. Or, we can check it manually: . for epoch in range(1): epoch_loss = 0 for i, batch in enumerate(trn_dl): x_raw, y_batch = [t.to(device) for t in batch] x_raw.shape . torch.Size([60, 1, 24]) . If you want to, you can just fiddle around with the numbers. We want to end up at 1 for L in the end. After manually grid searching, I came up with a model where we only use one convolution, with a kernel of the size of the timeframe (at least almost). After that, I apply a max_pooling layer. . raw_ni=x_train.shape[1] # no of input features (here:1) drop=0.3 m = CostumConv1d(raw_ni, 32, 23, 1, 0, drop=drop) output_ = m(x_raw) print(output_.shape) # m = CostumConv1d(32, 64, 3, 2, 0, drop=drop) # output_ = m(output_) # print(output_.shape) m = nn.MaxPool1d(2, stride=2) output_ = m(output_) print(output_.shape) . torch.Size([5, 32, 2]) torch.Size([5, 32, 1]) . And now we know how to set up our model. . class Classifier(nn.Module): def __init__(self, raw_ni, no, drop=.5): super().__init__() self.raw = nn.Sequential( CostumConv1d(raw_ni, 128, 23, 1, 0, drop=drop), # CostumConv1d( 32, 64, 3, 2, 0, drop=drop), # CostumConv1d( 64, 256, 3, 1, 0, drop=drop), # CostumConv1d( 256, 256, 2, 1, 0, drop=drop), # CostumConv1d( 256, 256, 2, 1, 0, drop=drop), nn.MaxPool1d(2, stride=2), Flatten(), nn.Dropout(drop), nn.Linear(128, 64), nn.ReLU(inplace=True), nn.Dropout(drop), nn.Linear( 64, 64), nn.ReLU(inplace=True)) self.out = nn.Sequential( nn.Linear(64, 64), nn.ReLU(inplace=True), nn.Linear(64, no)) def forward(self, t_raw): raw_out = self.raw(t_raw) out = self.out(raw_out) return out . raw_feat = x_train.shape[1] lr = 0.001 n_epochs = 500 iterations_per_epoch = len(trn_dl) num_classes = 2 best_acc = 0 patience, trials = 200, 0 base = 1 step = 2 loss_history = [] acc_history = [] model = Classifier(raw_feat, num_classes).to(device) criterion = nn.CrossEntropyLoss() opt = optim.Adam(model.parameters(), lr=lr) . print(&#39;Start model training&#39;) for epoch in range(1, n_epochs + 1): model.train() epoch_loss = 0 for i, batch in enumerate(trn_dl): x_raw, y_batch = [t.to(device) for t in batch] opt.zero_grad() out = model(x_raw) loss = criterion(out, y_batch) epoch_loss += loss.item() loss.backward() opt.step() epoch_loss /= trn_sz loss_history.append(epoch_loss) model.eval() correct, total = 0, 0 for batch in val_dl: x_raw, y_batch = [t.to(device) for t in batch] out = model(x_raw) preds = F.log_softmax(out, dim=1).argmax(dim=1) total += y_batch.size(0) correct += (preds == y_batch).sum().item() acc = correct / total acc_history.append(acc) if epoch % base == 0: print(f&#39;Epoch: {epoch:3d}. Loss: {epoch_loss:.4f}. Acc.: {acc:2.2%}&#39;) base *= step if acc &gt; best_acc: trials = 0 best_acc = acc torch.save(model.state_dict(), &#39;best.pth&#39;) print(f&#39;Epoch {epoch} best model saved with accuracy: {best_acc:2.2%}&#39;) else: trials += 1 if trials &gt;= patience: print(f&#39;Early stopping on epoch {epoch}&#39;) break print(&#39;Done!&#39;) . Start model training Epoch: 1. Loss: 0.0175. Acc.: 57.14% Epoch 1 best model saved with accuracy: 57.14% Epoch: 2. Loss: 0.0170. Acc.: 57.14% Epoch 3 best model saved with accuracy: 100.00% Epoch: 4. Loss: 0.0172. Acc.: 85.71% Epoch: 8. Loss: 0.0171. Acc.: 57.14% Epoch: 16. Loss: 0.0167. Acc.: 71.43% Epoch: 32. Loss: 0.0132. Acc.: 100.00% Epoch: 64. Loss: 0.0024. Acc.: 100.00% Epoch: 128. Loss: 0.0007. Acc.: 100.00% Early stopping on epoch 203 Done! . def smooth(y, box_pts): box = np.ones(box_pts)/box_pts y_smooth = np.convolve(y, box, mode=&#39;same&#39;) return y_smooth . f, ax = plt.subplots(1, 2, figsize=(12, 4)) ax[0].plot(loss_history, label=&#39;loss&#39;) ax[0].set_title(&#39;Validation Loss History&#39;) ax[0].set_xlabel(&#39;Epoch no.&#39;) ax[0].set_ylabel(&#39;Loss&#39;) ax[1].plot(smooth(acc_history, 5)[:-2], label=&#39;acc&#39;) ax[1].set_title(&#39;Validation Accuracy History&#39;) ax[1].set_xlabel(&#39;Epoch no.&#39;) ax[1].set_ylabel(&#39;Accuracy&#39;); . &lt;!DOCTYPE svg PUBLIC &quot;-//W3C//DTD SVG 1.1//EN&quot; &quot;http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd&quot;&gt; 2021-04-30T18:03:30.997127 image/svg+xml Matplotlib v3.4.1, https://matplotlib.org/ We see that our model did a great job in classifying the validation data correctly. Remember, we only have training data for about 60 cases. Let&#39;s see how our model performs on the test dataset. . Check on test data . preds_array = np.array([]) for batch in tst_dl: x_raw, y_batch = [t.to(device) for t in batch] out = model(x_raw) preds = F.log_softmax(out, dim=1).argmax(dim=1).numpy() preds_array = np.concatenate((preds_array, preds), axis=None) . from sklearn.metrics import confusion_matrix confusion_matrix(y_test, preds_array) . array([[499, 14], [ 16, 500]], dtype=int64) . from sklearn.metrics import classification_report target_names = [&#39;class 1&#39;, &#39;class 2&#39;] print(classification_report(y_test, preds_array, target_names=target_names)) . precision recall f1-score support class 1 0.97 0.97 0.97 513 class 2 0.97 0.97 0.97 516 accuracy 0.97 1029 macro avg 0.97 0.97 0.97 1029 weighted avg 0.97 0.97 0.97 1029 . Glorious! We achieved 97% accuracy! That is the current best result for this dataset. Let&#39;s have a look at the wrongly classified timeseries. . wrongly_classified_idx = np.argwhere(y_test!=preds_array).reshape(-1) . df_test.iloc[wrongly_classified_idx[0], 1:].plot.line(title=f&#39;time series with class = {df_test.iloc[wrongly_classified_idx[0], 0]} n Prediction: {preds_array[wrongly_classified_idx[0]]+1}&#39;); . &lt;!DOCTYPE svg PUBLIC &quot;-//W3C//DTD SVG 1.1//EN&quot; &quot;http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd&quot;&gt; 2021-04-30T18:42:07.680361 image/svg+xml Matplotlib v3.4.1, https://matplotlib.org/ df_test.iloc[wrongly_classified_idx[1], 1:].plot.line(title=f&#39;time series with class = {df_test.iloc[wrongly_classified_idx[1], 0]} n Prediction: {preds_array[wrongly_classified_idx[1]]+1}&#39;); . &lt;!DOCTYPE svg PUBLIC &quot;-//W3C//DTD SVG 1.1//EN&quot; &quot;http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd&quot;&gt; 2021-04-30T18:42:26.648049 image/svg+xml Matplotlib v3.4.1, https://matplotlib.org/ We can see that these cases are pretty hard to classify correctly. Especially the first case looks almost like a mislabeling. . After this very hands-on approach in the next blog I&#39;ll write about the way 1d convolutions work and the math behind it, so stay tuned! Lasse .",
            "url": "https://lschmiddey.github.io/fastpages_/2021/04/30/Timeseries_Classification_with_ConvolutionalNeuralNet.html",
            "relUrl": "/2021/04/30/Timeseries_Classification_with_ConvolutionalNeuralNet.html",
            "date": " • Apr 30, 2021"
        }
        
    
  
    
        ,"post10": {
            "title": "Deep Learning for tabular data augmentation",
            "content": "How to use a variational Autoencoder to augment tabular data . When it comes to DeepLearning, the more data we have the better the chances are to get a great performing model. In fields like image recognition research has already came up with quite a few clever ideas how to use the existing data to create more data out of it. This is called data augmentation. . However, when we look at Deep Learning in the tabular data context, there are still many concepts missing. What I would like to show in this blogpost is a way to augment tabular data, what we could use in order to train a DeepLearning Model on more tabular data, or which can be used to create data of underrepresented classes. . I want to show graphically how this newly created data is sampled from the distribution of the underlying data and hence how this data can help to make better Deep Learning models. . I&#39;ve already created a small library, which I called deep_tabular_augmentation. In here I&#39;ve created a class, which handles all of the tabular data augmentation. . import pandas as pd import numpy as np import torch from sklearn.model_selection import train_test_split from sklearn import preprocessing import deep_tabular_augmentation as dta import warnings; warnings.simplefilter(&#39;ignore&#39;) . So first, we need to get some data. Here, I&#39;ve got some data on the infamous wine-dataset. . device = torch.device(&#39;cuda&#39; if torch.cuda.is_available() else &#39;cpu&#39;) DATA_PATH = &#39;data/wine.csv&#39; df = pd.read_csv(DATA_PATH, sep=&#39;,&#39;) df.head() . Wine Alcohol Malic.acid Ash Acl Mg Phenols Flavanoids Nonflavanoid.phenols Proanth Color.int Hue OD Proline . 0 1 | 14.23 | 1.71 | 2.43 | 15.6 | 127 | 2.80 | 3.06 | 0.28 | 2.29 | 5.64 | 1.04 | 3.92 | 1065 | . 1 1 | 13.20 | 1.78 | 2.14 | 11.2 | 100 | 2.65 | 2.76 | 0.26 | 1.28 | 4.38 | 1.05 | 3.40 | 1050 | . 2 1 | 13.16 | 2.36 | 2.67 | 18.6 | 101 | 2.80 | 3.24 | 0.30 | 2.81 | 5.68 | 1.03 | 3.17 | 1185 | . 3 1 | 14.37 | 1.95 | 2.50 | 16.8 | 113 | 3.85 | 3.49 | 0.24 | 2.18 | 7.80 | 0.86 | 3.45 | 1480 | . 4 1 | 13.24 | 2.59 | 2.87 | 21.0 | 118 | 2.80 | 2.69 | 0.39 | 1.82 | 4.32 | 1.04 | 2.93 | 735 | . cols = df.columns . We then build a DataLoader, in which we also standardize our data. We save the scaler in our dataset to make use of it later, when we invert the scaling. . def load_and_standardize_data(path): # read in from csv df = pd.read_csv(path, sep=&#39;,&#39;) # replace nan with -99 df = df.fillna(-99) df = df.values.reshape(-1, df.shape[1]).astype(&#39;float32&#39;) # randomly split X_train, X_test = train_test_split(df, test_size=0.3, random_state=42) # standardize values scaler = preprocessing.StandardScaler() X_train = scaler.fit_transform(X_train) X_test = scaler.transform(X_test) return X_train, X_test, scaler . from torch.utils.data import Dataset, DataLoader class DataBuilder(Dataset): def __init__(self, path, train=True): self.X_train, self.X_test, self.standardizer = load_and_standardize_data(DATA_PATH) if train: self.x = torch.from_numpy(self.X_train) self.len=self.x.shape[0] else: self.x = torch.from_numpy(self.X_test) self.len=self.x.shape[0] del self.X_train del self.X_test def __getitem__(self,index): return self.x[index] def __len__(self): return self.len . traindata_set=DataBuilder(DATA_PATH, train=True) testdata_set=DataBuilder(DATA_PATH, train=False) trainloader=DataLoader(dataset=traindata_set,batch_size=1024) testloader=DataLoader(dataset=testdata_set,batch_size=1024) . trainloader.dataset.x.shape, testloader.dataset.x.shape . (torch.Size([124, 14]), torch.Size([54, 14])) . We&#39;ve build our train and test datasets, and with the help of DataLoaders we also turned them into tensors. So, let&#39;s use deep_tabular_augmentation now. The class needs seven inputs: trainloader, testloader, device on which to run the traning, the input dimension (in this case: 14), and how many nodes the first and second hidden layers should have. Finally, we can also specify the number of latent factors. These latent factors will contain all the condensed information, meaning that we can use these latent factors to recreate the original 14 input dimensions (e.g. our data). . D_in = traindata_set.x.shape[1] H = 50 H2 = 12 autoenc_model = dta.AutoencoderModel(trainloader, testloader, device, D_in, H, H2, latent_dim=3) . After we&#39;ve successfully initiated our model, let&#39;s train it and call the trained model &quot;autoenc_model_fit&quot;. . autoenc_model_fit = autoenc_model.fit(epochs=600) . ====&gt; Epoch: 200 Average training loss: 11.3281 ====&gt; Epoch: 200 Average test loss: 11.4239 ====&gt; Epoch: 400 Average training loss: 9.7651 ====&gt; Epoch: 400 Average test loss: 10.3157 ====&gt; Epoch: 600 Average training loss: 9.1283 ====&gt; Epoch: 600 Average test loss: 10.5291 . Now, all we need is to create some fake data based on the trained model. How this works is the following: we know the learned parameters for the mean and the variance of our latent factors. Then, we use a normal distribution with the mean and variance of each of the latent factors to sample a value for latent factor 1,2 and 3 (because we&#39;ve got three latent facots in this case). These generated starting points for our latent factors are then used to inflate towards the 14 real input variables. Let&#39;s see how it&#39;s done: . scaler = trainloader.dataset.standardizer pred = autoenc_model_fit.predict_df(no_samples=500, cols=cols, scaler=scaler) df_fake[&#39;Wine&#39;] = np.round(df_fake[&#39;Wine&#39;]).astype(int) df_fake[&#39;Wine&#39;] = np.where(df_fake[&#39;Wine&#39;]&lt;1, 1, df_fake[&#39;Wine&#39;]) df_fake[&#39;Wine&#39;] = np.where(df_fake[&#39;Wine&#39;]&gt;3, 3, df_fake[&#39;Wine&#39;]) df_fake.head() . Wine Alcohol Malic.acid Ash Acl Mg Phenols Flavanoids Nonflavanoid.phenols Proanth Color.int Hue OD Proline . 0 2 | 12.493084 | 2.045130 | 2.237029 | 18.645376 | 101.227913 | 2.366858 | 2.039845 | 0.310666 | 1.780123 | 3.824865 | 1.053821 | 2.959614 | 614.468567 | . 1 2 | 12.388008 | 2.028943 | 2.237992 | 19.671783 | 93.292801 | 2.290553 | 2.102422 | 0.337810 | 1.582847 | 3.545685 | 1.047288 | 2.853665 | 574.657776 | . 2 2 | 12.863456 | 2.061298 | 2.315192 | 18.529932 | 104.701004 | 2.480082 | 2.273354 | 0.298898 | 1.788156 | 4.134489 | 1.071253 | 2.954578 | 788.806580 | . 3 2 | 12.315710 | 2.164225 | 2.261593 | 20.433725 | 91.778603 | 2.019248 | 1.704518 | 0.383477 | 1.496545 | 3.532443 | 0.991632 | 2.591641 | 531.966309 | . 4 2 | 12.562940 | 2.135798 | 2.234170 | 19.034275 | 101.889763 | 2.421708 | 2.133960 | 0.296481 | 1.818705 | 3.890027 | 1.052557 | 2.903332 | 662.883545 | . The deep_tabular_augmentation library has another method in its sleeve: predict_with_noise. What this does is the following, sampling from a normal distribution each element (independend of each other element) will be multiplied by 1 plus the sampled number. Why should we do this? The answer is that the Variational Autoencoder works similar to a PCA, resulting in sharper defined relations between variables. So the Variational Autoencoder keeps mean and standard deviance within the variables, however, the trained parameters of the model already find out &quot;hidden&quot; relations between variables. When these relations are linear the Variational Autoencoder de facto performs a PCA. We&#39;ll have a look at it in a second. . df_fake_with_noise = autoenc_model_fit.predict_with_noise_df(no_samples=500, scaler=scaler, cols=cols, mu=0, sigma=0.05, group_var=&#39;Wine&#39;) df_fake_with_noise[&#39;Wine&#39;] = np.round(df_fake_with_noise[&#39;Wine&#39;]).astype(int) df_fake_with_noise[&#39;Wine&#39;] = np.where(df_fake_with_noise[&#39;Wine&#39;]&lt;1, 1, df_fake_with_noise[&#39;Wine&#39;]) df_fake_with_noise[&#39;Wine&#39;] = np.where(df_fake_with_noise[&#39;Wine&#39;]&gt;3, 3, df_fake_with_noise[&#39;Wine&#39;]) df_fake_with_noise.head() . Wine Alcohol Malic.acid Ash Acl Mg Phenols Flavanoids Nonflavanoid.phenols Proanth Color.int Hue OD Proline . 0 2 | 12.106316 | 2.142077 | 2.127616 | 19.408381 | 92.179733 | 2.418110 | 2.124110 | 0.353460 | 1.544483 | 3.348948 | 1.057455 | 2.828610 | 560.824158 | . 1 2 | 12.147018 | 2.009001 | 2.188961 | 22.396885 | 101.379967 | 2.318827 | 2.177448 | 0.336155 | 1.584168 | 3.603321 | 0.984947 | 2.718268 | 604.860901 | . 2 2 | 13.262069 | 1.864855 | 2.277317 | 19.010958 | 95.259872 | 2.493481 | 2.209520 | 0.347245 | 1.750477 | 3.704191 | 0.989856 | 2.743370 | 631.236572 | . 3 2 | 13.586826 | 2.270907 | 2.191374 | 22.129240 | 91.323662 | 1.793574 | 1.240703 | 0.437917 | 1.393128 | 3.973017 | 0.862660 | 2.276499 | 543.781311 | . 4 2 | 13.825186 | 1.984307 | 2.333792 | 18.083511 | 102.420219 | 2.705270 | 2.401335 | 0.312623 | 1.910688 | 4.119694 | 1.008278 | 3.032777 | 685.976562 | . Let&#39;s have a look at the descriptives, especially the mean. Can you spot a difference between the real and the fake data? . df.groupby(&#39;Wine&#39;).describe().loc[:,(slice(None),[&#39;mean&#39;])] . Alcohol Malic.acid Ash Acl Mg Phenols Flavanoids Nonflavanoid.phenols Proanth Color.int Hue OD Proline . mean mean mean mean mean mean mean mean mean mean mean mean mean . Wine . 1 13.744746 | 2.010678 | 2.455593 | 17.037288 | 106.338983 | 2.840169 | 2.982373 | 0.290000 | 1.899322 | 5.528305 | 1.062034 | 3.157797 | 1115.711864 | . 2 12.278732 | 1.932676 | 2.244789 | 20.238028 | 94.549296 | 2.258873 | 2.080845 | 0.363662 | 1.630282 | 3.086620 | 1.056282 | 2.785352 | 519.507042 | . 3 13.153750 | 3.333750 | 2.437083 | 21.416667 | 99.312500 | 1.678750 | 0.781458 | 0.447500 | 1.153542 | 7.396250 | 0.682708 | 1.683542 | 629.895833 | . df_fake.groupby(&#39;Wine&#39;).describe().loc[:,(slice(None),[&#39;mean&#39;])] . Alcohol Malic.acid Ash Acl Mg Phenols Flavanoids Nonflavanoid.phenols Proanth Color.int Hue OD Proline . mean mean mean mean mean mean mean mean mean mean mean mean mean . Wine . 1 13.756567 | 1.972927 | 2.439609 | 16.679155 | 110.221558 | 2.888496 | 2.933521 | 0.296994 | 1.980520 | 5.707772 | 1.065832 | 3.040885 | 1103.145508 | . 2 12.550643 | 2.169043 | 2.292549 | 19.789505 | 96.663307 | 2.250596 | 2.012712 | 0.350111 | 1.627728 | 3.967775 | 1.007894 | 2.744052 | 616.919006 | . 3 13.225099 | 3.809655 | 2.512825 | 22.554857 | 101.781906 | 1.470288 | 0.664501 | 0.507955 | 0.921151 | 7.329511 | 0.642636 | 1.483876 | 621.194458 | . df_fake_with_noise.groupby(&#39;Wine&#39;).describe().loc[:,(slice(None),[&#39;mean&#39;])] . Alcohol Malic.acid Ash Acl Mg Phenols Flavanoids Nonflavanoid.phenols Proanth Color.int Hue OD Proline . mean mean mean mean mean mean mean mean mean mean mean mean mean . Wine . 1 13.816388 | 1.980611 | 2.445411 | 16.888805 | 109.618469 | 2.890874 | 2.916224 | 0.297376 | 1.960559 | 5.643065 | 1.068307 | 3.012105 | 1106.231079 | . 2 12.554925 | 2.182181 | 2.296422 | 19.779770 | 96.850357 | 2.270568 | 2.013577 | 0.349725 | 1.625649 | 4.029018 | 1.005889 | 2.740945 | 626.561035 | . 3 13.099731 | 3.869962 | 2.526824 | 22.768381 | 102.265625 | 1.440060 | 0.597155 | 0.517642 | 0.879244 | 7.493037 | 0.621761 | 1.406803 | 605.561829 | . Now let&#39;s have a graphical look on how the fake data looks vs the real data. . . This is what I meant by &quot;performing a PCA&quot;. One can clearly see how the Variational Autoencoder gave structure to the relation of Alcohol and Hue. If we add noise to it, this relation vanishes. But what happens, if we use more than 3 latent factors? This is the result with 14 (=input variables) latent factors: . . The same pattern emerges. However, when applying random noise to it, the resulting data looks pretty much like the real data. . Now let&#39;s have a look at some distributions. The first image always represents the results with 3 latent factors, the second one with 14 latent factors. . 3 latent factors . . 14 latent factors . . 3 latent factors . . 14 latent factors . . 3 latent factors . . 14 latent factors . . We see that when using a Variational Autoencoder to make data augmentation on tabular data, it actually already finds relations between variables. If we want to get rid of this effect and add random noise to the data, the resulting distributions look pretty much like the original, real data points. How can we use these insights to improve machine learning/deep learning models? This I will cover in an upcoming blogpost. . Until then, stay tuned for more! Lasse .",
            "url": "https://lschmiddey.github.io/fastpages_/2021/04/10/DeepLearning_TabularDataAugmentation.html",
            "relUrl": "/2021/04/10/DeepLearning_TabularDataAugmentation.html",
            "date": " • Apr 10, 2021"
        }
        
    
  
    
        ,"post11": {
            "title": "Data Augmentation for tabular data on inbalanced dataset",
            "content": "How to augment highly inbalanced data with fake data . import torch import torch.nn as nn import torch.nn.functional as F from torch import nn, optim from torch.autograd import Variable import pandas as pd import numpy as np from sklearn import preprocessing from sklearn.model_selection import train_test_split import mlprepare as mlp from sklearn.ensemble import RandomForestClassifier from sklearn.metrics import confusion_matrix . device = torch.device(&#39;cuda&#39; if torch.cuda.is_available() else &#39;cpu&#39;) device . device(type=&#39;cpu&#39;) . DATA_PATH = &#39;data/creditcard.csv&#39; . df = pd.read_csv(DATA_PATH, sep=&#39;,&#39;) df.head() . Time V1 V2 V3 V4 V5 V6 V7 V8 V9 ... V21 V22 V23 V24 V25 V26 V27 V28 Amount Class . 0 0.0 | -1.359807 | -0.072781 | 2.536347 | 1.378155 | -0.338321 | 0.462388 | 0.239599 | 0.098698 | 0.363787 | ... | -0.018307 | 0.277838 | -0.110474 | 0.066928 | 0.128539 | -0.189115 | 0.133558 | -0.021053 | 149.62 | 0 | . 1 0.0 | 1.191857 | 0.266151 | 0.166480 | 0.448154 | 0.060018 | -0.082361 | -0.078803 | 0.085102 | -0.255425 | ... | -0.225775 | -0.638672 | 0.101288 | -0.339846 | 0.167170 | 0.125895 | -0.008983 | 0.014724 | 2.69 | 0 | . 2 1.0 | -1.358354 | -1.340163 | 1.773209 | 0.379780 | -0.503198 | 1.800499 | 0.791461 | 0.247676 | -1.514654 | ... | 0.247998 | 0.771679 | 0.909412 | -0.689281 | -0.327642 | -0.139097 | -0.055353 | -0.059752 | 378.66 | 0 | . 3 1.0 | -0.966272 | -0.185226 | 1.792993 | -0.863291 | -0.010309 | 1.247203 | 0.237609 | 0.377436 | -1.387024 | ... | -0.108300 | 0.005274 | -0.190321 | -1.175575 | 0.647376 | -0.221929 | 0.062723 | 0.061458 | 123.50 | 0 | . 4 2.0 | -1.158233 | 0.877737 | 1.548718 | 0.403034 | -0.407193 | 0.095921 | 0.592941 | -0.270533 | 0.817739 | ... | -0.009431 | 0.798278 | -0.137458 | 0.141267 | -0.206010 | 0.502292 | 0.219422 | 0.215153 | 69.99 | 0 | . 5 rows × 31 columns . df_base = df.copy() . cols = df_base.columns . We need to normalize Time and Amount . mean_time=df_base[&#39;Time&#39;].mean() mean_amount=df_base[&#39;Amount&#39;].mean() std_time=df_base[&#39;Time&#39;].std() std_amount=df_base[&#39;Amount&#39;].std() df_base[&#39;Time&#39;]=(df_base[&#39;Time&#39;]-mean_time)/std_time df_base[&#39;Amount&#39;]=(df_base[&#39;Amount&#39;]-mean_amount)/std_amount . Class=1 means that this was indeed a fraud case, class=0 means no fraud. This dataset is highly imbalanced: . df_base[&#39;Class&#39;].value_counts() . 0 284315 1 492 Name: Class, dtype: int64 . I want to create fake data based on the 492 cases, which I will then use to improve the model. Let&#39;s first train a simple RandomForest. . X_train, X_test, y_train, y_test = mlp.split_df(df_base, dep_var=&#39;Class&#39;, test_size=0.3, split_mode=&#39;random&#39;) . y_test.value_counts() . 0 85286 1 157 Name: Class, dtype: int64 . #Ratio of the two classes: y_test.value_counts()[0]/y_test.value_counts()[1] . 543.2229299363057 . RandomForest with Oversampling . Let&#39;s first use the class_weight provided by sklearn to deal with this highly inbalanced data. . def rf(xs, y, n_estimators=40, max_samples=500, max_features=0.5, min_samples_leaf=5, **kwargs): return RandomForestClassifier(n_jobs=-1, n_estimators=n_estimators, max_samples=max_samples, max_features=max_features, min_samples_leaf=min_samples_leaf, oob_score=True, class_weight={0:1,1:543}).fit(xs, y) . m = rf(X_train, y_train) . confusion_matrix(y_test, np.round(m.predict(X_test))) . array([[85278, 8], [ 118, 39]], dtype=int64) . With this technique we get about 39 out of 157 Fraud cases, although the results vary quite a lot! . Fake Data with VAE . We want only the data points where y_train/test_train =1 . X_train_fraud = X_train.iloc[np.where(y_train==1)[0]] X_test_fraud = X_test.iloc[np.where(y_test==1)[0]] . Let&#39;s build a dataloader for our data, still keeping the pre-defined training/test datasets the way they were. . from torch.utils.data import Dataset, DataLoader class DataBuilder(Dataset): def __init__(self, dataset): self.x = dataset.values self.x = torch.from_numpy(self.x).to(torch.float) self.len=self.x.shape[0] def __getitem__(self,index): return self.x[index] def __len__(self): return self.len . traindata_set=DataBuilder(X_train_fraud) testdata_set=DataBuilder(X_test_fraud) trainloader=DataLoader(dataset=traindata_set,batch_size=1024) testloader=DataLoader(dataset=testdata_set,batch_size=1024) . Define the Variational Autoencoder (for more information check out my earlier blogpost). . class Autoencoder(nn.Module): def __init__(self,D_in,H=50,H2=12,latent_dim=3): #Encoder super(Autoencoder,self).__init__() self.linear1=nn.Linear(D_in,H) self.lin_bn1 = nn.BatchNorm1d(num_features=H) self.linear2=nn.Linear(H,H2) self.lin_bn2 = nn.BatchNorm1d(num_features=H2) self.linear3=nn.Linear(H2,H2) self.lin_bn3 = nn.BatchNorm1d(num_features=H2) # Latent vectors mu and sigma self.fc1 = nn.Linear(H2, latent_dim) self.bn1 = nn.BatchNorm1d(num_features=latent_dim) self.fc21 = nn.Linear(latent_dim, latent_dim) self.fc22 = nn.Linear(latent_dim, latent_dim) # Sampling vector self.fc3 = nn.Linear(latent_dim, latent_dim) self.fc_bn3 = nn.BatchNorm1d(latent_dim) self.fc4 = nn.Linear(latent_dim, H2) self.fc_bn4 = nn.BatchNorm1d(H2) # Decoder self.linear4=nn.Linear(H2,H2) self.lin_bn4 = nn.BatchNorm1d(num_features=H2) self.linear5=nn.Linear(H2,H) self.lin_bn5 = nn.BatchNorm1d(num_features=H) self.linear6=nn.Linear(H,D_in) self.lin_bn6 = nn.BatchNorm1d(num_features=D_in) self.relu = nn.ReLU() def encode(self, x): lin1 = self.relu(self.lin_bn1(self.linear1(x))) lin2 = self.relu(self.lin_bn2(self.linear2(lin1))) lin3 = self.relu(self.lin_bn3(self.linear3(lin2))) fc1 = F.relu(self.bn1(self.fc1(lin3))) r1 = self.fc21(fc1) r2 = self.fc22(fc1) return r1, r2 def reparameterize(self, mu, logvar): if self.training: std = logvar.mul(0.5).exp_() eps = Variable(std.data.new(std.size()).normal_()) return eps.mul(std).add_(mu) else: return mu def decode(self, z): fc3 = self.relu(self.fc_bn3(self.fc3(z))) fc4 = self.relu(self.fc_bn4(self.fc4(fc3))) lin4 = self.relu(self.lin_bn4(self.linear4(fc4))) lin5 = self.relu(self.lin_bn5(self.linear5(lin4))) return self.lin_bn6(self.linear6(lin5)) def forward(self, x): mu, logvar = self.encode(x) z = self.reparameterize(mu, logvar) return self.decode(z), mu, logvar . class customLoss(nn.Module): def __init__(self): super(customLoss, self).__init__() self.mse_loss = nn.MSELoss(reduction=&quot;sum&quot;) # x_recon ist der im forward im Model erstellte recon_batch, x ist der originale x Batch, mu ist mu und logvar ist logvar def forward(self, x_recon, x, mu, logvar): loss_MSE = self.mse_loss(x_recon, x) loss_KLD = -0.5 * torch.sum(1 + logvar - mu.pow(2) - logvar.exp()) return loss_MSE + loss_KLD . D_in = traindata_set.x.shape[1] H = 50 H2 = 12 model = Autoencoder(D_in, H, H2).to(device) optimizer = optim.Adam(model.parameters(), lr=1e-3) . loss_mse = customLoss() . Train Model . log_interval = 50 val_losses = [] train_losses = [] test_losses = [] . def train(epoch): model.train() train_loss = 0 for batch_idx, data in enumerate(trainloader): data = data.to(device) optimizer.zero_grad() recon_batch, mu, logvar = model(data) loss = loss_mse(recon_batch, data, mu, logvar) loss.backward() train_loss += loss.item() optimizer.step() if epoch % 200 == 0: print(&#39;====&gt; Epoch: {} Average training loss: {:.4f}&#39;.format( epoch, train_loss / len(trainloader.dataset))) train_losses.append(train_loss / len(trainloader.dataset)) . def test(epoch): with torch.no_grad(): test_loss = 0 for batch_idx, data in enumerate(testloader): data = data.to(device) optimizer.zero_grad() recon_batch, mu, logvar = model(data) loss = loss_mse(recon_batch, data, mu, logvar) test_loss += loss.item() if epoch % 200 == 0: print(&#39;====&gt; Epoch: {} Average test loss: {:.4f}&#39;.format( epoch, test_loss / len(testloader.dataset))) test_losses.append(test_loss / len(testloader.dataset)) . epochs = 1500 for epoch in range(1, epochs + 1): train(epoch) test(epoch) . ====&gt; Epoch: 200 Average training loss: 706.2121 ====&gt; Epoch: 200 Average test loss: 590.0016 ====&gt; Epoch: 400 Average training loss: 620.5279 ====&gt; Epoch: 400 Average test loss: 521.3142 ====&gt; Epoch: 600 Average training loss: 566.4392 ====&gt; Epoch: 600 Average test loss: 477.5008 ====&gt; Epoch: 800 Average training loss: 521.7474 ====&gt; Epoch: 800 Average test loss: 440.3243 ====&gt; Epoch: 1000 Average training loss: 481.2092 ====&gt; Epoch: 1000 Average test loss: 407.7625 ====&gt; Epoch: 1200 Average training loss: 434.3898 ====&gt; Epoch: 1200 Average test loss: 362.2760 ====&gt; Epoch: 1400 Average training loss: 396.9551 ====&gt; Epoch: 1400 Average test loss: 343.7408 . We&#39;re still improving so keep going . epochs = 2500 optimizer = optim.Adam(model.parameters(), lr=1e-3) for epoch in range(1, epochs + 1): train(epoch) test(epoch) . ====&gt; Epoch: 200 Average training loss: 343.3472 ====&gt; Epoch: 200 Average test loss: 300.3575 ====&gt; Epoch: 400 Average training loss: 310.5800 ====&gt; Epoch: 400 Average test loss: 285.6697 ====&gt; Epoch: 600 Average training loss: 281.8408 ====&gt; Epoch: 600 Average test loss: 263.7150 ====&gt; Epoch: 800 Average training loss: 256.1950 ====&gt; Epoch: 800 Average test loss: 244.9427 ====&gt; Epoch: 1000 Average training loss: 232.6077 ====&gt; Epoch: 1000 Average test loss: 236.3014 ====&gt; Epoch: 1200 Average training loss: 211.2899 ====&gt; Epoch: 1200 Average test loss: 217.6404 ====&gt; Epoch: 1400 Average training loss: 191.3525 ====&gt; Epoch: 1400 Average test loss: 205.8287 ====&gt; Epoch: 1600 Average training loss: 174.0826 ====&gt; Epoch: 1600 Average test loss: 189.0589 ====&gt; Epoch: 1800 Average training loss: 157.4292 ====&gt; Epoch: 1800 Average test loss: 175.6006 ====&gt; Epoch: 2000 Average training loss: 143.2475 ====&gt; Epoch: 2000 Average test loss: 177.1668 ====&gt; Epoch: 2200 Average training loss: 129.9684 ====&gt; Epoch: 2200 Average test loss: 160.4641 ====&gt; Epoch: 2400 Average training loss: 117.6745 ====&gt; Epoch: 2400 Average test loss: 150.9483 . epochs = 500 optimizer = optim.Adam(model.parameters(), lr=1e-3) for epoch in range(1, epochs + 1): train(epoch) test(epoch) . ====&gt; Epoch: 200 Average training loss: 54.6816 ====&gt; Epoch: 200 Average test loss: 129.6853 ====&gt; Epoch: 400 Average training loss: 48.5159 ====&gt; Epoch: 400 Average test loss: 134.4429 . Let&#39;s look at the results: . with torch.no_grad(): for batch_idx, data in enumerate(testloader): data = data.to(device) optimizer.zero_grad() recon_batch, mu, logvar = model(data) . recon_row = recon_batch[0].cpu().numpy() recon_row = np.append(recon_row, [1]) real_row = testloader.dataset.x[0].cpu().numpy() real_row = np.append(real_row, [1]) . df = pd.DataFrame(np.stack((recon_row, real_row)), columns = cols) df . Time V1 V2 V3 V4 V5 V6 V7 V8 V9 ... V21 V22 V23 V24 V25 V26 V27 V28 Amount Class . 0 -0.196971 | -7.667089 | 5.699276 | -10.15090 | 10.077229 | -7.307253 | -2.589641 | -9.824335 | 3.019747 | -7.658296 | ... | 1.073921 | 0.034662 | 0.247951 | 0.00464 | -0.037674 | 0.597619 | 0.763070 | -0.609457 | -0.377716 | 1.0 | . 1 0.910404 | -5.839191 | 7.151532 | -12.81676 | 7.031115 | -9.651272 | -2.938427 | -11.543207 | 4.843626 | -3.494276 | ... | 2.462056 | 1.054865 | 0.530481 | 0.47267 | -0.275998 | 0.282435 | 0.104886 | 0.254417 | 0.910404 | 1.0 | . 2 rows × 31 columns . sigma = torch.exp(logvar/2) . mu.mean(axis=0), sigma.mean(axis=0) . (tensor([0.0001, 0.0163, 0.0400]), tensor([0.9976, 0.0370, 0.0381])) . # sample z from q no_samples = 20 q = torch.distributions.Normal(mu.mean(axis=0), sigma.mean(axis=0)) z = q.rsample(sample_shape=torch.Size([no_samples])) . with torch.no_grad(): pred = model.decode(z).cpu().numpy() . df_fake = pd.DataFrame(pred) df_fake[&#39;Class&#39;]=1 df_fake.columns = cols df_fake[&#39;Class&#39;] = np.round(df_fake[&#39;Class&#39;]).astype(int) df_fake[&#39;Time&#39;] = (df_fake[&#39;Time&#39;]*std_time)+mean_time df_fake[&#39;Amount&#39;] = (df_fake[&#39;Amount&#39;]*std_amount)+mean_amount df_fake.head() . Time V1 V2 V3 V4 V5 V6 V7 V8 V9 ... V21 V22 V23 V24 V25 V26 V27 V28 Amount Class . 0 -1.014143 | 1.505616 | -4.616234 | 7.718655 | -0.977422 | 8.594662 | -3.198405 | -6.944025 | -5.043085 | 2.561653 | ... | 1.094700 | 0.510489 | -1.254657 | -0.085117 | 0.283567 | -0.268765 | 3.025049 | 0.929408 | -79.125496 | 1 | . 1 -1.810440 | -13.005595 | 1.212420 | 5.370727 | 2.069537 | -1.141557 | -3.816671 | -6.958980 | 4.140651 | -1.208175 | ... | 0.902933 | -0.573067 | 1.209823 | 0.543091 | 0.666637 | -0.524895 | 0.204588 | -0.074243 | -380.632935 | 1 | . 2 -1.152523 | 12.006341 | -3.014931 | 4.485871 | -1.155190 | 10.059814 | -3.355832 | -8.342437 | -8.336978 | 2.741910 | ... | -0.101801 | 1.417866 | -2.335097 | 0.034988 | -0.466923 | -0.012957 | 2.653872 | 1.081970 | -163.960175 | 1 | . 3 0.228914 | -5.935965 | -1.644437 | -6.354884 | 7.788726 | -0.055751 | -1.726003 | 0.577209 | 1.638260 | -5.880371 | ... | -5.350942 | 2.994604 | -0.079382 | -1.020990 | -0.090167 | 0.395981 | -1.590370 | -1.090804 | 9.417862 | 1 | . 4 0.180823 | -3.444491 | 4.722339 | -4.571048 | 4.998073 | -4.543203 | -0.816252 | -5.482205 | 3.643872 | -4.685173 | ... | -1.748235 | 1.525022 | 0.258438 | -0.465014 | 0.064509 | 0.277528 | 1.127516 | 0.161839 | 171.483337 | 1 | . 5 rows × 31 columns . df_fake[&#39;Amount&#39;].mean() . 121.77293 . df.groupby(&#39;Class&#39;).mean()[&#39;Amount&#39;] . Class 0 88.291022 1 122.211321 Name: Amount, dtype: float64 . Use fake data for oversampling in RandomForest . y_train.value_counts() . 0 199029 1 335 Name: Class, dtype: int64 . So let&#39;s build about 190.000 fake fraud detection cases: . no_samples = 190_000 q = torch.distributions.Normal(mu.mean(axis=0), sigma.mean(axis=0)) z = q.rsample(sample_shape=torch.Size([no_samples])) . with torch.no_grad(): pred = model.decode(z).cpu().numpy() . Concat to our X_train: . X_train_augmented = np.vstack((X_train.values, pred)) y_train_augmented = np.append(y_train.values, np.repeat(1,no_samples)) X_train_augmented.shape . (389364, 30) . We now have roughly as many fraud cases as we have non-fraud cases. . Train RandomForest . def rf_aug(xs, y, n_estimators=40, max_samples=500, max_features=0.5, min_samples_leaf=5, **kwargs): return RandomForestClassifier(n_jobs=-1, n_estimators=n_estimators, max_samples=max_samples, max_features=max_features, min_samples_leaf=min_samples_leaf, oob_score=True).fit(xs, y) . m_aug = rf_aug(X_train_augmented, y_train_augmented) confusion_matrix(y_test, np.round(m_aug.predict(X_test))) . array([[84963, 323], [ 30, 127]], dtype=int64) . confusion_matrix(y_test, np.round(m.predict(X_test))) . array([[85278, 8], [ 118, 39]], dtype=int64) . Look at that! We managed to find 127 out of 157! If our goal was to detect as many of the fraud cases, then we highly succeeded. Maybe you should think of this technique when you&#39;re dealing with highly inbalanced datasets in the future. .",
            "url": "https://lschmiddey.github.io/fastpages_/2021/03/17/data-augmentation-tabular-data.html",
            "relUrl": "/2021/03/17/data-augmentation-tabular-data.html",
            "date": " • Mar 17, 2021"
        }
        
    
  
    
        ,"post12": {
            "title": "Data Augmentation for tabular data",
            "content": "How to create fake tabular data with a variational autoencoder to improve deep learning algorithms . To train deeplearning models the more data the better. When we&#39;re thinking of image data, the deeplearnig community thought about a lot of tricks how to enhance the model given a dataset of images. Meaning that by rotating, flipping, blurring etc. the image we can create more input data and also improve our model. . However, when thinking about tabular data, only few of these techniques exist. In this blogpost I want to show you how to create a variational autoencoder and make use of data augmentation. I will create fake data, which is sampled from the learned distribution of the underlying data. . import torch import torch.nn as nn import torch.nn.functional as F from torch import nn, optim from torch.autograd import Variable import pandas as pd import numpy as np from sklearn import preprocessing from sklearn.model_selection import train_test_split . device = torch.device(&#39;cuda&#39; if torch.cuda.is_available() else &#39;cpu&#39;) device . device(type=&#39;cpu&#39;) . Define path to dataset . DATA_PATH = &#39;data/wine.csv&#39; . Dataset Overview . df_base = pd.read_csv(DATA_PATH, sep=&#39;,&#39;) df_base.head() . Wine Alcohol Malic.acid Ash Acl Mg Phenols Flavanoids Nonflavanoid.phenols Proanth Color.int Hue OD Proline . 0 1 | 14.23 | 1.71 | 2.43 | 15.6 | 127 | 2.80 | 3.06 | 0.28 | 2.29 | 5.64 | 1.04 | 3.92 | 1065 | . 1 1 | 13.20 | 1.78 | 2.14 | 11.2 | 100 | 2.65 | 2.76 | 0.26 | 1.28 | 4.38 | 1.05 | 3.40 | 1050 | . 2 1 | 13.16 | 2.36 | 2.67 | 18.6 | 101 | 2.80 | 3.24 | 0.30 | 2.81 | 5.68 | 1.03 | 3.17 | 1185 | . 3 1 | 14.37 | 1.95 | 2.50 | 16.8 | 113 | 3.85 | 3.49 | 0.24 | 2.18 | 7.80 | 0.86 | 3.45 | 1480 | . 4 1 | 13.24 | 2.59 | 2.87 | 21.0 | 118 | 2.80 | 2.69 | 0.39 | 1.82 | 4.32 | 1.04 | 2.93 | 735 | . cols = df_base.columns . Build Data Loader . def load_and_standardize_data(path): # read in from csv df = pd.read_csv(path, sep=&#39;,&#39;) # replace nan with -99 df = df.fillna(-99) df = df.values.reshape(-1, df.shape[1]).astype(&#39;float32&#39;) # randomly split X_train, X_test = train_test_split(df, test_size=0.3, random_state=42) # standardize values scaler = preprocessing.StandardScaler() X_train = scaler.fit_transform(X_train) X_test = scaler.transform(X_test) return X_train, X_test, scaler . from torch.utils.data import Dataset, DataLoader class DataBuilder(Dataset): def __init__(self, path, train=True): self.X_train, self.X_test, self.standardizer = load_and_standardize_data(DATA_PATH) if train: self.x = torch.from_numpy(self.X_train) self.len=self.x.shape[0] else: self.x = torch.from_numpy(self.X_test) self.len=self.x.shape[0] del self.X_train del self.X_test def __getitem__(self,index): return self.x[index] def __len__(self): return self.len . traindata_set=DataBuilder(DATA_PATH, train=True) testdata_set=DataBuilder(DATA_PATH, train=False) trainloader=DataLoader(dataset=traindata_set,batch_size=1024) testloader=DataLoader(dataset=testdata_set,batch_size=1024) . type(trainloader.dataset.x), type(testloader.dataset.x) . (torch.Tensor, torch.Tensor) . trainloader.dataset.x.shape, testloader.dataset.x.shape . (torch.Size([124, 14]), torch.Size([54, 14])) . trainloader.dataset.x . tensor([[ 1.3598, 0.6284, 1.0812, ..., -0.6414, -1.0709, -0.5182], [ 0.0628, -0.5409, -0.6130, ..., 0.3465, 1.3308, -0.2151], [ 0.0628, -0.7557, -1.2870, ..., 0.4324, -0.3984, 0.0420], ..., [-1.2343, 1.6904, -0.4855, ..., 1.0338, 0.5485, 2.6682], [ 0.0628, -0.3261, -0.7952, ..., 0.0029, -0.7415, -0.7983], [ 0.0628, -0.7437, 0.0428, ..., -0.6843, 1.0700, -0.9861]]) . Build model . class Autoencoder(nn.Module): def __init__(self,D_in,H=50,H2=12,latent_dim=3): #Encoder super(Autoencoder,self).__init__() self.linear1=nn.Linear(D_in,H) self.lin_bn1 = nn.BatchNorm1d(num_features=H) self.linear2=nn.Linear(H,H2) self.lin_bn2 = nn.BatchNorm1d(num_features=H2) self.linear3=nn.Linear(H2,H2) self.lin_bn3 = nn.BatchNorm1d(num_features=H2) # Latent vectors mu and sigma self.fc1 = nn.Linear(H2, latent_dim) self.bn1 = nn.BatchNorm1d(num_features=latent_dim) self.fc21 = nn.Linear(latent_dim, latent_dim) self.fc22 = nn.Linear(latent_dim, latent_dim) # Sampling vector self.fc3 = nn.Linear(latent_dim, latent_dim) self.fc_bn3 = nn.BatchNorm1d(latent_dim) self.fc4 = nn.Linear(latent_dim, H2) self.fc_bn4 = nn.BatchNorm1d(H2) # Decoder self.linear4=nn.Linear(H2,H2) self.lin_bn4 = nn.BatchNorm1d(num_features=H2) self.linear5=nn.Linear(H2,H) self.lin_bn5 = nn.BatchNorm1d(num_features=H) self.linear6=nn.Linear(H,D_in) self.lin_bn6 = nn.BatchNorm1d(num_features=D_in) self.relu = nn.ReLU() def encode(self, x): lin1 = self.relu(self.lin_bn1(self.linear1(x))) lin2 = self.relu(self.lin_bn2(self.linear2(lin1))) lin3 = self.relu(self.lin_bn3(self.linear3(lin2))) fc1 = F.relu(self.bn1(self.fc1(lin3))) r1 = self.fc21(fc1) r2 = self.fc22(fc1) return r1, r2 def reparameterize(self, mu, logvar): if self.training: std = logvar.mul(0.5).exp_() eps = Variable(std.data.new(std.size()).normal_()) return eps.mul(std).add_(mu) else: return mu def decode(self, z): fc3 = self.relu(self.fc_bn3(self.fc3(z))) fc4 = self.relu(self.fc_bn4(self.fc4(fc3))) lin4 = self.relu(self.lin_bn4(self.linear4(fc4))) lin5 = self.relu(self.lin_bn5(self.linear5(lin4))) return self.lin_bn6(self.linear6(lin5)) def forward(self, x): mu, logvar = self.encode(x) z = self.reparameterize(mu, logvar) return self.decode(z), mu, logvar . class customLoss(nn.Module): def __init__(self): super(customLoss, self).__init__() self.mse_loss = nn.MSELoss(reduction=&quot;sum&quot;) def forward(self, x_recon, x, mu, logvar): loss_MSE = self.mse_loss(x_recon, x) loss_KLD = -0.5 * torch.sum(1 + logvar - mu.pow(2) - logvar.exp()) return loss_MSE + loss_KLD . If you want to better understand the variational autoencoder technique, look here. . For better understanding this AutoencoderClass, let me go briefly through it. This is a variational autoencoder (VAE) with two hidden layers, which (by default, but you can change this) 50 and then 12 activations. The latent factors are set to 3 (you can change that, too). So we&#39;re first exploding our initially 14 variables to 50 activations, then condensing it to 12, then to 3. From these 3 latent factors we then sample to recreate the original 14 values. We do that by inflating the 3 latent factors back to 12, then 50 and finally 14 activations (we decode the latent factors so to speak). With this reconstructed batch (recon_batch) we compare it with the original batch, computate our loss and adjust the weights and biases via our gradient (our optimizer here will be Adam). . D_in = data_set.x.shape[1] H = 50 H2 = 12 model = Autoencoder(D_in, H, H2).to(device) optimizer = optim.Adam(model.parameters(), lr=1e-3) . loss_mse = customLoss() . Train Model . epochs = 1500 log_interval = 50 val_losses = [] train_losses = [] test_losses = [] . def train(epoch): model.train() train_loss = 0 for batch_idx, data in enumerate(trainloader): data = data.to(device) optimizer.zero_grad() recon_batch, mu, logvar = model(data) loss = loss_mse(recon_batch, data, mu, logvar) loss.backward() train_loss += loss.item() optimizer.step() if epoch % 200 == 0: print(&#39;====&gt; Epoch: {} Average training loss: {:.4f}&#39;.format( epoch, train_loss / len(trainloader.dataset))) train_losses.append(train_loss / len(trainloader.dataset)) . def test(epoch): with torch.no_grad(): test_loss = 0 for batch_idx, data in enumerate(testloader): data = data.to(device) optimizer.zero_grad() recon_batch, mu, logvar = model(data) loss = loss_mse(recon_batch, data, mu, logvar) test_loss += loss.item() if epoch % 200 == 0: print(&#39;====&gt; Epoch: {} Average test loss: {:.4f}&#39;.format( epoch, test_loss / len(testloader.dataset))) test_losses.append(test_loss / len(testloader.dataset)) . for epoch in range(1, epochs + 1): train(epoch) test(epoch) . ====&gt; Epoch: 200 Average training loss: 12.3501 ====&gt; Epoch: 200 Average test loss: 11.7777 ====&gt; Epoch: 400 Average training loss: 10.1168 ====&gt; Epoch: 400 Average test loss: 8.9987 ====&gt; Epoch: 600 Average training loss: 9.2956 ====&gt; Epoch: 600 Average test loss: 9.3548 ====&gt; Epoch: 800 Average training loss: 8.9570 ====&gt; Epoch: 800 Average test loss: 8.9647 ====&gt; Epoch: 1000 Average training loss: 8.6688 ====&gt; Epoch: 1000 Average test loss: 8.5866 ====&gt; Epoch: 1200 Average training loss: 8.3341 ====&gt; Epoch: 1200 Average test loss: 8.8371 ====&gt; Epoch: 1400 Average training loss: 8.4063 ====&gt; Epoch: 1400 Average test loss: 8.7891 . We we&#39;re able to reduce the training and test loss but quite a bit, let&#39;s have a look at how the fake results actually look like vs the real results: . with torch.no_grad(): for batch_idx, data in enumerate(testloader): data = data.to(device) optimizer.zero_grad() recon_batch, mu, logvar = model(data) . scaler = trainloader.dataset.standardizer recon_row = scaler.inverse_transform(recon_batch[0].cpu().numpy()) real_row = scaler.inverse_transform(testloader.dataset.x[0].cpu().numpy()) . df = pd.DataFrame(np.stack((recon_row, real_row)), columns = cols) df . Wine Alcohol Malic.acid Ash Acl Mg Phenols Flavanoids Nonflavanoid.phenols Proanth Color.int Hue OD Proline . 0 1.002792 | 13.535107 | 2.010303 | 2.557292 | 18.198132 | 112.606842 | 2.737524 | 2.807587 | 0.320866 | 1.738254 | 4.899318 | 1.078039 | 3.187276 | 1013.391479 | . 1 1.000000 | 13.640000 | 3.100000 | 2.560000 | 15.200000 | 116.000000 | 2.700000 | 3.030000 | 0.170000 | 1.660000 | 5.100000 | 0.960000 | 3.360000 | 845.000000 | . Not to bad right (the first row is the reconstructed row, the second one the real row from the data)? However, what we want is to built this row not with the real input so to speak, since right now we were giving the model the complete rows with their 14 columns, condensed it to 3 input parameters, just to blow it up again to the corresponding 14 columns. What I want to do is to create these 14 rows by giving the model 3 latent factors as input. Let&#39;s have a look at these latent variables. . sigma = torch.exp(logvar/2) . mu[1], sigma[1] . (tensor([-0.9960, -0.8502, -0.0043]), tensor([0.2555, 0.4801, 0.9888])) . Mu represents the mean for each of our latent factor values, logvar the log of the standard deviation. Each of these have a distribution by itself. We have 54 cases in our test data, so we have 3x54 different mu and logvar. We can have a look at the distribution of each of the 3 latent variables: . mu.mean(axis=0), sigma.mean(axis=0) . (tensor([-0.0088, 0.0051, 0.0044]), tensor([0.4514, 0.3897, 0.9986])) . All of the latent variables have a mean around zero, but the last latent factor has a wider standard deviation. So when we sample values from each of these latent variables, the last value will vary much more then the other two. I assume a normal distribution for all the latent factors. . # sample z from q no_samples = 20 q = torch.distributions.Normal(mu.mean(axis=0), sigma.mean(axis=0)) z = q.rsample(sample_shape=torch.Size([no_samples])) . z.shape . torch.Size([20, 3]) . z[:5] . tensor([[ 0.5283, 0.4519, 0.6792], [ 0.3664, -0.5569, -0.1531], [-0.5802, 0.4394, 1.8406], [-1.0136, -0.4239, 0.4524], [-0.0605, 0.3913, 0.8030]]) . With these three latent factors we can now start and create fake data for our dataset and see how it looks like: . with torch.no_grad(): pred = model.decode(z).cpu().numpy() . pred[1] . array([-0.24290268, -0.6087041 , -0.44325534, -0.7158908 , -0.15065292, -0.47845733, 0.26319185, 0.23732403, -0.22809544, 0.12187037, -0.8295655 , 0.44908378, 0.6173717 , -0.55648965], dtype=float32) . Create fake data from Autoencoder . fake_data = scaler.inverse_transform(pred) fake_data.shape . (20, 14) . df_fake = pd.DataFrame(fake_data, columns = cols) df_fake[&#39;Wine&#39;] = np.round(df_fake[&#39;Wine&#39;]).astype(int) df_fake[&#39;Wine&#39;] = np.where(df_fake[&#39;Wine&#39;]&lt;1, 1, df_fake[&#39;Wine&#39;]) df_fake.head(10) . Wine Alcohol Malic.acid Ash Acl Mg Phenols Flavanoids Nonflavanoid.phenols Proanth Color.int Hue OD Proline . 0 3 | 13.350755 | 3.817283 | 2.425754 | 21.229387 | 98.816788 | 1.682916 | 0.910786 | 0.450081 | 1.245882 | 8.242197 | 0.667928 | 1.705379 | 636.650818 | . 1 2 | 12.453159 | 1.916350 | 2.172731 | 18.977226 | 93.556114 | 2.444676 | 2.246270 | 0.335432 | 1.663583 | 3.166457 | 1.063876 | 3.050176 | 568.385925 | . 2 2 | 12.735057 | 2.404566 | 2.447556 | 20.400013 | 105.475235 | 1.937112 | 1.657119 | 0.385740 | 1.452577 | 4.242754 | 0.928397 | 2.467263 | 680.271545 | . 3 1 | 14.664644 | 1.517465 | 2.269279 | 12.428186 | 88.851791 | 3.354010 | 3.997237 | 0.265253 | 2.586414 | 7.366968 | 1.275564 | 3.170231 | 1516.662720 | . 4 3 | 13.160161 | 3.359397 | 2.415784 | 21.050211 | 99.859154 | 1.662516 | 0.929189 | 0.427978 | 1.135361 | 7.101127 | 0.708510 | 1.732820 | 640.412231 | . 5 2 | 12.453159 | 1.916350 | 2.172731 | 18.977226 | 93.556114 | 2.444676 | 2.246270 | 0.335432 | 1.663583 | 3.166457 | 1.063876 | 3.050176 | 568.385925 | . 6 2 | 12.520310 | 2.522696 | 2.375254 | 20.435560 | 92.619812 | 1.838333 | 1.361269 | 0.470815 | 1.221076 | 4.518130 | 0.906680 | 2.146883 | 583.079102 | . 7 3 | 12.877177 | 2.746192 | 2.395865 | 20.154610 | 97.263092 | 1.744550 | 1.187050 | 0.464942 | 1.160733 | 5.619783 | 0.836708 | 1.871472 | 665.485718 | . 8 2 | 12.679532 | 2.344776 | 2.331834 | 19.901327 | 97.031586 | 1.857117 | 1.495742 | 0.461352 | 1.239715 | 4.668478 | 0.934352 | 2.094139 | 680.778809 | . 9 2 | 13.062141 | 2.719065 | 2.461590 | 19.947014 | 103.352890 | 2.070540 | 1.566055 | 0.380154 | 1.293219 | 5.675068 | 0.852832 | 2.128047 | 778.582825 | . For comparison the real data: . df_base.sample(10) . Wine Alcohol Malic.acid Ash Acl Mg Phenols Flavanoids Nonflavanoid.phenols Proanth Color.int Hue OD Proline . 1 1 | 13.20 | 1.78 | 2.14 | 11.2 | 100 | 2.65 | 2.76 | 0.26 | 1.28 | 4.38 | 1.05 | 3.40 | 1050 | . 35 1 | 13.48 | 1.81 | 2.41 | 20.5 | 100 | 2.70 | 2.98 | 0.26 | 1.86 | 5.10 | 1.04 | 3.47 | 920 | . 114 2 | 12.08 | 1.39 | 2.50 | 22.5 | 84 | 2.56 | 2.29 | 0.43 | 1.04 | 2.90 | 0.93 | 3.19 | 385 | . 149 3 | 13.08 | 3.90 | 2.36 | 21.5 | 113 | 1.41 | 1.39 | 0.34 | 1.14 | 9.40 | 0.57 | 1.33 | 550 | . 158 3 | 14.34 | 1.68 | 2.70 | 25.0 | 98 | 2.80 | 1.31 | 0.53 | 2.70 | 13.00 | 0.57 | 1.96 | 660 | . 9 1 | 13.86 | 1.35 | 2.27 | 16.0 | 98 | 2.98 | 3.15 | 0.22 | 1.85 | 7.22 | 1.01 | 3.55 | 1045 | . 90 2 | 12.08 | 1.83 | 2.32 | 18.5 | 81 | 1.60 | 1.50 | 0.52 | 1.64 | 2.40 | 1.08 | 2.27 | 480 | . 47 1 | 13.90 | 1.68 | 2.12 | 16.0 | 101 | 3.10 | 3.39 | 0.21 | 2.14 | 6.10 | 0.91 | 3.33 | 985 | . 10 1 | 14.10 | 2.16 | 2.30 | 18.0 | 105 | 2.95 | 3.32 | 0.22 | 2.38 | 5.75 | 1.25 | 3.17 | 1510 | . 31 1 | 13.58 | 1.66 | 2.36 | 19.1 | 106 | 2.86 | 3.19 | 0.22 | 1.95 | 6.90 | 1.09 | 2.88 | 1515 | . Compare variables grouped by Wine . df_base.groupby(&#39;Wine&#39;).mean() . Alcohol Malic.acid Ash Acl Mg Phenols Flavanoids Nonflavanoid.phenols Proanth Color.int Hue OD Proline . Wine . 1 13.744746 | 2.010678 | 2.455593 | 17.037288 | 106.338983 | 2.840169 | 2.982373 | 0.290000 | 1.899322 | 5.528305 | 1.062034 | 3.157797 | 1115.711864 | . 2 12.278732 | 1.932676 | 2.244789 | 20.238028 | 94.549296 | 2.258873 | 2.080845 | 0.363662 | 1.630282 | 3.086620 | 1.056282 | 2.785352 | 519.507042 | . 3 13.153750 | 3.333750 | 2.437083 | 21.416667 | 99.312500 | 1.678750 | 0.781458 | 0.447500 | 1.153542 | 7.396250 | 0.682708 | 1.683542 | 629.895833 | . df_fake.groupby(&#39;Wine&#39;).mean() . Alcohol Malic.acid Ash Acl Mg Phenols Flavanoids Nonflavanoid.phenols Proanth Color.int Hue OD Proline . Wine . 1 13.812141 | 1.814212 | 2.482638 | 17.172688 | 107.468864 | 3.062387 | 3.344664 | 0.259955 | 2.162966 | 5.331643 | 1.147217 | 3.280716 | 1148.031372 | . 2 12.560544 | 2.157595 | 2.301805 | 19.696327 | 99.324005 | 2.254415 | 1.995140 | 0.366076 | 1.575015 | 3.791955 | 1.000527 | 2.741598 | 629.895203 | . 3 13.170316 | 3.413856 | 2.416369 | 20.929930 | 99.028229 | 1.683604 | 0.964315 | 0.443444 | 1.176529 | 7.288512 | 0.718357 | 1.745200 | 644.870056 | . That looks pretty convincing if you ask me. . To sum up, we&#39;ve built a variational autoencoder, which we trained on our trainingset. We checked whether our loss kept on improving based on the testset, which the autoencoder never saw for generating fake data. We then calculated the mean and standard deviation from our latent factors given the test data. We&#39;ve then sampled from this distribution to feed it back into our decoder to create some fake data. With this approach I am now able to create as much fake data derived from the underlying distribution as a want. And I think the results look promising. . You can take this approach to for example create data from under-represented in highly skewed datasets instead of just weighting them higher. The re-weighting approach might cause the algorithm to find relations where there are none, only because a few then overrepresented data points share this relation by random. With the shown approach, the learned distribution would take into account the high variance these features have and therefore will hopefully help the algorithm to not draw these false conclusions. . Stay tuned for the next blogpost, where I will show the shown approach in exactly this use case. .",
            "url": "https://lschmiddey.github.io/fastpages_/2021/03/14/tabular-data-variational-autoencoder.html",
            "relUrl": "/2021/03/14/tabular-data-variational-autoencoder.html",
            "date": " • Mar 14, 2021"
        }
        
    
  
    
        ,"post13": {
            "title": "MLP Tutorial",
            "content": "How to make use of the ml-prepare package . import mlprepare as mlp import pandas as pd import numpy . Load Data . df = pd.read_csv(&#39;TrainAndValid.csv&#39;, low_memory=False) . df.head() . SalesID SalePrice MachineID ModelID datasource auctioneerID YearMade MachineHoursCurrentMeter UsageBand saledate ... Undercarriage_Pad_Width Stick_Length Thumb Pattern_Changer Grouser_Type Backhoe_Mounting Blade_Type Travel_Controls Differential_Type Steering_Controls . 0 1139246 | 66000.0 | 999089 | 3157 | 121 | 3.0 | 2004 | 68.0 | Low | 11/16/2006 0:00 | ... | NaN | NaN | NaN | NaN | NaN | NaN | NaN | NaN | Standard | Conventional | . 1 1139248 | 57000.0 | 117657 | 77 | 121 | 3.0 | 1996 | 4640.0 | Low | 3/26/2004 0:00 | ... | NaN | NaN | NaN | NaN | NaN | NaN | NaN | NaN | Standard | Conventional | . 2 1139249 | 10000.0 | 434808 | 7009 | 121 | 3.0 | 2001 | 2838.0 | High | 2/26/2004 0:00 | ... | NaN | NaN | NaN | NaN | NaN | NaN | NaN | NaN | NaN | NaN | . 3 1139251 | 38500.0 | 1026470 | 332 | 121 | 3.0 | 2001 | 3486.0 | High | 5/19/2011 0:00 | ... | NaN | NaN | NaN | NaN | NaN | NaN | NaN | NaN | NaN | NaN | . 4 1139253 | 11000.0 | 1057373 | 17311 | 121 | 3.0 | 2007 | 722.0 | Medium | 7/23/2009 0:00 | ... | NaN | NaN | NaN | NaN | NaN | NaN | NaN | NaN | NaN | NaN | . 5 rows × 53 columns . to_keep = [&#39;SalePrice&#39;, &#39;MachineID&#39;, &#39;saledate&#39;, &#39;MachineHoursCurrentMeter&#39;, &#39;UsageBand&#39;] df = df[to_keep] df.head() . SalePrice MachineID saledate MachineHoursCurrentMeter UsageBand . 0 66000.0 | 999089 | 11/16/2006 0:00 | 68.0 | Low | . 1 57000.0 | 117657 | 3/26/2004 0:00 | 4640.0 | Low | . 2 10000.0 | 434808 | 2/26/2004 0:00 | 2838.0 | High | . 3 38500.0 | 1026470 | 5/19/2011 0:00 | 3486.0 | High | . 4 11000.0 | 1057373 | 7/23/2009 0:00 | 722.0 | Medium | . mlp Functions . df_to_type . date_type = [&#39;saledate&#39;] continuous_type = [&#39;SalePrice&#39;, &#39;MachineHoursCurrentMeter&#39;] categorical_type = [&#39;MachineID&#39;, &#39;UsageBand&#39;] . result = mlp.df_to_type(df, date_type, continuous_type, categorical_type) . result.head() . SalePrice MachineID saleWeek MachineHoursCurrentMeter UsageBand saleYear saleMonth saleDay saleDayofweek saleDayofyear saleIs_month_end saleIs_month_start saleIs_quarter_end saleIs_quarter_start saleIs_year_end saleIs_year_start saleElapsed . 0 66000.0 | 999089 | 46 | 68.0 | Low | 2006 | 11 | 16 | 3 | 320 | False | False | False | False | False | False | 1163635200 | . 1 57000.0 | 117657 | 13 | 4640.0 | Low | 2004 | 3 | 26 | 4 | 86 | False | False | False | False | False | False | 1080259200 | . 2 10000.0 | 434808 | 9 | 2838.0 | High | 2004 | 2 | 26 | 3 | 57 | False | False | False | False | False | False | 1077753600 | . 3 38500.0 | 1026470 | 20 | 3486.0 | High | 2011 | 5 | 19 | 3 | 139 | False | False | False | False | False | False | 1305763200 | . 4 11000.0 | 1057373 | 30 | 722.0 | Medium | 2009 | 7 | 23 | 3 | 204 | False | False | False | False | False | False | 1248307200 | . We automatically extracted some extra information from the date variable and transformed the categorical variables to the correct type. . result.dtypes . SalePrice float64 MachineID category saleWeek UInt32 MachineHoursCurrentMeter float64 UsageBand category saleYear int64 saleMonth int64 saleDay int64 saleDayofweek int64 saleDayofyear int64 saleIs_month_end bool saleIs_month_start bool saleIs_quarter_end bool saleIs_quarter_start bool saleIs_year_end bool saleIs_year_start bool saleElapsed object dtype: object . Let&#39;s only keep the saleYear and saleMonth from our date variable. . to_keep = [&#39;SalePrice&#39;, &#39;MachineID&#39;, &#39;MachineHoursCurrentMeter&#39;, &#39;UsageBand&#39;, &#39;saleYear&#39;, &#39;saleMonth&#39;] continuous_type = [&#39;SalePrice&#39;, &#39;MachineHoursCurrentMeter&#39;] categorical_type = [&#39;MachineID&#39;, &#39;UsageBand&#39;] result = result[to_keep] result.head() . SalePrice MachineID MachineHoursCurrentMeter UsageBand saleYear saleMonth . 0 66000.0 | 999089 | 68.0 | Low | 2006 | 11 | . 1 57000.0 | 117657 | 4640.0 | Low | 2004 | 3 | . 2 10000.0 | 434808 | 2838.0 | High | 2004 | 2 | . 3 38500.0 | 1026470 | 3486.0 | High | 2011 | 5 | . 4 11000.0 | 1057373 | 722.0 | Medium | 2009 | 7 | . split_df . Now, let&#39;s split the data into train and test, first randomly, then by a variable, then by a condition. . X_train, X_test, y_train, y_test = mlp.split_df(result, dep_var=&#39;SalePrice&#39;, test_size=0.3, split_mode=&#39;random&#39;) . X_train.shape, X_test.shape . ((288888, 5), (123810, 5)) . X_train, X_test, y_train, y_test = mlp.split_df(result, dep_var=&#39;SalePrice&#39;, test_size=0.3, split_mode=&#39;on_split_id&#39;, split_var=&#39;MachineID&#39;) . X_train.shape, X_test.shape . ((276523, 5), (136175, 5)) . #every row that fulfills this condition will be in the trainset cond = (result.saleYear&lt;2009) . X_train, X_test, y_train, y_test = mlp.split_df(result, dep_var=&#39;SalePrice&#39;, test_size=0.3, split_mode=&#39;on_condition&#39;, cond=cond) . X_train.shape, X_test.shape . ((288689, 5), (124009, 5)) . X_train.head() . MachineID MachineHoursCurrentMeter UsageBand saleYear saleMonth . 0 999089 | 68.0 | Low | 2006 | 11 | . 1 117657 | 4640.0 | Low | 2004 | 3 | . 2 434808 | 2838.0 | High | 2004 | 2 | . 5 1001274 | 508.0 | Low | 2008 | 12 | . 6 772701 | 11540.0 | High | 2004 | 8 | . cat_transform . X_train_, X_test_, dict_list, dict_inv_list = mlp.cat_transform(X_train, X_test, cat_type = categorical_type) . X_train_.head() . MachineID MachineHoursCurrentMeter UsageBand saleYear saleMonth . 0 62273 | 68.0 | 2 | 2006 | 11 | . 1 9581 | 4640.0 | 2 | 2004 | 3 | . 2 28730 | 2838.0 | 1 | 2004 | 2 | . 5 62837 | 508.0 | 2 | 2008 | 12 | . 6 48637 | 11540.0 | 1 | 2004 | 8 | . We changed the defined categorical types to int and saved the corresponding dictionaries. Also, we added a special token for NaN values. . dict_list[1] . {0: &#39;#NaN&#39;, 1: &#39;High&#39;, 2: &#39;Low&#39;, 3: &#39;Medium&#39;} . cont_standardize . Let&#39;s standardize the data. If we want specific columns to not be standardized, we can put them into the cat_type argument. If we have an ID to later match the results to, put it into the id_type argument and it will not be standardized. If you don&#39;t want the dependend variable to be standardized, set transform_y to False (also realize that you will not get the scaler_y object as an output). . categorical_type = [&#39;MachineID&#39;, &#39;UsageBand&#39;, &#39;saleYear&#39;, &#39;saleMonth&#39;] X_train_2, X_test_2, y_train_2, y_test_2, scaler, scaler_y = mlp.cont_standardize(X_train_, X_test_, y_train, y_test, cat_type=categorical_type, transform_y=True, path=&#39;&#39;, standardizer=&#39;StandardScaler&#39;) . y_train[:5] . 0 66000.0 1 57000.0 2 10000.0 5 26500.0 6 21000.0 Name: SalePrice, dtype: float64 . y_train_2[:5] . array([[ 1.53656444], [ 1.14173911], [-0.92012647], [-0.19628004], [-0.43756218]]) . X_train_2.head() . MachineID MachineHoursCurrentMeter UsageBand saleYear saleMonth . 0 62273 | -0.372846 | 2 | 2006 | 11 | . 1 9581 | 0.893532 | 2 | 2004 | 3 | . 2 28730 | 0.394404 | 1 | 2004 | 2 | . 5 62837 | -0.250972 | 2 | 2008 | 12 | . 6 48637 | 2.804732 | 1 | 2004 | 8 | . saleYear and saleMonth didn&#39;t get standardized, also the categorical variables didn&#39;t get standardized. .",
            "url": "https://lschmiddey.github.io/fastpages_/2021/02/01/mlp-Tutorial.html",
            "relUrl": "/2021/02/01/mlp-Tutorial.html",
            "date": " • Feb 1, 2021"
        }
        
    
  
    
        ,"post14": {
            "title": "How to build a web app with Streamlit",
            "content": "Combine Streamlit and Heroku to easily build and deploy a machine learning web-app . In this blog post I want to show how easy it is to build a web application with Streamlit and then use Heroku to deploy it and make it accessible for everyone. For this small web-app, I want to detect blobs in a given image. Furthermore, I want to be able to fiddle around with the parameters within the model and see the results immediately on the webpage. So let&#39;s first start with building our python program to detect blobs. . For this, we will make use of opencv-python, which already has a class with which we can detect blobs in images: the SimpleBlobDetector . import cv2 blob_params = cv2.SimpleBlobDetector_Params() blob_params.filterByInertia = False blob_params.filterByConvexity = False blob_params.filterByColor = True blob_params.blobColor = 0 blob_params.filterByCircularity = True blob_params.filterByArea = False blob_detector = cv2.SimpleBlobDetector_create(blob_params) . These are some of the parameters the class has got. Next, we fetch an image and use the algorithm to detect the biggest blob detected. . keypoints = blob_detector.detect(openCVim) # find largest blob if len(keypoints) &gt; 0: kp_max = keypoints[0] for kp in keypoints: if kp.size &gt; kp_max.size: kp_max = kp . And that&#39;s pretty much it. openCVim will be the input of our model, and kp_max the keypoint with the biggest size. What we need now is streamlit to easily create a webpage which will use this model. . import streamlit as st st.write(&quot;&quot;&quot; # Simple Blob Detection App Upload your image and see where the Blob is! &quot;&quot;&quot;) st.sidebar.header(&#39;User Input Parameters&#39;) . It&#39;s that easy. We created a header for our webpage and a sidebar with a different header. In this sidebar, we want to be able to fiddle around with some of the blob_params. . def user_input_features(): minCircularity = st.sidebar.slider(&#39;minCircularity&#39;, 0., 1., 0.8) minArea = st.sidebar.slider(&#39;minArea&#39;, 0, 1, 10) maxArea = st.sidebar.slider(&#39;maxArea&#39;, 0, 1, 100000) data = {&#39;minCircularity&#39;: minCircularity, &#39;minArea&#39;: minArea, &#39;maxArea&#39;: maxArea} features = pd.DataFrame(data, index=[0]) return features df = user_input_features() blob_params.minCircularity = df.minCircularity.values.item() blob_params.minArea = df.minArea.values.item() blob_params.maxArea = df.maxArea.values.item() st.subheader(&#39;User Input parameters&#39;) st.write(df) . We defined a function, which uses streamlits sidebar.slider function. The first value is the lowest value the slider can be, the second the largest value the slider can be and the last value is the default value. We then use these values to create a dataframe, which we use to fill the blob_params. So each time the user changes one of the values via the slider, the model get&#39;s a different parameter input and will automatically rerun the model. With st.subheader we give a subheader and then show the dataframe to the user with the chosen parameters. . uploaded_file = st.file_uploader(&quot;Choose an image...&quot;, type=&quot;jpg&quot;) if uploaded_file is not None: # Read in and make greyscale PILim = Image.open(uploaded_file).convert(&#39;L&#39;) # Make Numpy/OpenCV-compatible version openCVim = np.array(PILim) openCVim = cv2.bitwise_not(openCVim) st.image(openCVim, caption=&#39;Uploaded Image.&#39;, use_column_width=True) . Next, the user should upload an image. Only when this file is not None we will proceed with our modeling. We read the image in with PIL, put it to grayscale (in my experience for blob-detection that worked better) and transform it to an numpy array, which cv2 needs to create the model. . keypoints = blob_detector.detect(openCVim) # find largest blob if len(keypoints) &gt; 0: kp_max = keypoints[0] for kp in keypoints: if kp.size &gt; kp_max.size: kp_max = kp pts = np.array([kp_max.pt]) data_coordinates = {&#39;x_coordinate&#39;: int(pts[:, 0]), &#39;y_coordinate&#39;: int(pts[:, 1])} df_coordinates = pd.DataFrame(data_coordinates, index=[0]) im_with_keypoints = cv2.cvtColor(openCVim,cv2.COLOR_GRAY2RGB) # im_with_keypoints = cv2.circle(openCVim, (int(pts[:, 0]), int(pts[:, 1])), 50, color=(0,255,0), thickness=30, lineType=8, shift=0) im_with_keypoints = cv2.drawKeypoints(im_with_keypoints, [kp_max], np.array([]), (0,0,255), cv2.DRAW_MATCHES_FLAGS_DRAW_RICH_KEYPOINTS) st.image(im_with_keypoints, caption=&#39;Image with Blob.&#39;, use_column_width=True) st.write(df_coordinates) . Still in the if statement we progress by building the model, get the biggest blob and get the coordinates by calling kp_max.pt. We store these values in a dictionary to put it in a dataframe, which we show at the end of the page. We also use the coordinates to mark the calculated keypoint. Finally, we return the image with a circle around the detected image to the user. . And that&#39;s it, we build a fully functional web-app with streamlit. Finally, we want to deploy it on Heroku. After creating an account it should look something like this: . . Click on &quot;Create new App&quot;. . . . Use your git-repository to let Heroku deploy the web-app for you, click on connect and your done! It&#39;s that easy. Heroku requires three more files in your repository: . ⋅⋅ requirements.txt, where you specify the packages you use and the respective version ⋅⋅ Procfile, which tells Heroku how to start the Streamlit-app ⋅⋅* setup.sh, which is a shell script which tells the Heroku server how to deploy the Streamlit-app . Simply check out my git repository for an example. . After all is said and done, this is how the app looks like: . . . . Or simply check out the web-page. . I hope you enjoyed this post and stay tuned for the next one. . Lasse .",
            "url": "https://lschmiddey.github.io/fastpages_/2021/01/24/How-to-build-web-app-with-streamlit.html",
            "relUrl": "/2021/01/24/How-to-build-web-app-with-streamlit.html",
            "date": " • Jan 24, 2021"
        }
        
    
  
    
        ,"post15": {
            "title": "How to pre-process data for machine learning",
            "content": "A common task for almost all data science projects is to preprocess your data. This is especially the case for tabular data. In this blog I want to build a pre-process function which can handle will handle all these pre-processing steps for us. On top of that, I will add enough flexibility to that function to make it useful not just in this example. . Let&#39;s start by loading the data. . Imports . import numpy as np import pandas as pd import pickle from sklearn.model_selection import train_test_split from sklearn.preprocessing import StandardScaler, MinMaxScaler . We later want to save and load data with pickle, so let&#39;s define these functions: . def save_obj(obj, name ): with open(f&#39;{name}.pkl&#39;, &#39;wb&#39;) as f: pickle.dump(obj, f) def load_obj(name ): with open(f&#39;{name}.pkl&#39;, &#39;rb&#39;) as f: return pickle.load(f) . df = pd.read_csv(&#39;train.csv&#39;) . df.head() . Id MSSubClass MSZoning LotFrontage LotArea Street Alley LotShape LandContour Utilities ... PoolArea PoolQC Fence MiscFeature MiscVal MoSold YrSold SaleType SaleCondition SalePrice . 0 1 | 60 | RL | 65.0 | 8450 | Pave | NaN | Reg | Lvl | AllPub | ... | 0 | NaN | NaN | NaN | 0 | 2 | 2008 | WD | Normal | 208500 | . 1 2 | 20 | RL | 80.0 | 9600 | Pave | NaN | Reg | Lvl | AllPub | ... | 0 | NaN | NaN | NaN | 0 | 5 | 2007 | WD | Normal | 181500 | . 2 3 | 60 | RL | 68.0 | 11250 | Pave | NaN | IR1 | Lvl | AllPub | ... | 0 | NaN | NaN | NaN | 0 | 9 | 2008 | WD | Normal | 223500 | . 3 4 | 70 | RL | 60.0 | 9550 | Pave | NaN | IR1 | Lvl | AllPub | ... | 0 | NaN | NaN | NaN | 0 | 2 | 2006 | WD | Abnorml | 140000 | . 4 5 | 60 | RL | 84.0 | 14260 | Pave | NaN | IR1 | Lvl | AllPub | ... | 0 | NaN | NaN | NaN | 0 | 12 | 2008 | WD | Normal | 250000 | . 5 rows × 81 columns . df.shape . (1460, 81) . We&#39;ve got 81 columns in our data. That&#39;s a lot of data, for this blog we only need a couple of these variables. The function will then work for any length of datasets. We define which columns to keep and then check the data types. . to_keep = [&#39;Id&#39;, &#39;MSZoning&#39;, &#39;LotFrontage&#39;, &#39;LotArea&#39;, &#39;Street&#39;, &#39;OverallQual&#39;, &#39;YearBuilt&#39;, &#39;CentralAir&#39;, &#39;SaleType&#39;, &#39;SalePrice&#39;] . df = df[to_keep] df.head() . Id MSZoning LotFrontage LotArea Street OverallQual YearBuilt CentralAir SaleType SalePrice . 0 1 | RL | 65.0 | 8450 | Pave | 7 | 2003 | Y | WD | 208500 | . 1 2 | RL | 80.0 | 9600 | Pave | 6 | 1976 | Y | WD | 181500 | . 2 3 | RL | 68.0 | 11250 | Pave | 7 | 2001 | Y | WD | 223500 | . 3 4 | RL | 60.0 | 9550 | Pave | 7 | 1915 | Y | WD | 140000 | . 4 5 | RL | 84.0 | 14260 | Pave | 8 | 2000 | Y | WD | 250000 | . pd.set_option(&#39;display.max_rows&#39;, 20) df.dtypes . Id int64 MSZoning object LotFrontage float64 LotArea int64 Street object OverallQual int64 YearBuilt int64 CentralAir object SaleType object SalePrice int64 dtype: object . Datetime vs Continuous vs Categorical . In tabular data, there are usually four different data types: dates, continuous and categorical variables (of which boolean are a special type). We need to define which column is of which type. This dataset does not contain a datetime column, so I will define some random datetime data to show you how to cope with datetime data too. . df[&quot;Fake_date&quot;] = np.random.choice(pd.date_range(&#39;1980-01-01&#39;, &#39;2000-01-01&#39;), len(df)).astype(&#39;str&#39;) df[&quot;Fake_date_2&quot;] = np.random.choice(pd.date_range(&#39;1980-01-01&#39;, &#39;2000-01-01&#39;), len(df)).astype(&#39;str&#39;) . df.head() . Id MSZoning LotFrontage LotArea Street OverallQual YearBuilt CentralAir SaleType SalePrice Fake_date Fake_date_2 . 0 1 | RL | 65.0 | 8450 | Pave | 7 | 2003 | Y | WD | 208500 | 1985-12-22T00:00:00.000000000 | 1988-05-22T00:00:00.000000000 | . 1 2 | RL | 80.0 | 9600 | Pave | 6 | 1976 | Y | WD | 181500 | 1999-11-12T00:00:00.000000000 | 1983-08-11T00:00:00.000000000 | . 2 3 | RL | 68.0 | 11250 | Pave | 7 | 2001 | Y | WD | 223500 | 1998-03-07T00:00:00.000000000 | 1991-12-15T00:00:00.000000000 | . 3 4 | RL | 60.0 | 9550 | Pave | 7 | 1915 | Y | WD | 140000 | 1985-04-11T00:00:00.000000000 | 1980-11-27T00:00:00.000000000 | . 4 5 | RL | 84.0 | 14260 | Pave | 8 | 2000 | Y | WD | 250000 | 1980-12-04T00:00:00.000000000 | 1982-10-01T00:00:00.000000000 | . df.dtypes . Id int64 MSZoning object LotFrontage float64 LotArea int64 Street object OverallQual int64 YearBuilt int64 CentralAir object SaleType object SalePrice int64 Fake_date object Fake_date_2 object dtype: object . We now need to define which column should be of which type. We use four lists for this: . date_type = [&#39;Fake_date&#39;, &#39;Fake_date_2&#39;] continuous_type = [&#39;LotFrontage&#39;, &#39;LotArea&#39;, &#39;YearBuilt&#39;, &#39;SalePrice&#39;] categorical_type = [&#39;MSZoning&#39;, &#39;Street&#39;, &#39;OverallQual&#39;, &#39;SaleType&#39;,&#39;CentralAir&#39;] . I defined &#39;OverallQual&#39; as a category, because even though this variable is in ascending order, we do not know whether the difference from OverallQual of 6 and 7 is the same magnitude than OverallQual from 0 to 1. However, you can define this variable as continous as well. . We then define a small function, which will take our lists as input and transform our data to the correct data types. . def df_to_type(df, cont_type, cat_type): if cat_type is not None: df[cat_type] = df[cat_type].astype(&#39;category&#39;) for i in date_type: df[i] = pd.to_datetime(df[i]) return df . Did it work? . df_to_type(df, continuous_type, categorical_type) df.dtypes . Id int64 MSZoning category LotFrontage float64 LotArea int64 Street category OverallQual category YearBuilt int64 CentralAir category SaleType category SalePrice int64 Fake_date datetime64[ns] Fake_date_2 datetime64[ns] dtype: object . That looks good! We can now make use of pandas various datetime functions to add more informations to our data. I therefore make use of fastai&#39;s add_datepart function. However, I do not want to import the whole library, so I simple get the parts for this specific function. . import re def ifnone(a:any,b:any)-&gt;any: &quot;`a` if `a` is not None, otherwise `b`.&quot; return b if a is None else a def make_date(df, date_field): &quot;Make sure `df[date_field]` is of the right date type.&quot; field_dtype = df[date_field].dtype if isinstance(field_dtype, pd.core.dtypes.dtypes.DatetimeTZDtype): field_dtype = np.datetime64 if not np.issubdtype(field_dtype, np.datetime64): df[date_field] = pd.to_datetime(df[date_field], infer_datetime_format=True) def add_datepart(df, field_name, prefix=None, drop=True, time=False): &quot;Helper function that adds columns relevant to a date in the column `field_name` of `df`.&quot; make_date(df, field_name) field = df[field_name] prefix = ifnone(prefix, re.sub(&#39;[Dd]ate$&#39;, &#39;&#39;, field_name)) attr = [&#39;Year&#39;, &#39;Month&#39;, &#39;Day&#39;, &#39;Dayofweek&#39;, &#39;Dayofyear&#39;, &#39;Is_month_end&#39;, &#39;Is_month_start&#39;, &#39;Is_quarter_end&#39;, &#39;Is_quarter_start&#39;, &#39;Is_year_end&#39;, &#39;Is_year_start&#39;] if time: attr = attr + [&#39;Hour&#39;, &#39;Minute&#39;, &#39;Second&#39;] for n in attr: df[prefix + n] = getattr(field.dt, n.lower()) # Pandas removed `dt.week` in v1.1.10 week = field.dt.isocalendar().week if hasattr(field.dt, &#39;isocalendar&#39;) else field.dt.week df.insert(3, prefix+&#39;Week&#39;, week) mask = ~field.isna() df[prefix + &#39;Elapsed&#39;] = np.where(mask,field.values.astype(np.int64) // 10 ** 9,None) if drop: df.drop(field_name, axis=1, inplace=True) return df . Let&#39;s add to the function, so that after defining the correct data type it takes all of our date-variables and transforms them according to add_datepart. . def df_to_type(df, date_type=None, cont_type=None, cat_type=None): if cat_type is not None: df[cat_type] = df[cat_type].astype(&#39;category&#39;) if date_type is not None: for i in date_type: df[i] = pd.to_datetime(df[i]) df = add_datepart(df, i) return df . df_1 = df_to_type(df, date_type, continuous_type, categorical_type) df_1.head() . Id MSZoning LotFrontage Fake_date_2Week Fake_Week LotArea Street OverallQual YearBuilt CentralAir ... Fake_date_2Day Fake_date_2Dayofweek Fake_date_2Dayofyear Fake_date_2Is_month_end Fake_date_2Is_month_start Fake_date_2Is_quarter_end Fake_date_2Is_quarter_start Fake_date_2Is_year_end Fake_date_2Is_year_start Fake_date_2Elapsed . 0 1 | RL | 65.0 | 20 | 51 | 8450 | Pave | 7 | 2003 | Y | ... | 22 | 6 | 143 | False | False | False | False | False | False | 580262400 | . 1 2 | RL | 80.0 | 32 | 45 | 9600 | Pave | 6 | 1976 | Y | ... | 11 | 3 | 223 | False | False | False | False | False | False | 429408000 | . 2 3 | RL | 68.0 | 50 | 10 | 11250 | Pave | 7 | 2001 | Y | ... | 15 | 6 | 349 | False | False | False | False | False | False | 692755200 | . 3 4 | RL | 60.0 | 48 | 15 | 9550 | Pave | 7 | 1915 | Y | ... | 27 | 3 | 332 | False | False | False | False | False | False | 344131200 | . 4 5 | RL | 84.0 | 39 | 49 | 14260 | Pave | 8 | 2000 | Y | ... | 1 | 4 | 274 | False | True | False | True | False | False | 402278400 | . 5 rows × 36 columns . Pretty cool right? The next step is to split the data into train and validation set. There are usually three ways to do this: split randomly, split based on a identifier column (so that the same person is either in train or valid regardless of how many rows she represents in the data) or by date (usually in time series). . I give three examples how to do this given this specific data. I start by randomly splitting the data: . First, we need to define our dependend variable and the rest: . dep_var = &#39;SalePrice&#39; cols = list(df_1.columns) cols.remove(dep_var) . Here&#39;s how we can make a random split using the train_test_split: . X_train, X_test, y_train, y_test = train_test_split(df_1[cols], df_1[dep_var], test_size=0.33, random_state=42) . X_train.shape, X_test.shape, y_train.shape, y_test.shape . ((978, 35), (482, 35), (978,), (482,)) . Another common way how to split the data is based on an ID, so that an ID can only be in one group. Next to the dependend variable we need to define the variable on which to split. . split_var = &#39;Id&#39; . # list of unique_id unique_id_array = list(df_1[split_var].unique()) # split into train and test data based on uid test_size=0.33 cnt_uid = len(unique_id_array) len_test = np.round(cnt_uid*test_size).astype(int) len_train = cnt_uid - len_test test_idx = list(np.random.choice(unique_id_array, len_test, replace=False)) train_idx = list(set(unique_id_array) - set(test_idx)) X_train = df_1[df_1[split_var].isin(train_idx)].copy() y_train = X_train[dep_var] X_train = X_train[cols] X_test = df_1[df_1[split_var].isin(test_idx)].copy() y_test = X_test[dep_var] X_test = X_test[cols] . X_train.shape, X_test.shape, y_train.shape, y_test.shape . ((978, 35), (482, 35), (978,), (482,)) . In this case we end up with the exact same shape of all train and test data. This is due to the fact, that in this case the Id is unique. To see that this will change when there is more than one row per Id I create a fake_ID and show you the results. Let&#39;s assume we have 10 IDs: . IDS = np.array([1,2,3,4,5,6,7,8,9,10]) n = df_1.shape[0] df_1[&#39;Fake_ID&#39;] = np.resize(IDS, n) . df_1.Fake_ID.head(12) . 0 1 1 2 2 3 3 4 4 5 5 6 6 7 7 8 8 9 9 10 10 1 11 2 Name: Fake_ID, dtype: int64 . We now do the same thing as before, only using this Fake_ID as split_ID: . split_var = &#39;Fake_ID&#39; # list of unique_id unique_id_array = list(df_1[split_var].unique()) # split into train and test data based on uid test_size=0.33 cnt_uid = len(unique_id_array) len_test = np.round(cnt_uid*test_size).astype(int) len_train = cnt_uid - len_test test_idx = list(np.random.choice(unique_id_array, len_test, replace=False)) train_idx = list(set(unique_id_array) - set(test_idx)) X_train = df_1[df_1[split_var].isin(train_idx)].copy() y_train = X_train[dep_var] X_train = X_train[cols] X_test = df_1[df_1[split_var].isin(test_idx)].copy() y_test = X_test[dep_var] X_test = X_test[cols] . X_train.shape, X_test.shape, y_train.shape, y_test.shape . ((1022, 35), (438, 35), (1022,), (438,)) . Beatiful! So let&#39;s move on to our last way to split data, defined by the date. We have created the Fake_date variable, resulting in random dates from 01.01.2980 - 01.01.2000. Let&#39;s say, we want the last 6 month to be our testset. . cond = (df_1.Fake_Year&lt;1999) | (df_1.Fake_Month&lt;6) train_idx = np.where( cond)[0] test_idx = np.where(~cond)[0] X_train = df_1.iloc[train_idx] y_train = X_train[dep_var] X_train = X_train[cols] X_test = df_1.iloc[test_idx] y_test = X_test[dep_var] X_test = X_test[cols] . X_train.shape, X_test.shape, y_train.shape, y_test.shape . ((1413, 35), (47, 35), (1413,), (47,)) . We now have the three most common cases for how to split your data. Let&#39;s put that into a function. . def split_df(df, x_cols, dep_var, test_size, split_mode=&#39;random&#39;, split_var=None, cond=None): &#39;&#39;&#39; split_mode can take three values: random, on_split_id, on_condition &#39;&#39;&#39; if split_mode == &#39;random&#39;: from sklearn.model_selection import train_test_split X_train, X_test, y_train, y_test = train_test_split(df[x_cols], df_1[dep_var], test_size=test_size) elif split_mode == &#39;on_split_id&#39;: if split_var is None: print(&#39;Give name of split_var&#39;) else: # list of unique_id unique_id_array = list(df[split_var].unique()) # split into train and test data based on uid test_size=0.33 cnt_uid = len(unique_id_array) len_test = np.round(cnt_uid*test_size).astype(int) len_train = cnt_uid - len_test test_idx = list(np.random.choice(unique_id_array, len_test, replace=False)) train_idx = list(set(unique_id_array) - set(test_idx)) X_train = df[df[split_var].isin(train_idx)].copy() y_train = X_train[dep_var] X_train = X_train[x_cols] X_test = df[df[split_var].isin(test_idx)].copy() y_test = X_test[dep_var] X_test = X_test[x_cols] elif split_mode == &#39;on_condition&#39;: if cond is None: print(&#39;You have to specify cond, for example like so: cond = (df_1.Fake_Year&lt;1999) | (df_1.Fake_Month&lt;6)&#39;) else: train_idx = np.where( cond)[0] test_idx = np.where(~cond)[0] X_train = df_1.iloc[train_idx] y_train = X_train[dep_var] X_train = X_train[cols] X_test = df_1.iloc[test_idx] y_test = X_test[dep_var] X_test = X_test[cols] else: print(&#39;Something is not working right, did you specify the split_mode?&#39;) return X_train, X_test, y_train, y_test . Let&#39;s check our function for all three split_modes: . X_train, X_test, y_train, y_test = split_df(df=df_1, x_cols=cols, dep_var=dep_var, test_size=0.33, split_mode=&#39;random&#39;) X_train.shape, X_test.shape, y_train.shape, y_test.shape . ((978, 35), (482, 35), (978,), (482,)) . X_train, X_test, y_train, y_test = split_df(df=df_1, x_cols=cols, dep_var=dep_var, test_size=0.33, split_mode=&#39;on_split_id&#39;, split_var=split_var) X_train.shape, X_test.shape, y_train.shape, y_test.shape . ((1022, 35), (438, 35), (1022,), (438,)) . X_train, X_test, y_train, y_test = split_df(df=df_1, x_cols=cols, dep_var=dep_var, test_size=0.33, split_mode=&#39;on_condition&#39;, cond=cond) X_train.shape, X_test.shape, y_train.shape, y_test.shape . ((1413, 35), (47, 35), (1413,), (47,)) . Absolutely brilliant. And we&#39;re almost done now. The last piece of the puzzle is the transformation and standardization of our data. We convert the categorical variables into numbers and save the mapping into a dictionary. We standardize the continuous variables with a standardizer of choice and save it. IMPORTANT: we build the dictionaries and the standardizer on the trainset only and use it on the testset to avoid any spillover effects. . First, we build a function which will transform all of our categorical variables and save it to path. We therefore need a function to save our dicts (and later load them). . def cat_transform(X_train, X_test, cat_type, path=&#39;&#39;): dict_list = [] dict_inv_list = [] for i in cat_type: dict_ = dict( enumerate(X_train[i].cat.categories ) ) dict_inv_ = {v: k for k, v in dict_.items()} X_train[i] = X_train[i].map(dict_inv_) X_test[i] = X_test[i].map(dict_inv_) dict_list.append(dict_) dict_inv_list.append(dict_inv_list) dict_name = f&#39;{path}dict_list_cat&#39; save_obj(dict_list, dict_name) dict_inv_name = f&#39;{path}dict_inv_list_cat&#39; save_obj(dict_inv_list, dict_inv_name) return X_train, X_test, dict_list, dict_inv_list . X_train, X_test, y_train, y_test = split_df(df=df_1, x_cols=cols, dep_var=dep_var, test_size=0.33, split_mode=&#39;random&#39;) X_train, X_test, dict_list, dict_inv_list = cat_transform(X_train, X_test, categorical_type) . X_train[categorical_type].head() . MSZoning Street OverallQual SaleType CentralAir . 744 3 | 1 | 7 | 8 | 1 | . 492 3 | 1 | 5 | 6 | 1 | . 307 4 | 1 | 5 | 8 | 1 | . 985 3 | 1 | 4 | 3 | 0 | . 484 3 | 1 | 4 | 8 | 1 | . With this function we automatically saved our dictionaries and mappings to the corresponding path. Next, we take the continuous variables, use a standardizer of our choice and save the standardizer to path. We have to indicate the ID column, because we do not want to standardize this column. We also have to define whether we want to standardize our target variable. . def cont_standardize(X_train, X_test, y_train, y_test, cat_type=None, id_type=None, transform_y=True, path=&#39;&#39;, standardizer=&#39;StandardScaler&#39;): if standardizer ==&#39;StandardScaler&#39;: scaler = StandardScaler() if cat_type==None: cont_type = list(X_train.columns) cont_type.remove(id_type) elif id_type==None: list(set(X_train.columns) - set(id_type)) elif cat_type==None and id_type==None: cont_type = list(X_train.columns) else: cont_type = list(set(X_train.columns) - set(cat_type)) cont_type.remove(id_type) X_train[cont_type] = scaler.fit_transform(X_train[cont_type]) X_test[cont_type] = scaler.transform(X_test[cont_type]) scaler_name = f&#39;{path}StandardScaler&#39; save_obj(scaler, scaler_name) if transform_y: scaler_y = StandardScaler() y_train = scaler_y.fit_transform(y_train.values.reshape(-1, 1)) y_test = scaler_y.transform(y_test.values.reshape(-1, 1)) scaler_y_name = f&#39;{path}StandardScaler_y&#39; save_obj(scaler_y, scaler_name) else: pass if transform_y: return X_train, X_test, y_train, y_test, scaler, scaler_y else: return X_train, X_test, y_train, y_test, scaler elif standardizer ==&#39;MinMaxScaler&#39;: scaler = MinMaxScaler() if cat_type==None: cont_type = list(X_train.columns) cont_type.remove(id_type) elif id_type==None: list(set(X_train.columns) - set(id_type)) elif cat_type==None and id_type==None: cont_type = list(X_train.columns) else: cont_type = list(set(X_train.columns) - set(cat_type)) cont_type.remove(id_type) X_train[cont_type] = scaler.fit_transform(X_train[cont_type]) X_test[cont_type] = scaler.transform(X_test[cont_type]) scaler_name = f&#39;{path}MinMaxScaler&#39; save_obj(scaler, scaler_name) if transform_y: scaler_y = MinMaxScaler() y_train = scaler_y.fit_transform(y_train.values.reshape(-1, 1)) y_test = scaler_y.transform(y_test.values.reshape(-1, 1)) scaler_y_name = f&#39;{path}MinMaxScaler_y&#39; save_obj(scaler_y, scaler_name) else: pass if transform_y: return X_train, X_test, y_train, y_test, scaler, scaler_y else: return X_train, X_test, y_train, y_test, scaler else: print(&#39;standardizer can either be StandardScaler or MinMaxScaler&#39;) . id_type=&#39;Id&#39; . X_train, X_test, y_train, y_test, scaler, scaler_y = cont_standardize(X_train, X_test, y_train, y_test, cat_type=categorical_type, id_type=&#39;Id&#39;, transform_y=True) . X_train.head() . Id MSZoning LotFrontage Fake_date_2Week Fake_Week LotArea Street OverallQual YearBuilt CentralAir ... Fake_date_2Day Fake_date_2Dayofweek Fake_date_2Dayofyear Fake_date_2Is_month_end Fake_date_2Is_month_start Fake_date_2Is_quarter_end Fake_date_2Is_quarter_start Fake_date_2Is_year_end Fake_date_2Is_year_start Fake_date_2Elapsed . 744 0.043062 | 3 | -1.147645 | 1.484951 | 1.160387 | -0.511627 | 1 | 7 | 0.716393 | 1 | ... | -0.455404 | 1.448463 | 1.544753 | -0.15861 | -0.186871 | -0.101639 | -0.111456 | 0.0 | -0.064084 | -1.213687 | . 492 -0.554919 | 3 | 1.391675 | -0.384396 | -0.232891 | 0.521756 | 1 | 5 | 1.155090 | 1 | ... | 0.557602 | -0.500088 | -0.401376 | -0.15861 | -0.186871 | -0.101639 | -0.111456 | 0.0 | -0.064084 | -1.640805 | . 307 -0.993913 | 4 | NaN | -1.252306 | -1.029050 | -0.255387 | 1 | 5 | -1.747058 | 1 | ... | 0.670158 | 1.448463 | -1.250422 | -0.15861 | -0.186871 | -0.101639 | -0.111456 | 0.0 | -0.064084 | -0.513396 | . 985 0.614941 | 3 | -0.076369 | -0.117346 | 0.032495 | 0.044997 | 1 | 4 | -0.734681 | 0 | ... | 0.895271 | 1.448463 | -0.086561 | -0.15861 | -0.186871 | -0.101639 | -0.111456 | 0.0 | -0.064084 | 0.043000 | . 484 -0.573903 | 3 | NaN | 0.149703 | -0.630971 | -0.271827 | 1 | 4 | -0.329730 | 1 | ... | 0.107377 | -1.474364 | 0.132856 | -0.15861 | -0.186871 | -0.101639 | -0.111456 | 0.0 | -0.064084 | 0.887644 | . 5 rows × 35 columns . y_train[:5] . array([[-0.02988161], [-0.11953991], [-1.1544938 ], [-0.71334758], [-0.62014767]]) . We have now saved our StandardScaler to path and transformed the data the way we wanted it. To see the &quot;real&quot; values of our y_train we simply invert our standardizer: . scaler_y.inverse_transform(y_train[:5]) . array([[180000.], [172785.], [ 89500.], [125000.], [132500.]]) . Beautiful! And now I want to show you how incredibly quickly we can now setup our data. I deleted everything in memory and started from here. . Complete run-through . df = pd.read_csv(&#39;train.csv&#39;) to_keep = [&#39;Id&#39;, &#39;MSZoning&#39;, &#39;LotFrontage&#39;, &#39;LotArea&#39;, &#39;Street&#39;, &#39;OverallQual&#39;, &#39;YearBuilt&#39;, &#39;CentralAir&#39;, &#39;SaleType&#39;, &#39;SalePrice&#39;] df = df[to_keep] df[&quot;Fake_date&quot;] = np.random.choice(pd.date_range(&#39;1980-01-01&#39;, &#39;2000-01-01&#39;), len(df)).astype(&#39;str&#39;) df.head() . Id MSZoning LotFrontage LotArea Street OverallQual YearBuilt CentralAir SaleType SalePrice Fake_date . 0 1 | RL | 65.0 | 8450 | Pave | 7 | 2003 | Y | WD | 208500 | 1988-10-01T00:00:00.000000000 | . 1 2 | RL | 80.0 | 9600 | Pave | 6 | 1976 | Y | WD | 181500 | 1989-05-17T00:00:00.000000000 | . 2 3 | RL | 68.0 | 11250 | Pave | 7 | 2001 | Y | WD | 223500 | 1992-09-20T00:00:00.000000000 | . 3 4 | RL | 60.0 | 9550 | Pave | 7 | 1915 | Y | WD | 140000 | 1984-08-11T00:00:00.000000000 | . 4 5 | RL | 84.0 | 14260 | Pave | 8 | 2000 | Y | WD | 250000 | 1986-04-07T00:00:00.000000000 | . date_type = [&#39;Fake_date&#39;] continuous_type = [&#39;LotFrontage&#39;, &#39;LotArea&#39;, &#39;YearBuilt&#39;, &#39;SalePrice&#39;] categorical_type = [&#39;MSZoning&#39;, &#39;Street&#39;, &#39;OverallQual&#39;, &#39;SaleType&#39;,&#39;CentralAir&#39;] . df_1 = df_to_type(df, date_type, continuous_type, categorical_type) . dep_var = &#39;SalePrice&#39; cols = list(df_1.columns) cols.remove(dep_var) . X_train, X_test, y_train, y_test = split_df(df=df_1, x_cols=cols, dep_var=dep_var, test_size=0.33, split_mode=&#39;random&#39;) . X_train, X_test, dict_list, dict_inv_list = cat_transform(X_train, X_test, categorical_type) . X_train, X_test, y_train, y_test, scaler, scaler_y = cont_standardize(X_train, X_test, y_train, y_test, cat_type=categorical_type, id_type=&#39;Id&#39;, transform_y=True) . X_train.head() . Id MSZoning LotFrontage Fake_Week LotArea Street OverallQual YearBuilt CentralAir SaleType ... Fake_Day Fake_Dayofweek Fake_Dayofyear Fake_Is_month_end Fake_Is_month_start Fake_Is_quarter_end Fake_Is_quarter_start Fake_Is_year_end Fake_Is_year_start Fake_Elapsed . 253 254 | 3 | 0.570755 | -0.515555 | -0.113494 | 1 | 5 | -0.242016 | 1 | 1 | ... | -1.189170 | -1.484321 | -0.556901 | -0.171679 | -0.180928 | -0.111456 | -0.106655 | -0.064084 | -0.045268 | -1.648408 | . 1185 1186 | 3 | -0.416423 | 0.870733 | -0.079594 | 1 | 4 | -1.588959 | 1 | 8 | ... | -0.623669 | 1.480279 | 0.922893 | -0.171679 | -0.180928 | -0.111456 | -0.106655 | -0.064084 | -0.045268 | -1.231187 | . 515 516 | 3 | 0.926139 | 0.540664 | 0.137262 | 1 | 9 | 1.273295 | 1 | 6 | ... | 1.525232 | -0.496121 | 0.536450 | -0.171679 | -0.180928 | -0.111456 | -0.106655 | -0.064084 | -0.045268 | -0.907465 | . 433 434 | 3 | 1.163061 | 0.012555 | 0.016602 | 1 | 5 | 0.869212 | 1 | 8 | ... | -0.962969 | 0.986179 | 0.036902 | -0.171679 | -0.180928 | -0.111456 | -0.106655 | -0.064084 | -0.045268 | -0.932367 | . 1406 1407 | 3 | -0.021552 | -0.911637 | -0.192566 | 1 | 4 | 0.027373 | 1 | 8 | ... | 1.412132 | 0.986179 | -0.924493 | -0.171679 | -0.180928 | -0.111456 | -0.106655 | -0.064084 | -0.045268 | 1.422486 | . 5 rows × 22 columns . y_train[:5] . array([[-0.2703821 ], [-0.96272526], [ 2.92223258], [ 0.02950289], [-0.59634404]]) . Absolutely brilliant. Look how easy and fast we pre-processed our data. We now can start any Machine Learning Algorithm we want. It&#39;s super easy to replicate the results, because we saved the mapping and the scaler. We automatically created train and testset, we are flexible to use this in any way we want to split our data. I hope this will come in handy for your next machine learning project. . Stay tuned for the next blogpost! . Lasse .",
            "url": "https://lschmiddey.github.io/fastpages_/2020/10/22/How-to-preprocess-data-for-machine-learning.html",
            "relUrl": "/2020/10/22/How-to-preprocess-data-for-machine-learning.html",
            "date": " • Oct 22, 2020"
        }
        
    
  
    
        ,"post16": {
            "title": "How to deploy a machine learninig model",
            "content": "In this blogpost I will show you how to first create a simple Random Forest Classifier and then build an API with Flask. Let&#39;s start by building the model. . import numpy as np import pandas as pd from pathlib import Path import pickle from sklearn.ensemble import RandomForestClassifier from sklearn.preprocessing import StandardScaler from sklearn.model_selection import train_test_split . p = Path(&#39;/notebooks/storage/data/Titanic&#39;) df = pd.read_csv(f&#39;{p}/train/train.csv&#39;, index_col=0) df.tail(5) . Survived Pclass Name Sex Age SibSp Parch Ticket Fare Cabin Embarked . PassengerId . 887 0 | 2 | Montvila, Rev. Juozas | male | 27.0 | 0 | 0 | 211536 | 13.00 | NaN | S | . 888 1 | 1 | Graham, Miss. Margaret Edith | female | 19.0 | 0 | 0 | 112053 | 30.00 | B42 | S | . 889 0 | 3 | Johnston, Miss. Catherine Helen &quot;Carrie&quot; | female | NaN | 1 | 2 | W./C. 6607 | 23.45 | NaN | S | . 890 1 | 1 | Behr, Mr. Karl Howell | male | 26.0 | 0 | 0 | 111369 | 30.00 | C148 | C | . 891 0 | 3 | Dooley, Mr. Patrick | male | 32.0 | 0 | 0 | 370376 | 7.75 | NaN | Q | . What we want to predict is whether the Passenger has survived or not. We want a simple model, so let&#39;s only keep the following variables: . to_keep = [&#39;Survived&#39;, &#39;Pclass&#39;, &#39;Sex&#39;, &#39;Age&#39;, &#39;Parch&#39;] final_df = df.reset_index()[to_keep] . final_df.dtypes . Survived int64 Pclass int64 Sex object Age float64 Parch int64 dtype: object . final_df[&#39;Sex&#39;] = np.where(final_df[&#39;Sex&#39;]==&#39;male&#39;, 0, 1) . final_df.head() . Survived Pclass Sex Age Parch . 0 0 | 3 | 0 | 22.0 | 0 | . 1 1 | 1 | 1 | 38.0 | 0 | . 2 1 | 3 | 1 | 26.0 | 0 | . 3 1 | 1 | 1 | 35.0 | 0 | . 4 0 | 3 | 0 | 35.0 | 0 | . Now that we&#39;ve created our final dataframe, let&#39;s train the model. . First, we define the accuracy metric to see how our model is doing: . def accu(pred,y, threshold=0.5): return (np.round(pred-threshold+0.5) == y).mean() def m_accu(m, xs, y): return np.round(accu(m.predict(xs), y), 3) . We then standardize our data, in this case only the age variable. . final_df = final_df.fillna(0) . scaler = StandardScaler() final_df[&#39;Age&#39;] = scaler.fit_transform(final_df[&#39;Age&#39;].values.reshape(-1, 1)) . Then we define the model: . def rf(xs, y, n_estimators=40, max_samples=500, max_features=0.5, min_samples_leaf=5, **kwargs): return RandomForestClassifier(n_jobs=-1, n_estimators=n_estimators, max_samples=max_samples, max_features=max_features, min_samples_leaf=min_samples_leaf, oob_score=True).fit(xs, y) . Then we split the data into train and validation. . col_names = [&#39;Pclass&#39;, &#39;Sex&#39;, &#39;Age&#39;, &#39;Parch&#39;] dep_var = &#39;Survived&#39; . xs, xs_valid, y, y_valid = train_test_split(final_df[col_names], final_df[dep_var], test_size=0.33, random_state=42) . And finally let&#39;s train the model: . m = rf(xs, y); . m_accu(m, xs, y), m_accu(m, xs_valid, y_valid) . (0.836, 0.82) . from sklearn.metrics import confusion_matrix confusion_matrix(y_valid, np.round(m.predict(xs_valid))) . array([[165, 10], [ 43, 77]]) . I guess that looks ok, so I will save the final model together with the standardizer. . def save_obj(obj, name ): with open(f&#39;{name}.pkl&#39;, &#39;wb&#39;) as f: pickle.dump(obj, f) def load_obj(name ): with open(f&#39;{name}.pkl&#39;, &#39;rb&#39;) as f: return pickle.load(f) . filename = &#39;Flask_App/app/final_model.pkl&#39; pickle.dump(m, open(filename, &#39;wb&#39;)) save_obj(scaler, &#39;Flask_App/app/standardizer&#39;) . Create an API with Flask . Now that we have our model we want to build an API. We will use Flask for this. This is how the folder structure should look like: . . For our Flask App to run we need our terminal. Here are the bash commands you need to run to set up Flask: . python3 -m venv venv . venv/bin/activate pip install Flask pip install pandas numpy sklearn requests pip freeze &gt; requirements.txt cd app export FLASK_APP=main.py export FLASK_ENV=development flask run . In our folder we create a virtual environment which I called venv. I then activate it an install Flask and some other packages we need to make our RF-Model work. I then save the requirements into a txt file. I go into the app folder, set the Flask App to main.py and the environment to development. Finally, I start flask. The output should look like this: . . Next, we need to define a main.py and a utils.py. Let&#39;s start with the utils.py . With our API we want to send a GET request with values for our variables: . Pclass = 1 Age = 22.0 Sex = 0 Parch = 1 # load trained model and standardizer PATH = &quot;final_model.pkl&quot; loaded_model = pickle.load(open(PATH, &#39;rb&#39;)) standardizer = load_obj(&#39;standardizer&#39;) # create dataframe from input data df = pd.DataFrame({&#39;Pclass&#39;: [Pclass], &#39;Age&#39;: [Age], &#39;Sex&#39;:[Sex], &#39;Parch&#39;:[Parch]}) # define transform function def transform_data(raw_data): raw_data = raw_data.fillna(0) raw_data[&#39;Age&#39;] = standardizer.transform(raw_data[&#39;Age&#39;].values.reshape(-1, 1)) return raw_data # define prediction function def get_prediction(transformed_data): pred = loaded_model.predict_proba(transformed_data) return pred . Does it work? . get_prediction(transform_data(df)) . array([[0.65921623, 0.34078377]]) . Awesome! So our utils.py works, let&#39;s build our main.py. . from flask import Flask, request, jsonify import csv import pandas as pd from utils import transform_data, get_prediction app = Flask(__name__) @app.route(&#39;/predict&#39;, methods=[&quot;GET&quot;]) def predict(): if request.method == &#39;GET&#39;: Pclass = request.args.get(&#39;Pclass&#39;) Age = request.args.get(&#39;Age&#39;) Sex = request.args.get(&#39;Sex&#39;) Parch = request.args.get(&#39;Parch&#39;) df = pd.DataFrame({&#39;Pclass&#39;: [Pclass], &#39;Age&#39;: [Age], &#39;Sex&#39;:[Sex], &#39;Parch&#39;:[Parch]}) transf_data = transform_data(raw_data) prediction = get_prediction(transf_data) prediction = prediction[0][1].item() # We take the first value of our predictions, representing the probability to survive. data = {&#39;prediction&#39;: prediction} return jsonify(data) else: return jsonify({&#39;error&#39;: &#39;Only GET requests possible&#39;}) . What this does is the following: it reads the data from the GET request, uses the utils.py for transform_data and get_predictions and returns the prediction for surviving. . Finally, we want to check our app. We build a test.py file where we send data to our &quot;server&quot;, which will return a result. This is how the test.py file looks like: . import requests # https://your-heroku-app-name.herokuapp.com/predict # http://localhost:5000/predict data = {&#39;Pclass&#39;: 1, &#39;Age&#39;: 22.0, &#39;Sex&#39;: 0, &#39;Parch&#39;: 1} r = requests.get(&quot;http://localhost:5000/predict&quot;, params=data) . Check our API: . Let&#39;s use our terminal to see whether our API is working. . . Awesome! We built a Flask App to deploy our machine learning model and made it available as an API. . Stay tuned for the next blogpost! Lasse .",
            "url": "https://lschmiddey.github.io/fastpages_/2020/10/19/Deploy_Machine-Learning-Model.html",
            "relUrl": "/2020/10/19/Deploy_Machine-Learning-Model.html",
            "date": " • Oct 19, 2020"
        }
        
    
  
    
        ,"post17": {
            "title": "How to use fastai tabular with custom metric",
            "content": "How to easily train a tabular model with fastai . First, we have to load our data (I used the kaggle API to do this, check out my previous blogpost) . from pathlib import Path p = Path(&#39;/notebooks/storage/data/Titanic&#39;) filename = Path(&#39;/notebooks/storage/data/Titanic/titanic.zip&#39;) . !unzip -q {str(filename)} -d {str(p/&quot;train&quot;)} . Get imports . import pandas as pd from pandas.api.types import is_string_dtype, is_numeric_dtype, is_categorical_dtype from fastai.tabular.all import * from sklearn.metrics import confusion_matrix . df = pd.read_csv(f&#39;{p}/train/train.csv&#39;, index_col=0) df.tail(5) . Survived Pclass Name Sex Age SibSp Parch Ticket Fare Cabin Embarked . PassengerId . 887 0 | 2 | Montvila, Rev. Juozas | male | 27.0 | 0 | 0 | 211536 | 13.00 | NaN | S | . 888 1 | 1 | Graham, Miss. Margaret Edith | female | 19.0 | 0 | 0 | 112053 | 30.00 | B42 | S | . 889 0 | 3 | Johnston, Miss. Catherine Helen &quot;Carrie&quot; | female | NaN | 1 | 2 | W./C. 6607 | 23.45 | NaN | S | . 890 1 | 1 | Behr, Mr. Karl Howell | male | 26.0 | 0 | 0 | 111369 | 30.00 | C148 | C | . 891 0 | 3 | Dooley, Mr. Patrick | male | 32.0 | 0 | 0 | 370376 | 7.75 | NaN | Q | . df.shape . (891, 11) . Let&#39;s check out the data type for each column. . df.dtypes . Survived int64 Pclass int64 Name object Sex object Age float64 SibSp int64 Parch int64 Ticket object Fare float64 Cabin object Embarked object dtype: object . We see that &quot;Pclass&quot;, &quot;Sex&quot;, &quot;Cabin&quot; and &quot;Embarked&quot; are objects. When we think about these variables, they clearly are categorical variables. So let&#39;s change that. Also, this blogpost is not about how to train the best possible model, so we do not want any fancy feature engineering. I therefore will get rid of the variable &quot;Name&quot;. . df[&#39;Pclass&#39;] = df[&#39;Pclass&#39;].astype(&#39;category&#39;) df[&#39;Sex&#39;] = df[&#39;Sex&#39;].astype(&#39;category&#39;) df[&#39;Cabin&#39;] = df[&#39;Cabin&#39;].astype(&#39;category&#39;) df[&#39;Embarked&#39;] = df[&#39;Embarked&#39;].astype(&#39;category&#39;) . df = df.drop(columns=[&#39;Name&#39;]) . I want to build a validation set, based on the index. The easiest way is to create an array with the length of our data, randomly select a percentage of indeces we want in our training data, and use the leftover indeces for our validation set. . # Define percentage of train data, define length of training indeces and validation indeces p = 0.9 len_df = len(df) len_idx_tain = round(len_df*p) len_idx_val = len_df-len_idx_tain . # build array of indeces for training and validation idx_arr = range(0,len_df) train_idx = np.random.choice(range(0,len_df), len_idx_tain, replace=False) val_idx = [i for i in idx_arr if i not in train_idx] val_idx = np.asarray(val_idx) . Let&#39;s put these arrays into a split variable, which fastai knows how to make use of to split the data into training data and validation data. . splits = (list(train_idx),list(val_idx)) . Then we make use of the &quot;cont_cat_split&quot; function to easily get a list of column names for each categorical and continuous variable. . cont_nn, cat_nn = cont_cat_split(df, dep_var=&#39;Survived&#39;) . cont_nn, cat_nn . ([&#39;Age&#39;, &#39;Fare&#39;], [&#39;Pclass&#39;, &#39;Sex&#39;, &#39;SibSp&#39;, &#39;Parch&#39;, &#39;Ticket&#39;, &#39;Cabin&#39;, &#39;Embarked&#39;]) . That looks great! How about our missing values? . df.isna().sum() . Survived 0 Pclass 0 Sex 0 Age 177 SibSp 0 Parch 0 Ticket 0 Fare 0 Cabin 687 Embarked 2 dtype: int64 . Looks like there are quite a few missing values for age and cabin. But we know a way to make use of that! Even &quot;no-information&quot; can be an information. . procs_nn = [Categorify, FillMissing, Normalize] . Fastai provides us with many super useful out-of-the-box functions. Three of them you can see here: Categorify will take all of the variables with type &quot;category&quot; will replace the category with a numerical number and write the mapping into a dictionary. FillMissing, well, does exactly this. It also provides us with a extra boolean variable, indicating whether the row has a missing value for a specific variable (e.g. age). Normalize then normalizes our continuous data and saves the standardzier. . df[&#39;Survived&#39;] = df[&#39;Survived&#39;].astype(np.float32) . This one is important: fastai needs the dependend variable to be of type float32, even though we have a binary classification! We need this, because the loss function will be mse-loss. This leads to possibly odd behavior: the numbers can get below 0 and even below -1 or above 2! If we use a provided metric like accuracy, this leads to odd results. So we will write our own custom metric! But first, let&#39;s use the TabularPandas class and put that in a dataloader (important: do not let the batchsize become bigger than your data, this will result in a error!). . to_nn = TabularPandas(df, procs_nn, cat_nn, cont_nn, splits=splits, y_names=&#39;Survived&#39;) # length of data is 891, so let the batchsize be smaller than that! dls = to_nn.dataloaders(256) . Train Model . Now is the time to train our model. But wait! We first have to define a custom metric, because the accuracy provided by fastai will lead to odd results. I can show you what I mean: . learn = tabular_learner(dls, layers=[64, 8], n_out=1, metrics=[accuracy]) . learn.fit_one_cycle(4,1e-3) . epoch train_loss valid_loss accuracy time . 0 | 0.562715 | 0.504298 | 0.617977 | 00:00 | . 1 | 0.498489 | 0.477128 | 0.617977 | 00:00 | . 2 | 0.436740 | 0.448243 | 0.617977 | 00:00 | . 3 | 0.391733 | 0.423635 | 0.617977 | 00:00 | . What is going on here? Is the accuracy not improving? The answer is no. Tabular learner in combination with accuracy does not give us the result we want. Why is that? First, our predictions will not be 0 or 1, but floating point values. That&#39;s good for our loss, so our model can learn from its gradient (checkout my blogpost about gradients if you do not know what that means). But this leads to a malfunctioning of the accuracy metric, which fastai uses from sklearn. What we need to do is to define our own custom metric. Let&#39;s do that! . import sklearn.metrics as skm def _accumulate(self, learn): #pred = learn.pred.argmax(dim=self.dim_argmax) if self.dim_argmax else learn.pred m = nn.Sigmoid() pred = learn.pred pred = torch.round(m(pred)) targ = learn.y pred,targ = to_detach(pred),to_detach(targ) self.preds.append(pred) self.targs.append(targ) AccumMetric.accumulate = _accumulate def BinAccu(): return skm_to_fastai(skm.accuracy_score) . So what&#39;s going on here? Next to Callbacks, fastai provides a clever way how to customize metrics. To be honest, it took me some time to figure it out, but here&#39;s how it works. Each learner has a .pred and a .y, which means this is how you can get its predictions and its targets. As I already mentioned, preds are floating point values, but we want them to be between 0 and 1 - luckily, this is exactly what the sigmoid function is doing. Then we want the values to be either 0 or 1, so let&#39;s just round these values (threshold here is .5, but you can fiddle around with that). We then append these &quot;new&quot; preds and targets. . &quot;In order to provide a more flexible foundation to support metrics like this fastai provides a Metric abstract class which defines three methods: reset, accumulate, and value (which is a property). Reset is called at the start of training, accumulate is called after each batch, and then finally value is called to calculate the final check.&quot; . So with this function we directly sit on top of accumulate. The function skm_to_fastai let&#39;s you use sklearn metrics (in this case: accuracy_score) and uses the pred and targ we provided in our tiny function. Important: we have to instanciate the instance first! . binaccu = BinAccu() learn = tabular_learner(dls, n_out=1, metrics=[binaccu]) . Ok, we&#39;re good to go. Let&#39;s use fastai&#39;s awesome lr_find(). . learn.lr_find() . SuggestedLRs(lr_min=0.03630780577659607, lr_steep=0.0010000000474974513) . Looks like we should set our learning rate to about 1e-3. . learn.fit_one_cycle(10,1e-3) . epoch train_loss valid_loss accuracy_score time . 0 | 0.484679 | 0.372455 | 0.325843 | 00:00 | . 1 | 0.425642 | 0.374143 | 0.595506 | 00:00 | . 2 | 0.343880 | 0.367273 | 0.494382 | 00:00 | . 3 | 0.271155 | 0.349920 | 0.393258 | 00:00 | . 4 | 0.220030 | 0.334517 | 0.382022 | 00:00 | . 5 | 0.184440 | 0.325883 | 0.382022 | 00:00 | . 6 | 0.157990 | 0.319556 | 0.382022 | 00:00 | . 7 | 0.137255 | 0.313525 | 0.382022 | 00:00 | . 8 | 0.120796 | 0.309076 | 0.382022 | 00:00 | . 9 | 0.107582 | 0.306098 | 0.382022 | 00:00 | . Our accuracy is improving until epoch 2. So we should restart our training. But first, let&#39;s have a look, whether our accuracy score is doing what we expect: . preds, targs = learn.get_preds() m = nn.Sigmoid() confusion_matrix(torch.round(m(preds.view(-1))).numpy(), targs.view(-1).numpy()) . array([[ 0, 0], [55, 34]]) . 1-abs(torch.round(m(preds.view(-1))) - targs.view(-1)).sum()/len((torch.round(m(preds.view(-1))) - targs.view(-1))) . tensor(0.3820) . Awesome. That&#39;s exactly what we wanted (not the result though, which is pretty bad ;) ) . Let&#39;s re-run the trainig. . binaccu = BinAccu() learn = tabular_learner(dls, layers=[128,128], n_out=1, metrics=[binaccu]) . learn.fit_one_cycle(5,1e-5) . epoch train_loss valid_loss accuracy_score time . 0 | 0.616267 | 0.422966 | 0.617978 | 00:00 | . 1 | 0.610159 | 0.418977 | 0.617978 | 00:00 | . 2 | 0.607095 | 0.416566 | 0.617978 | 00:00 | . 3 | 0.604457 | 0.414736 | 0.629213 | 00:00 | . 4 | 0.604596 | 0.413118 | 0.640449 | 00:00 | . preds, targs = learn.get_preds() m = nn.Sigmoid() confusion_matrix(torch.round(m(preds.view(-1))).numpy(), targs.view(-1).numpy()) . array([[54, 31], [ 1, 3]]) . To be honest, the results aren&#39;t quite that good. With a RandomForest you can easily get up to 85% accuracy. However, in this blogpost I wanted to show you how to leverage fastai&#39;s tabular_learner and add a custom metric to it. . I hope you stay tuned for the next blogpost! . Lasse .",
            "url": "https://lschmiddey.github.io/fastpages_/2020/10/01/Tabular-Data-with-custom-metric.html",
            "relUrl": "/2020/10/01/Tabular-Data-with-custom-metric.html",
            "date": " • Oct 1, 2020"
        }
        
    
  
    
        ,"post18": {
            "title": "Build a web app with binder",
            "content": "Let&#39;s deploy the model! . This is the last part of my small project to get an app running, which will take an image as input, extract the text and then run a deep learning model on it to give the book a rating based on my book taste. In part 3 we put together the parts we need to create our web app with binder and voila. . The final project you&#39;ll find in my git repo. This blogpost should guide you through the git repo, what to do to build your web app from a jupyter notebook. Ok, so let&#39;s get started! . . Alright, what have we got here? First of all, the jupyter notebook from part 3. So nothing new here. We have a LICENSE and a README file, which aren&#39;t that important. What&#39;s next is important, the three files &quot;app.yml&quot;, &quot;apt.txt&quot; and &quot;requirements.txt&quot;. Let&#39;s start with &quot;requirements.txt&quot;. . . In the &quot;requirements.txt&quot; are all the packages we need for our project. Binder will create a docker container for us, so it needs to know what packages are required. Next, let&#39;s have a look at &quot;apt.txt&quot;. . . This one is moderatly more difficult. Especially if you do haven&#39;t worked with docker before. It looks like the requirement file, however what this does is it apt installs these packages. This is required, because pytesseract works different from other packages. Without this file our jupyter notebook won&#39;t be able to connect to pytesseract. I had a lot of head scratching and googling to do before I found out that tesseract needs to be installed that way to find the path where its libraries are. . Next, let&#39;s look at app.yml. . . This file is needed to that we can make use of voila. Voila takes all the non html Output, runs it in the background and doesn&#39;t show it to the user of the app. . Ok, we&#39;re finally able to start our web app on Binder. . . So we simply specify the path to our git repository and type &quot;/voila/render/App-with-Voila-mybinder.ipynb&quot; into the URL to open. Then instead of &quot;File&quot; we use &quot;URL&quot;. . Ok, let Binder do its work and set up a docker container for us, on which our app is running. When Binder creates the docker container for the project for the first time, this will take a while (5 min or so). . Let&#39;s have a look at the running app. . . Let&#39;s uploade an image and see what my algorithm will say how much I will like this book: . . Awesome! That looks great (btw. the book was the sea wolf by Jack London and I loved this book). Now everyone can use this little web app and see whether I would recommend this book or not. Simply click on the &quot;launch binder&quot; in my git repo and start the app. I hope you enjoyed this little project as much as I did and stay tuned for more. . Lasse .",
            "url": "https://lschmiddey.github.io/fastpages_/2020/09/28/Build-binder-app-Part4.html",
            "relUrl": "/2020/09/28/Build-binder-app-Part4.html",
            "date": " • Sep 28, 2020"
        }
        
    
  
    
        ,"post19": {
            "title": "Lasse's book recommender",
            "content": "How would Lasse rate this book? . This is the third part of my little project to build a rating system on text which we extract from images and which in turn leads to a rating on how much I will like this book. In this notebook I want to show you how to make use of ipywidgets to make a notebook which we can use as a web appplication. Furthermore, I will show you how to download the trained model from part 2 from my private GoogleDrive. So let&#39;s get started! . !pip install googledrivedownloader !pip install transformers . Collecting googledrivedownloader Downloading googledrivedownloader-0.4-py2.py3-none-any.whl (3.9 kB) Installing collected packages: googledrivedownloader Successfully installed googledrivedownloader-0.4 Collecting transformers Downloading transformers-3.3.0-py3-none-any.whl (1.1 MB) |████████████████████████████████| 1.1 MB 14.9 MB/s eta 0:00:01 |██▉ | 92 kB 15.2 MB/s eta 0:00:01 |███████████████████████████████ | 1.0 MB 14.9 MB/s eta 0:00:01 Requirement already satisfied: tqdm&gt;=4.27 in /opt/conda/envs/fastai/lib/python3.8/site-packages (from transformers) (4.48.2) Requirement already satisfied: requests in /opt/conda/envs/fastai/lib/python3.8/site-packages (from transformers) (2.24.0) Requirement already satisfied: sentencepiece!=0.1.92 in /opt/conda/envs/fastai/lib/python3.8/site-packages (from transformers) (0.1.86) Requirement already satisfied: numpy in /opt/conda/envs/fastai/lib/python3.8/site-packages (from transformers) (1.19.1) Collecting filelock Downloading filelock-3.0.12-py3-none-any.whl (7.6 kB) Collecting regex!=2019.12.17 Downloading regex-2020.9.27-cp38-cp38-manylinux2010_x86_64.whl (675 kB) |████████████████████████████████| 675 kB 7.2 MB/s eta 0:00:01 Collecting sacremoses Downloading sacremoses-0.0.43.tar.gz (883 kB) |████████████████████████████████| 883 kB 25.0 MB/s eta 0:00:01 Requirement already satisfied: packaging in /opt/conda/envs/fastai/lib/python3.8/site-packages (from transformers) (20.4) Collecting tokenizers==0.8.1.rc2 Downloading tokenizers-0.8.1rc2-cp38-cp38-manylinux1_x86_64.whl (3.0 MB) |████████████████████████████████| 3.0 MB 23.4 MB/s eta 0:00:01 Requirement already satisfied: chardet&lt;4,&gt;=3.0.2 in /opt/conda/envs/fastai/lib/python3.8/site-packages (from requests-&gt;transformers) (3.0.4) Requirement already satisfied: certifi&gt;=2017.4.17 in /opt/conda/envs/fastai/lib/python3.8/site-packages (from requests-&gt;transformers) (2020.6.20) Requirement already satisfied: idna&lt;3,&gt;=2.5 in /opt/conda/envs/fastai/lib/python3.8/site-packages (from requests-&gt;transformers) (2.10) Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,&lt;1.26,&gt;=1.21.1 in /opt/conda/envs/fastai/lib/python3.8/site-packages (from requests-&gt;transformers) (1.25.10) Requirement already satisfied: six in /opt/conda/envs/fastai/lib/python3.8/site-packages (from sacremoses-&gt;transformers) (1.15.0) Collecting click Downloading click-7.1.2-py2.py3-none-any.whl (82 kB) |████████████████████████████████| 82 kB 1.3 MB/s eta 0:00:01 Requirement already satisfied: joblib in /opt/conda/envs/fastai/lib/python3.8/site-packages (from sacremoses-&gt;transformers) (0.16.0) Requirement already satisfied: pyparsing&gt;=2.0.2 in /opt/conda/envs/fastai/lib/python3.8/site-packages (from packaging-&gt;transformers) (2.4.7) Building wheels for collected packages: sacremoses Building wheel for sacremoses (setup.py) ... done Created wheel for sacremoses: filename=sacremoses-0.0.43-py3-none-any.whl size=893259 sha256=5a3671aa51ef5e5501f57c816f31eea01e646340384391c47489f75a0c3cb57c Stored in directory: /root/.cache/pip/wheels/7b/78/f4/27d43a65043e1b75dbddaa421b573eddc67e712be4b1c80677 Successfully built sacremoses Installing collected packages: filelock, regex, click, sacremoses, tokenizers, transformers Successfully installed click-7.1.2 filelock-3.0.12 regex-2020.9.27 sacremoses-0.0.43 tokenizers-0.8.1rc2 transformers-3.3.0 . from fastai.vision.all import * from fastai.vision.widgets import * from fastai.vision.widgets import * from PIL import Image, ImageFilter import pytesseract import re from transformers import BertTokenizer, BertForSequenceClassification from pathlib import Path from torch.utils.data import TensorDataset, DataLoader . Lots of models especially in the deep learning context can get quite large. I wasn&#39;t able to upload my model into git, so I thought of a way to get around that. I uploaded my trained model from part 2 into my GoogleDrive and then use the google_drive_downloader to download my model into my notebook. . from google_drive_downloader import GoogleDriveDownloader as gdd gdd.download_file_from_google_drive(file_id=&#39;1kk_SvwpwZeuLnZirW5vbrd8FEnm7yJRt&#39;, dest_path=&#39;./export.pkl&#39;, unzip=True) . Downloading 1kk_SvwpwZeuLnZirW5vbrd8FEnm7yJRt into ./export.pkl... Done. Unzipping...Done. . import warnings warnings.filterwarnings(&quot;ignore&quot;) . Next, we use all the steps you already know from part 2: rotate the image and filter it, use pytesseract to extract the text from the image, tokenize the text and put it in a dataloader and download the pre-trained model from the awesome huggingface library. . def proc_img(input_img): img = input_img.rotate(angle=270, resample=0, expand=10, center=None, translate=None, fillcolor=None) img = img.filter(ImageFilter.MedianFilter) return img . def get_text(img): return pytesseract.image_to_string(img, lang=&quot;deu&quot;) . def use_pattern(text): return pattern.sub(lambda m: rep[re.escape(m.group(0))], text) . rep = {&quot; n&quot;: &quot;&quot;, &quot;`&quot;: &quot;&quot;, &#39;%&#39;:&quot;&quot;, &#39;°&#39;: &#39;&#39;, &#39;&amp;&#39;:&#39;&#39;, &#39;‘&#39;:&#39;&#39;, &#39;€&#39;:&#39;e&#39;, &#39;®&#39;:&#39;&#39;, &#39; &#39;: &#39;&#39;, &#39;5&#39;:&#39;s&#39;, &#39;1&#39;:&#39;i&#39;, &#39;_&#39;:&#39;&#39;, &#39;-&#39;:&#39;&#39;} # define desired replacements here # use these three lines to do the replacement rep = dict((re.escape(k), v) for k, v in rep.items()) #Python 3 renamed dict.iteritems to dict.items so use rep.items() for latest versions pattern = re.compile(&quot;|&quot;.join(rep.keys())) . # Tokenize all of the sentences and map the tokens to thier word IDs. def tokenize_text(sent): input_ids = [] attention_masks = [] encoded_dict = tokenizer.encode_plus( sent, # Sentence to encode. add_special_tokens = True, # Add &#39;[CLS]&#39; and &#39;[SEP]&#39; truncation=True, max_length = 256, # Pad &amp; truncate all sentences. pad_to_max_length = True, #padding=&#39;longest&#39;, return_attention_mask = True, # Construct attn. masks. return_tensors = &#39;pt&#39;, # Return pytorch tensors. ) # Add the encoded sentence to the list. input_ids.append(encoded_dict[&#39;input_ids&#39;]) # And its attention mask (simply differentiates padding from non-padding). attention_masks.append(encoded_dict[&#39;attention_mask&#39;]) # Convert the lists into tensors. input_ids = torch.cat(input_ids, dim=0) attention_masks = torch.cat(attention_masks, dim=0) return input_ids, attention_masks . def create_dataloader(text): input_ids, attention_masks = tokenize_text(text) dataset = TensorDataset(input_ids, attention_masks) batch_size = 1 app_dataloader = DataLoader( dataset, # The validation samples. batch_size = batch_size # Evaluate with this batch size. ) return app_dataloader . def predict(dataloader): # Prediction on test set device = torch.device(&#39;cpu&#39;) # Put model in evaluation mode model.eval() # Tracking variables predictions = [] # Predict for batch in dataloader: # Add batch to CPU batch = tuple(t.to(device) for t in batch) # Unpack the inputs from our dataloader b_input_ids, b_input_mask = batch # Telling the model not to compute or store gradients, saving memory and # speeding up prediction with torch.no_grad(): # Forward pass, calculate logit predictions outputs = model(b_input_ids, token_type_ids=None, attention_mask=b_input_mask) logits = outputs[0] # Move logits and labels to CPU logits = logits.detach().cpu().numpy() # Store predictions and true labels predictions.append(logits) return np.argmax(predictions) . PRE_TRAINED_MODEL_NAME = &#39;bert-base-german-cased&#39; # Load the BERT tokenizer tokenizer = torch.hub.load(&#39;huggingface/pytorch-transformers&#39;, &#39;tokenizer&#39;, PRE_TRAINED_MODEL_NAME) # Download vocabulary from S3 and cache. n_classes=5 model = BertForSequenceClassification.from_pretrained( &quot;bert-base-german-cased&quot;, # Use the 12-layer BERT model, with an uncased vocab. num_labels = n_classes, # The number of output labels--2 for binary classification. # You can increase this for multi-class tasks. output_attentions = False, # Whether the model returns attentions weights. output_hidden_states = False, # Whether the model returns all hidden-states. ) . Downloading: &#34;https://github.com/huggingface/pytorch-transformers/archive/master.zip&#34; to /root/.cache/torch/hub/master.zip . . p = Path.cwd() . Even though we trained the model on GPU, that&#39;s not what we want for production. So I load my model onto CPU. . device = torch.device(&#39;cpu&#39;) model.load_state_dict(torch.load(p/&#39;export.pkl&#39;, map_location=device)) . btn_upload = widgets.FileUpload() out_pl = widgets.Output() rating_widget = widgets.Label() btn_run = widgets.Button(description=&#39;Lasses Empfehlung:&#39;) . def on_click_text(change): img = PILImage.create(btn_upload.data[-1]) out_pl.clear_output() with out_pl: display(proc_img(img).to_thumb(256,256)) text = use_pattern(get_text(proc_img(img))) star_rating = predict(create_dataloader(text)) rating_widget.value = f&#39;Lasse würde diesem Buch {star_rating+1} Stern(e) von 5 Sternen geben!&#39; . btn_run.on_click(on_click_text) . VBox([widgets.Label(&#39;Upload Bild von Buchseite&#39;), btn_upload, btn_run, out_pl, rating_widget]) . Perfect, that worked like a charme! Coming up I will show you how to take this notebook and turn it into a little web app. So stay tuned! . Lasse .",
            "url": "https://lschmiddey.github.io/fastpages_/2020/09/27/Prepare-Notebook-for-App-Part3.html",
            "relUrl": "/2020/09/27/Prepare-Notebook-for-App-Part3.html",
            "date": " • Sep 27, 2020"
        }
        
    
  
    
        ,"post20": {
            "title": "Use pretrained BERT model for classification",
            "content": "Would Lasse recommend this book? . This is the second part of the three part blogpost on my NLP project. In this blogpost I will show you how to use a pretrained BERT model to finetune a model to predict how I would rate a book based on one page. In the first part I showed how to build the dataset. Now I will show you how to use this data to basically build a model from that. First, let&#39;s get our packages. . !pip install transformers !pip install seaborn . from pathlib import Path import numpy as np import pandas as pd import torch import torch.nn as nn from sklearn.model_selection import train_test_split from sklearn.metrics import classification_report import transformers from transformers import BertTokenizer, BertForSequenceClassification # specify GPU device = torch.device(&quot;cuda&quot;) . We then load the data we got from our images in combination with pytesseract. . Load Data . p = Path.cwd() complete_df = pd.read_csv(p/&#39;datasets/text_df.csv&#39;) complete_df.head() . text title rating . 0 war ein schrecklicher Rückfall eingetreten.In ... | gegendenStrich | 1 | . 1 höchst moralischer Akt, die Welt von einem sol... | derSeewolf | 5 | . 2 deutsches Luder nehmen. Und sollten Sie es dan... | ButchersCrossing | 4 | . 3 müssen.»Sie kamen jetzt in die Vorstadt. Die S... | diePest | 2 | . 4 ins Gesicht, wandte sich von ihrem traurigen A... | diePest | 2 | . We only need the text and my rating. We also need to substract 1 from my rating for indexing purposes for the cross entropy loss function. . df = pd.DataFrame({ &#39;label&#39;: complete_df.iloc[:,2]-1, &#39;text&#39;: complete_df.iloc[:,0] }) df.head() . label text . 0 0 | war ein schrecklicher Rückfall eingetreten.In ... | . 1 4 | höchst moralischer Akt, die Welt von einem sol... | . 2 3 | deutsches Luder nehmen. Und sollten Sie es dan... | . 3 1 | müssen.»Sie kamen jetzt in die Vorstadt. Die S... | . 4 1 | ins Gesicht, wandte sich von ihrem traurigen A... | . # Get the lists of sentences and their labels. sentences = df.text.values labels = df.label.values . Bert Tokenizer . My data is in German. Luckily, the awesome huggingface library provides a crazy amount of pretrained models in languages from all over the world. We first need our tokenizer: . PRE_TRAINED_MODEL_NAME = &#39;bert-base-german-cased&#39; # Load the BERT tokenizer tokenizer = torch.hub.load(&#39;huggingface/pytorch-transformers&#39;, &#39;tokenizer&#39;, PRE_TRAINED_MODEL_NAME) # Download vocabulary from S3 and cache. . Using cache found in /root/.cache/torch/hub/huggingface_pytorch-transformers_master . Let&#39;s look what the tokenizer does to our text sentences: . # Print the original sentence. print(&#39; Original: &#39;, sentences[0]) # Print the sentence split into tokens. print(&#39;Tokenized: &#39;, tokenizer.tokenize(sentences[0])) # Print the sentence mapped to token ids. print(&#39;Token IDs: &#39;, tokenizer.convert_tokens_to_ids(tokenizer.tokenize(sentences[0]))) . Original: war ein schrecklicher Rückfall eingetreten.In dem »verheirateten Priester« wurde das LobChristi von Barbey d’Aurévilly gesungen; in »LesDiaboliques« hatte sich der Verfasser dem Teufel ergeben, den er pries; und jetzt erschien der Sadismus,dieser Bastard des Katholizismus, den die Religion inallen Formen mit Exorzismen und Scheiterhaufendurch alle Jahrhunderte verfolgt hat.Mit Barbey d’Aurévilly nahm die Serie der reli—giösen Schriftsteller ein Ende. Eigentlich gehörte dieser Paria in jeder Hinsicht mehr zur weltlichen Literatur als zu jener andern, bei der er einen Platzbeanspruchte, den man ihm verweigerte. Seine Sprache war die des wilden Romantismus, voll gewunde—ner Wendungen und übertriebener Vergleiche, undeigentlich erschien d’Aurévilly wie ein Zuchthengstunter diesen Wallachen, die die ultramontanen StalleDem Herzog kamen diese Betrachtungen heimgelegentlichen Wiederlesen einiger Stellen diesesC L ( ii i „ .. ‚]:„„„„ „a.—näepn alwxxr9rl’iﬂ» Tokenized: [&#39;war&#39;, &#39;ein&#39;, &#39;schreck&#39;, &#39;##licher&#39;, &#39;Rück&#39;, &#39;##fall&#39;, &#39;eingetreten&#39;, &#39;.&#39;, &#39;In&#39;, &#39;dem&#39;, &#39;[UNK]&#39;, &#39;verheiratet&#39;, &#39;##en&#39;, &#39;Priester&#39;, &#39;[UNK]&#39;, &#39;wurde&#39;, &#39;das&#39;, &#39;Lob&#39;, &#39;##Christ&#39;, &#39;##i&#39;, &#39;von&#39;, &#39;Barb&#39;, &#39;##ey&#39;, &#39;d&#39;, &#39;[UNK]&#39;, &#39;[UNK]&#39;, &#39;gesungen&#39;, &#39;;&#39;, &#39;in&#39;, &#39;[UNK]&#39;, &#39;Les&#39;, &#39;##Di&#39;, &#39;##ab&#39;, &#39;##oli&#39;, &#39;##ques&#39;, &#39;[UNK]&#39;, &#39;hatte&#39;, &#39;sich&#39;, &#39;der&#39;, &#39;Verfasser&#39;, &#39;dem&#39;, &#39;Teufel&#39;, &#39;ergeben&#39;, &#39;,&#39;, &#39;den&#39;, &#39;er&#39;, &#39;pri&#39;, &#39;##es&#39;, &#39;;&#39;, &#39;und&#39;, &#39;jetzt&#39;, &#39;erschien&#39;, &#39;der&#39;, &#39;Sad&#39;, &#39;##ismus&#39;, &#39;,&#39;, &#39;dieser&#39;, &#39;Bast&#39;, &#39;##ard&#39;, &#39;des&#39;, &#39;Kathol&#39;, &#39;##izismus&#39;, &#39;,&#39;, &#39;den&#39;, &#39;die&#39;, &#39;Religion&#39;, &#39;in&#39;, &#39;##allen&#39;, &#39;Formen&#39;, &#39;mit&#39;, &#39;Ex&#39;, &#39;##or&#39;, &#39;##zi&#39;, &#39;##sm&#39;, &#39;##en&#39;, &#39;und&#39;, &#39;Schei&#39;, &#39;##ter&#39;, &#39;##haufen&#39;, &#39;##durch&#39;, &#39;alle&#39;, &#39;Jahrhunderte&#39;, &#39;verfolgt&#39;, &#39;hat&#39;, &#39;.&#39;, &#39;Mit&#39;, &#39;Barb&#39;, &#39;##ey&#39;, &#39;d&#39;, &#39;[UNK]&#39;, &#39;[UNK]&#39;, &#39;nahm&#39;, &#39;die&#39;, &#39;Serie&#39;, &#39;der&#39;, &#39;rel&#39;, &#39;##i&#39;, &#39;[UNK]&#39;, &#39;g&#39;, &#39;##i&#39;, &#39;##ösen&#39;, &#39;Schriftsteller&#39;, &#39;ein&#39;, &#39;Ende&#39;, &#39;.&#39;, &#39;Eigentlich&#39;, &#39;gehörte&#39;, &#39;dieser&#39;, &#39;Par&#39;, &#39;##ia&#39;, &#39;in&#39;, &#39;jeder&#39;, &#39;Hinsicht&#39;, &#39;mehr&#39;, &#39;zur&#39;, &#39;welt&#39;, &#39;##lichen&#39;, &#39;Literatur&#39;, &#39;als&#39;, &#39;zu&#39;, &#39;jener&#39;, &#39;andern&#39;, &#39;,&#39;, &#39;bei&#39;, &#39;der&#39;, &#39;er&#39;, &#39;einen&#39;, &#39;Platz&#39;, &#39;##be&#39;, &#39;##anspruch&#39;, &#39;##te&#39;, &#39;,&#39;, &#39;den&#39;, &#39;man&#39;, &#39;ihm&#39;, &#39;verweigerte&#39;, &#39;.&#39;, &#39;Seine&#39;, &#39;Sprache&#39;, &#39;war&#39;, &#39;die&#39;, &#39;des&#39;, &#39;wild&#39;, &#39;##en&#39;, &#39;Roman&#39;, &#39;##ti&#39;, &#39;##sm&#39;, &#39;##us&#39;, &#39;,&#39;, &#39;voll&#39;, &#39;gew&#39;, &#39;##unde&#39;, &#39;[UNK]&#39;, &#39;ne&#39;, &#39;##r&#39;, &#39;Wend&#39;, &#39;##ungen&#39;, &#39;und&#39;, &#39;übert&#39;, &#39;##riebene&#39;, &#39;##r&#39;, &#39;Vergleich&#39;, &#39;##e&#39;, &#39;,&#39;, &#39;und&#39;, &#39;##eigent&#39;, &#39;##lich&#39;, &#39;erschien&#39;, &#39;d&#39;, &#39;[UNK]&#39;, &#39;[UNK]&#39;, &#39;wie&#39;, &#39;ein&#39;, &#39;Zucht&#39;, &#39;##hen&#39;, &#39;##gst&#39;, &#39;##unter&#39;, &#39;diesen&#39;, &#39;Wall&#39;, &#39;##achen&#39;, &#39;,&#39;, &#39;die&#39;, &#39;die&#39;, &#39;u&#39;, &#39;##lt&#39;, &#39;##ram&#39;, &#39;##ont&#39;, &#39;##anen&#39;, &#39;Stall&#39;, &#39;##e&#39;, &#39;##Dem&#39;, &#39;Herzog&#39;, &#39;kamen&#39;, &#39;diese&#39;, &#39;Betrachtung&#39;, &#39;##en&#39;, &#39;heim&#39;, &#39;##gelegen&#39;, &#39;##tlichen&#39;, &#39;Wieder&#39;, &#39;##lesen&#39;, &#39;einiger&#39;, &#39;Stellen&#39;, &#39;dieses&#39;, &#39;##C&#39;, &#39;L&#39;, &#39;(&#39;, &#39;i&#39;, &#39;##i&#39;, &#39;i&#39;, &#39;[UNK]&#39;, &#39;.&#39;, &#39;.&#39;, &#39;[UNK]&#39;, &#39;]&#39;, &#39;:&#39;, &#39;[UNK]&#39;, &#39;[UNK]&#39;, &#39;[UNK]&#39;, &#39;[UNK]&#39;, &#39;[UNK]&#39;, &#39;a&#39;, &#39;.&#39;, &#39;[UNK]&#39;, &#39;n&#39;, &#39;##ä&#39;, &#39;##ep&#39;, &#39;##n&#39;, &#39;al&#39;, &#39;##w&#39;, &#39;##xx&#39;, &#39;##r&#39;, &#39;##9&#39;, &#39;##r&#39;, &#39;##l&#39;, &#39;[UNK]&#39;, &#39;[UNK]&#39;, &#39;[UNK]&#39;] Token IDs: [185, 39, 21387, 766, 1060, 441, 9387, 26914, 173, 128, 2, 5025, 7, 7335, 2, 192, 93, 10929, 17339, 26899, 88, 18304, 8145, 9, 2, 2, 20397, 26968, 50, 2, 4189, 15845, 228, 13078, 11226, 2, 466, 144, 21, 18241, 128, 18649, 4254, 26918, 86, 67, 22074, 16, 26968, 42, 1868, 3368, 21, 16073, 1500, 26918, 534, 16804, 587, 91, 9032, 20438, 26918, 86, 30, 9373, 50, 2700, 7685, 114, 1108, 34, 517, 6694, 7, 42, 11168, 60, 26128, 4912, 987, 16902, 7547, 193, 26914, 304, 18304, 8145, 9, 2, 2, 1995, 30, 4345, 21, 4628, 26899, 2, 111, 26899, 3670, 6425, 39, 926, 26914, 13935, 2374, 534, 1059, 544, 50, 2617, 8110, 380, 252, 3522, 248, 3595, 153, 81, 8310, 19919, 26918, 178, 21, 67, 303, 1361, 165, 4465, 26, 26918, 86, 478, 787, 26792, 26914, 2072, 4247, 185, 30, 91, 24703, 7, 3529, 15099, 6694, 51, 26918, 1352, 397, 1270, 2, 2055, 26900, 16380, 184, 42, 8685, 25630, 26900, 3115, 26897, 26918, 42, 7656, 68, 3368, 9, 2, 2, 246, 39, 17373, 215, 22336, 940, 1377, 5405, 794, 26918, 30, 30, 2118, 362, 1021, 710, 6678, 16993, 26897, 12939, 5996, 3484, 620, 12115, 7, 6488, 10547, 5323, 2261, 18921, 7844, 4812, 1328, 26958, 94, 26954, 46, 26899, 46, 2, 26914, 26914, 2, 26985, 26964, 2, 2, 2, 2, 2, 18, 26914, 2, 53, 26923, 3154, 26898, 1119, 26915, 21591, 26900, 26942, 26900, 26907, 2, 2, 2] . So our bert-base-german-cased tokenizer splits the words into reasonable parts, which correspond to the token ids (input ids). . Tokenize Dataset . Let&#39;s check the length for each sequence and print the max sequence length. . max_len = 0 # For every sentence... for sent in sentences: # Tokenize the text and add `[CLS]` and `[SEP]` tokens. input_ids = tokenizer.encode(sent, add_special_tokens=True) # Update the maximum sentence length. max_len = max(max_len, len(input_ids)) print(&#39;Max sentence length: &#39;, max_len) . Token indices sequence length is longer than the specified maximum sequence length for this model (538 &gt; 512). Running this sequence through the model will result in indexing errors . Max sentence length: 538 . Das Maximum sentence length is 538. However, the maximum sentence length allowed by Bert is 512, so we have to set max_len to 256. Next, we tokenize all of our sentences. . # Tokenize all of the sentences and map the tokens to thier word IDs. input_ids = [] attention_masks = [] # For every sentence... for sent in sentences: # `encode_plus` will: # (1) Tokenize the sentence. # (2) Prepend the `[CLS]` token to the start. # (3) Append the `[SEP]` token to the end. # (4) Map tokens to their IDs. # (5) Pad or truncate the sentence to `max_length` # (6) Create attention masks for [PAD] tokens. encoded_dict = tokenizer.encode_plus( sent, # Sentence to encode. add_special_tokens = True, # Add &#39;[CLS]&#39; and &#39;[SEP]&#39; truncation=True, max_length = 256, # Pad &amp; truncate all sentences. pad_to_max_length = True, #padding=&#39;max_length=256&#39;, return_attention_mask = True, # Construct attn. masks. return_tensors = &#39;pt&#39;, # Return pytorch tensors. ) # Add the encoded sentence to the list. input_ids.append(encoded_dict[&#39;input_ids&#39;]) # And its attention mask (simply differentiates padding from non-padding). attention_masks.append(encoded_dict[&#39;attention_mask&#39;]) # Convert the lists into tensors. input_ids = torch.cat(input_ids, dim=0) attention_masks = torch.cat(attention_masks, dim=0) labels = torch.tensor(labels) . /opt/conda/envs/fastai/lib/python3.8/site-packages/transformers/tokenization_utils_base.py:1764: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding=&#39;longest&#39;` to pad to the longest sequence in the batch, or use `padding=&#39;max_length&#39;` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert). warnings.warn( . Training and Validation Set . We then put our data into a pytorch dataset and split the data into training and validation set. . from torch.utils.data import TensorDataset, random_split # Combine the training inputs into a TensorDataset. dataset = TensorDataset(input_ids, attention_masks, labels) # Create a 80-20 train-validation split. # Calculate the number of samples to include in each set. train_size = int(0.8 * len(dataset)) val_size = len(dataset) - train_size # Divide the dataset by randomly selecting samples. train_dataset, val_dataset = random_split(dataset, [train_size, val_size]) print(&#39;{:&gt;5,} training samples&#39;.format(train_size)) print(&#39;{:&gt;5,} validation samples&#39;.format(val_size)) . 75 training samples 19 validation samples . from torch.utils.data import DataLoader, RandomSampler, SequentialSampler # We take a batch size of 16 batch_size = 16 # We&#39;ll take training samples in random order. train_dataloader = DataLoader( train_dataset, sampler = RandomSampler(train_dataset), batch_size = batch_size ) # For validation the order doesn&#39;t matter, so we&#39;ll just read them sequentially. validation_dataloader = DataLoader( val_dataset, sampler = SequentialSampler(val_dataset), batch_size = batch_size ) . After putting the dataset into a dataloader we define how many different classes we&#39;ve got. . n_classes=5 . Get pretrained model . model = BertForSequenceClassification.from_pretrained( &quot;bert-base-german-cased&quot;, # Use the 12-layer BERT model, with an uncased vocab. num_labels = n_classes, # The number of output labels--2 for binary classification. # You can increase this for multi-class tasks. output_attentions = False, # Whether the model returns attentions weights. output_hidden_states = False, # Whether the model returns all hidden-states. ) # Tell pytorch to run this model on the GPU. model.cuda(); . Some weights of the model checkpoint at bert-base-german-cased were not used when initializing BertForSequenceClassification: [&#39;cls.predictions.bias&#39;, &#39;cls.predictions.transform.dense.weight&#39;, &#39;cls.predictions.transform.dense.bias&#39;, &#39;cls.predictions.transform.LayerNorm.weight&#39;, &#39;cls.predictions.transform.LayerNorm.bias&#39;, &#39;cls.predictions.decoder.weight&#39;, &#39;cls.seq_relationship.weight&#39;, &#39;cls.seq_relationship.bias&#39;] - This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPretraining model). - This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model). Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-german-cased and are newly initialized: [&#39;classifier.weight&#39;, &#39;classifier.bias&#39;] You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference. . Optimizer and Learning Rate . We use AdamW as our optimizer and use CrossEntropyLoss as our loss function. . from transformers import AdamW . # Note: AdamW is a class from the huggingface library (as opposed to pytorch) # I believe the &#39;W&#39; stands for &#39;Weight Decay fix&quot; optimizer = AdamW(model.parameters(), lr = 2e-4, # args.learning_rate - default is 5e-5, our notebook had 2e-5 eps = 1e-8 # args.adam_epsilon - default is 1e-8. ) . from transformers import get_linear_schedule_with_warmup epochs = 5 # Total number of training steps is [number of batches] x [number of epochs]. # (Note that this is not the same as the number of training samples). total_steps = len(train_dataloader) * epochs # Create the learning rate scheduler. scheduler = get_linear_schedule_with_warmup(optimizer, num_warmup_steps = 10, # Default value in run_glue.py num_training_steps = total_steps) . loss_fn = nn.CrossEntropyLoss().to(device) . def format_time(elapsed): &#39;&#39;&#39; Takes a time in seconds and returns a string hh:mm:ss &#39;&#39;&#39; # Round to the nearest second. elapsed_rounded = int(round((elapsed))) # Format as hh:mm:ss return str(datetime.timedelta(seconds=elapsed_rounded)) . Train Model . Let&#39;s train our model! . import random import numpy as np import time import datetime seed_val = 42 random.seed(seed_val) np.random.seed(seed_val) torch.manual_seed(seed_val) torch.cuda.manual_seed_all(seed_val) # We&#39;ll store a number of quantities such as training and validation loss, # validation accuracy, and timings. training_stats = [] # Measure the total training time for the whole run. total_t0 = time.time() # For each epoch... for epoch_i in range(0, epochs): # ======================================== # Training # ======================================== # Perform one full pass over the training set. print(&quot;&quot;) print(&#39;======== Epoch {:} / {:} ========&#39;.format(epoch_i + 1, epochs)) print(&#39;Training...&#39;) # Measure how long the training epoch takes. t0 = time.time() # Reset the total loss for this epoch. total_train_loss = 0 model.train() # For each batch of training data... for step, batch in enumerate(train_dataloader): # Progress update every 40 batches. if step % 40 == 0 and not step == 0: # Calculate elapsed time in minutes. elapsed = format_time(time.time() - t0) # Report progress. print(f&#39;Batch:{step} of {len(train_dataloader)}. Elapsed: {elapsed}&#39;) # `batch` contains three pytorch tensors: # [0]: input ids # [1]: attention masks # [2]: labels b_input_ids = batch[0].to(device) b_input_mask = batch[1].to(device) b_labels = batch[2].to(device) model.zero_grad() loss, logits = model(b_input_ids, token_type_ids=None, attention_mask=b_input_mask, labels=b_labels) total_train_loss += loss.item() loss.backward() # Clip the norm of the gradients to 1.0. # This is to help prevent the &quot;exploding gradients&quot; problem. torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0) optimizer.step() # Update the learning rate. scheduler.step() # Calculate the average loss over all of the batches. avg_train_loss = total_train_loss / len(train_dataloader) # Measure how long this epoch took. training_time = format_time(time.time() - t0) print(&quot;&quot;) print(&quot; Average training loss: {0:.2f}&quot;.format(avg_train_loss)) print(&quot; Training epoch took: {:}&quot;.format(training_time)) # ======================================== # Validation # ======================================== # After the completion of each training epoch, measure our performance on # our validation set. print(&quot;&quot;) print(&quot;Running Validation...&quot;) t0 = time.time() # Put the model in evaluation mode--the dropout layers behave differently # during evaluation. model.eval() # Tracking variables total_eval_accuracy = 0 total_eval_loss = 0 nb_eval_steps = 0 # Evaluate data for one epoch for batch in validation_dataloader: b_input_ids = batch[0].to(device) b_input_mask = batch[1].to(device) b_labels = batch[2].to(device) (loss, logits) = model(b_input_ids, token_type_ids=None, attention_mask=b_input_mask, labels=b_labels) # Accumulate the validation loss. total_eval_loss += loss.item() # Calculate the average loss over all of the batches. avg_val_loss = total_eval_loss / len(validation_dataloader) # Measure how long the validation run took. validation_time = format_time(time.time() - t0) print(f&#39;Validation Loss: {avg_val_loss}&#39;) print(f&#39;Validation took: {validation_time}&#39;) # Record all statistics from this epoch. training_stats.append( { &#39;epoch&#39;: epoch_i + 1, &#39;Training Loss&#39;: avg_train_loss, &#39;Valid. Loss&#39;: avg_val_loss, &#39;Training Time&#39;: training_time, &#39;Validation Time&#39;: validation_time } ) print(&quot;&quot;) print(&quot;Training complete!&quot;) print(&quot;Total training took {:} (h:mm:ss)&quot;.format(format_time(time.time()-total_t0))) . ======== Epoch 1 / 5 ======== Training... Average training loss: 1.52 Training epoch took: 0:00:07 Running Validation... Validation Loss: 1.3076387345790863 Validation took: 0:00:01 ======== Epoch 2 / 5 ======== Training... Average training loss: 1.34 Training epoch took: 0:00:07 Running Validation... Validation Loss: 1.1822895407676697 Validation took: 0:00:01 ======== Epoch 3 / 5 ======== Training... Average training loss: 0.85 Training epoch took: 0:00:07 Running Validation... Validation Loss: 0.8835422396659851 Validation took: 0:00:01 ======== Epoch 4 / 5 ======== Training... Average training loss: 0.32 Training epoch took: 0:00:07 Running Validation... Validation Loss: 0.46347731351852417 Validation took: 0:00:01 ======== Epoch 5 / 5 ======== Training... Average training loss: 0.13 Training epoch took: 0:00:07 Running Validation... Validation Loss: 0.4694706201553345 Validation took: 0:00:01 Training complete! Total training took 0:00:40 (h:mm:ss) . Evaluation . # Display floats with two decimal places. pd.set_option(&#39;precision&#39;, 2) # Create a DataFrame from our training statistics. df_stats = pd.DataFrame(data=training_stats) # Use the &#39;epoch&#39; as the row index. df_stats = df_stats.set_index(&#39;epoch&#39;) # Display the table. df_stats . Training Loss Valid. Loss Training Time Validation Time . epoch . 1 1.52 | 1.31 | 0:00:07 | 0:00:01 | . 2 1.34 | 1.18 | 0:00:07 | 0:00:01 | . 3 0.85 | 0.88 | 0:00:07 | 0:00:01 | . 4 0.32 | 0.46 | 0:00:07 | 0:00:01 | . 5 0.13 | 0.47 | 0:00:07 | 0:00:01 | . import matplotlib.pyplot as plt import seaborn as sns # Use plot styling from seaborn. sns.set(style=&#39;darkgrid&#39;) # Increase the plot size and font size. sns.set(font_scale=1.5) plt.rcParams[&quot;figure.figsize&quot;] = (12,6) # Plot the learning curve. plt.plot(df_stats[&#39;Training Loss&#39;], &#39;b-o&#39;, label=&quot;Training&quot;) plt.plot(df_stats[&#39;Valid. Loss&#39;], &#39;g-o&#39;, label=&quot;Validation&quot;) # Label the plot. plt.title(&quot;Training &amp; Validation Loss&quot;) plt.xlabel(&quot;Epoch&quot;) plt.ylabel(&quot;Loss&quot;) plt.legend() plt.xticks([1, 2, 3, 4]) plt.show() . Look at results . So far, we can see that our model learns. Let&#39;s have a look how the predictions on our trainloader look like: . # Prediction on test set # Put model in evaluation mode model.eval() # Tracking variables predictions , true_labels = [], [] # Predict for batch in train_dataloader: # Add batch to GPU batch = tuple(t.to(device) for t in batch) # Unpack the inputs from our dataloader b_input_ids, b_input_mask, b_labels = batch with torch.no_grad(): # Forward pass, calculate logit predictions outputs = model(b_input_ids, token_type_ids=None, attention_mask=b_input_mask) logits = outputs[0] # Move logits and labels to CPU logits = logits.detach().cpu().numpy() label_ids = b_labels.to(&#39;cpu&#39;).numpy() # Store predictions and true labels predictions.append(logits) true_labels.append(label_ids) print(&#39; DONE.&#39;) . DONE. DONE. DONE. DONE. DONE. . np.argmax(predictions[4], axis=1) . array([0, 4, 4, 0, 4, 3, 3, 3, 4, 3, 4]) . true_labels[4] . array([0, 4, 4, 0, 4, 3, 3, 3, 4, 3, 4]) . Well that looks right. However, this is the data we trained our model on. Way more interesting is the data our model hasn&#39;t trained on: . # Prediction on test set # Put model in evaluation mode model.eval() # Tracking variables predictions , true_labels = [], [] # Predict for batch in validation_dataloader: # Add batch to GPU batch = tuple(t.to(device) for t in batch) # Unpack the inputs from our dataloader b_input_ids, b_input_mask, b_labels = batch with torch.no_grad(): # Forward pass, calculate logit predictions outputs = model(b_input_ids, token_type_ids=None, attention_mask=b_input_mask) logits = outputs[0] # Move logits and labels to CPU logits = logits.detach().cpu().numpy() label_ids = b_labels.to(&#39;cpu&#39;).numpy() # Store predictions and true labels predictions.append(logits) true_labels.append(label_ids) print(&#39; DONE.&#39;) . DONE. DONE. . np.argmax(predictions[0], axis=1) . array([4, 3, 2, 1, 4, 0, 4, 1, 0, 1, 3, 4, 3, 4, 1, 4]) . true_labels[0] . array([3, 3, 1, 1, 4, 0, 0, 1, 0, 1, 3, 4, 3, 4, 1, 4]) . Awesome! We have quite some variation in our prediction and most of the time they look pretty good! We save our model: . Save Model . torch.save(model.state_dict(), p/&#39;model/model_5epochs_lr1e-4.pt&#39;) . To further improve the model, I will get more data and then retrain it. However, I think so far the model does a pretty good job in replacing me when it comes to book recommendations. . In the next part I will show you how to use Binder to make a small web application in which we can upload a picture of a page and then make a prediction how many stars I would probably give this book. . So stay tuned for the next blogpost! . Lasse .",
            "url": "https://lschmiddey.github.io/fastpages_/2020/09/26/Use-pretrained-Bert-model-for-classification-Part2.html",
            "relUrl": "/2020/09/26/Use-pretrained-Bert-model-for-classification-Part2.html",
            "date": " • Sep 26, 2020"
        }
        
    
  
    
        ,"post21": {
            "title": "Teach Python how to read",
            "content": "Using PIL and pytesseract . This is the first blogpost of a three to four (I haven&#39;t decided yet) part project. The main idea is that I want to create a model which will tell me how much I would like the book, given an image of a page as in input. . In this part, I will show you how to turn a image of text into actual text, using pytesseract. So let&#39;s first get our packages. . Import packages . !apt-get update !apt-get install libleptonica-dev -y !apt-get install tesseract-ocr tesseract-ocr-dev -y !apt-get install libtesseract-dev -y !apt-get install tesseract-ocr-deu . Ign:1 http://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu1604/x86_64 InRelease Hit:2 http://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu1604/x86_64 Release Hit:3 http://security.ubuntu.com/ubuntu xenial-security InRelease Ign:5 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1604/x86_64 InRelease Hit:6 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1604/x86_64 Release Hit:7 http://archive.ubuntu.com/ubuntu xenial InRelease Hit:9 http://archive.ubuntu.com/ubuntu xenial-updates InRelease Hit:10 http://archive.ubuntu.com/ubuntu xenial-backports InRelease Reading package lists... Done Reading package lists... Done Building dependency tree Reading state information... Done libleptonica-dev is already the newest version (1.73-1). 0 upgraded, 0 newly installed, 0 to remove and 39 not upgraded. Reading package lists... Done Building dependency tree Reading state information... Done tesseract-ocr is already the newest version (3.04.01-4). tesseract-ocr-dev is already the newest version (3.04.01-4). 0 upgraded, 0 newly installed, 0 to remove and 39 not upgraded. Reading package lists... Done Building dependency tree Reading state information... Done libtesseract-dev is already the newest version (3.04.01-4). 0 upgraded, 0 newly installed, 0 to remove and 39 not upgraded. Reading package lists... Done Building dependency tree Reading state information... Done The following NEW packages will be installed: tesseract-ocr-deu 0 upgraded, 1 newly installed, 0 to remove and 39 not upgraded. Need to get 4153 kB of archives. After this operation, 13.4 MB of additional disk space will be used. Get:1 http://archive.ubuntu.com/ubuntu xenial/universe amd64 tesseract-ocr-deu all 3.04.00-1 [4153 kB] Fetched 4153 kB in 1s (2333 kB/s) debconf: delaying package configuration, since apt-utils is not installed Selecting previously unselected package tesseract-ocr-deu. (Reading database ... 18655 files and directories currently installed.) Preparing to unpack .../tesseract-ocr-deu_3.04.00-1_all.deb ... Unpacking tesseract-ocr-deu (3.04.00-1) ... Setting up tesseract-ocr-deu (3.04.00-1) ... . !pip install pytesseract . Requirement already satisfied: pytesseract in /opt/conda/envs/fastai/lib/python3.8/site-packages (0.3.6) Requirement already satisfied: Pillow in /opt/conda/envs/fastai/lib/python3.8/site-packages (from pytesseract) (7.2.0) . from fastai.vision.all import * from fastai.vision.widgets import * import numpy as np from pathlib import Path import pytesseract import re from PIL import Image, ImageFilter import pandas as pd . Define PosixPath to data . I took about 100 images of pages from books I own (all in German). I then put them in an image folder, let&#39;s have a look at the directory. . p = Path.cwd()/&#39;images&#39; . img_paths = [x for x in p.iterdir()] . img_paths[0].parts[5] . &#39;IMG_5123_gegendenStrich.jpg&#39; . Use regex to extract title of book . Next to the text from the image, I would like to extract the title of the book so I can later easily join my ratings to the texts. I therefore use a regex. . title_list = [re.match(&quot;^.* _(.*) ..*$&quot;,img_paths[i].parts[5]).group(1) for i in range(len(img_paths))] . Automatically read in images, transform them and get text . We use pytesseract for extracting the text from the images. To improve the performance I tried a lot of data transformation: cropping, binarizing and a lot more. The only thing that worked for me was to first rotate the image and then use a MedianFilter. . def proc_img(img_path): im1 = Image.open(img_path) im1 = im1.rotate(angle=270, resample=0, expand=10, center=None, translate=None, fillcolor=None) im1 = im1.filter(ImageFilter.MedianFilter) return im1 . All of my input images are from german books, so I need to use lang=&quot;deu&quot;. . def get_text(img): return pytesseract.image_to_string(img, lang=&quot;deu&quot;) . I again use a regular expression to get rid of common mistakes pytesseract does: putting a n somewhere or confusing a s for a 5. . def use_pattern(text): return pattern.sub(lambda m: rep[re.escape(m.group(0))], text) . rep = {&quot; n&quot;: &quot;&quot;, &quot;`&quot;: &quot;&quot;, &#39;%&#39;:&quot;&quot;, &#39;°&#39;: &#39;&#39;, &#39;&amp;&#39;:&#39;&#39;, &#39;‘&#39;:&#39;&#39;, &#39;€&#39;:&#39;e&#39;, &#39;®&#39;:&#39;&#39;, &#39; &#39;: &#39;&#39;, &#39;5&#39;:&#39;s&#39;, &#39;1&#39;:&#39;i&#39;, &#39;_&#39;:&#39;&#39;, &#39;-&#39;:&#39;&#39;} # define desired replacements here # use these three lines to do the replacement rep = dict((re.escape(k), v) for k, v in rep.items()) #Python 3 renamed dict.iteritems to dict.items so use rep.items() for latest versions pattern = re.compile(&quot;|&quot;.join(rep.keys())) . Use tesseract to make image into text . Finally, we use a list comprehension (they&#39;re super useful) to put all of the text into a list of texts. . text_list = [use_pattern(get_text(proc_img(str(img_paths[i])))) for i in range(len(img_paths))] . Combine into Dataframe . And now let&#39;s put that into a pandas dataframe. . d = {&#39;text&#39;:text_list,&#39;title&#39;:title_list} df = pd.DataFrame(d) df.head() . text title . 0 war ein schrecklicher Rückfall eingetreten.In dem »verheirateten Priester« wurde das LobChristi von Barbey d’Aurévilly gesungen; in »LesDiaboliques« hatte sich der Verfasser dem Teufel ergeben, den er pries; und jetzt erschien der Sadismus,dieser Bastard des Katholizismus, den die Religion inallen Formen mit Exorzismen und Scheiterhaufendurch alle Jahrhunderte verfolgt hat.Mit Barbey d’Aurévilly nahm die Serie der reli—giösen Schriftsteller ein Ende. Eigentlich gehörte dieser Paria in jeder Hinsicht mehr zur weltlichen Lite—ratur als zu jener andern, bei der er einen Platzbeanspruchte, den... | gegendenStrich | . 1 höchst moralischer Akt, die Welt von einem solchen Ungeheuerzu befreien? Die Menschheit wäre dann besser und glücklicherund das Leben schöner und süßer.Ich dachte lange darüber nach. Schlaﬂos lag ich in meinerKoj e und hielt mir die Fakten vor Augen. Mit Johnson und Leachredete ich während der Nachtwachen, wenn Wolf Larsen unterDeck war. Beide Männer hatten die Hoffnung verloren — Johnson wegen seiner grundlegenden Schwermut, Leach, weil ersich in seinen vergeblichen Kämpfen erschöpft hatte. Aber eines Nachts ergriff er leidenschaftlich meine Hand und sagte:»Ich glaube, Sie sind in Ordnung... | derSeewolf | . 2 deutsches Luder nehmen. Und sollten Sie es dann allzu eilighaben, Mr. Andrews, werden Sie mich wohl von ihr runterziehen müssen.«Andrews wartete, dass die beiden Männer fortritten, undsah ihnen nach, wie sie sich durch das dämmrige Tal entfern—ten und ihre auf und ab wippenden Gestalten mit der dunkleren Schraffur der westlichen Berghänge verschmelzen. Dannaufs Neue überraschte, lenkte die Hände ab und sorgte dafür,dass ihm die eigenen Gesichtszüge fremd vorkamen; er fragtesich, wie er wohl aussah, fragte sich, ob Francine ihn wiederkennen würde, wenn sie ihn jetzt sehen könnte.Seit dem Ab... | ButchersCrossing | . 3 Doktor, das wissen Sie so gut wie ich. Vor hundert Jah—ren hat eine Pestepidemie in Persien alle Bewohner einerStadt getötet und ausgerechnet den Totenwäscher nicht,der nie aufgehört hatte, seine Arbeit zu verrichten.»müssen.»Sie kamen jetzt in die Vorstadt. Die Scheinwerfer beleuchteten die menschenleeren Straßen. Sie hielten an.Vor dem Auto fragte Rieux Tarrou, ob er mitkommenwolle, und der sagte ja. Ein Schimmer vom Himmel er—hellte ihre Gesichter. Rieux lachte plötzlich freundschaftlich.« Sagen Sie, Tarrou, was treibt Sie dazu, sich damit zubefassen? »&lt;&lt; Ich weiß nicht. Meine Moral vie... | diePest | . 4 ins Gesicht, wandte sich von ihrem traurigen Ausdruckangewidert ab, und nachdem er zum hundertsten Maldie Aushängeschilder der gegenüberliegenden Geschäfte, die Werbung für die schon nicht mehr erhält—lichen bekannten Aperitifmarken gelesen hatte, stander auf und lief ziellos durch die gelben Straßen derStadt. Er schleppte sich von einsamen Spaziergängen inCafés und von Cafés in Restaurants und erreichte soden Abend. An einem solchen Abend sah Rieux denJournalisten zögernd vor der Tür eines Cafés stehen. Erschien sich zu entschließen, ging hinein und setzte sichhinten hin. Es war um die Ze... | diePest | . df.text[3] . &#39;Doktor, das wissen Sie so gut wie ich. Vor hundert Jah—ren hat eine Pestepidemie in Persien alle Bewohner einerStadt getötet und ausgerechnet den Totenwäscher nicht,der nie aufgehört hatte, seine Arbeit zu verrichten.»müssen.»Sie kamen jetzt in die Vorstadt. Die Scheinwerfer beleuchteten die menschenleeren Straßen. Sie hielten an.Vor dem Auto fragte Rieux Tarrou, ob er mitkommenwolle, und der sagte ja. Ein Schimmer vom Himmel er—hellte ihre Gesichter. Rieux lachte plötzlich freundschaftlich.« Sagen Sie, Tarrou, was treibt Sie dazu, sich damit zubefassen? »&lt;&lt; Ich weiß nicht. Meine Moral vielleicht.»«Und die wäre? &gt;&gt;«Verständnis.»Tarrou wandte sich dem Haus zu, und Rieux sah erstwieder sein Gesicht, als sie bei dem alten Asthmatikerwaren.&#39; . Looking good! For this project I also need my ratings for each of the books. I use a dictionary and the map function to easily create a column with my ratings. . Use Dictionary to map my ratings . rating_lasse = {&#39;derPate&#39;: 5, &#39;ButchersCrossing&#39;: 4, &#39;derSeewolf&#39;: 5, &#39;JekyllandHyde&#39;: 4, &#39;gegendenStrich&#39;: 1, &#39;FruestueckmitKaengurus&#39;: 5, &#39;HuckleberryFinn&#39;: 4, &#39;diePest&#39;: 2, &#39;HerzderFinsternis&#39;: 3, &#39;derSpieler&#39;: 4} . df[&#39;rating&#39;] = df[&#39;title&#39;].map(rating_lasse) . df.head() . text title rating . 0 war ein schrecklicher Rückfall eingetreten.In dem »verheirateten Priester« wurde das LobChristi von Barbey d’Aurévilly gesungen; in »LesDiaboliques« hatte sich der Verfasser dem Teufel ergeben, den er pries; und jetzt erschien der Sadismus,dieser Bastard des Katholizismus, den die Religion inallen Formen mit Exorzismen und Scheiterhaufendurch alle Jahrhunderte verfolgt hat.Mit Barbey d’Aurévilly nahm die Serie der reli—giösen Schriftsteller ein Ende. Eigentlich gehörte dieser Paria in jeder Hinsicht mehr zur weltlichen Lite—ratur als zu jener andern, bei der er einen Platzbeanspruchte, den... | gegendenStrich | 1 | . 1 höchst moralischer Akt, die Welt von einem solchen Ungeheuerzu befreien? Die Menschheit wäre dann besser und glücklicherund das Leben schöner und süßer.Ich dachte lange darüber nach. Schlaﬂos lag ich in meinerKoj e und hielt mir die Fakten vor Augen. Mit Johnson und Leachredete ich während der Nachtwachen, wenn Wolf Larsen unterDeck war. Beide Männer hatten die Hoffnung verloren — Johnson wegen seiner grundlegenden Schwermut, Leach, weil ersich in seinen vergeblichen Kämpfen erschöpft hatte. Aber eines Nachts ergriff er leidenschaftlich meine Hand und sagte:»Ich glaube, Sie sind in Ordnung... | derSeewolf | 5 | . 2 deutsches Luder nehmen. Und sollten Sie es dann allzu eilighaben, Mr. Andrews, werden Sie mich wohl von ihr runterziehen müssen.«Andrews wartete, dass die beiden Männer fortritten, undsah ihnen nach, wie sie sich durch das dämmrige Tal entfern—ten und ihre auf und ab wippenden Gestalten mit der dunkleren Schraffur der westlichen Berghänge verschmelzen. Dannaufs Neue überraschte, lenkte die Hände ab und sorgte dafür,dass ihm die eigenen Gesichtszüge fremd vorkamen; er fragtesich, wie er wohl aussah, fragte sich, ob Francine ihn wiederkennen würde, wenn sie ihn jetzt sehen könnte.Seit dem Ab... | ButchersCrossing | 4 | . 3 Doktor, das wissen Sie so gut wie ich. Vor hundert Jah—ren hat eine Pestepidemie in Persien alle Bewohner einerStadt getötet und ausgerechnet den Totenwäscher nicht,der nie aufgehört hatte, seine Arbeit zu verrichten.»müssen.»Sie kamen jetzt in die Vorstadt. Die Scheinwerfer beleuchteten die menschenleeren Straßen. Sie hielten an.Vor dem Auto fragte Rieux Tarrou, ob er mitkommenwolle, und der sagte ja. Ein Schimmer vom Himmel er—hellte ihre Gesichter. Rieux lachte plötzlich freundschaftlich.« Sagen Sie, Tarrou, was treibt Sie dazu, sich damit zubefassen? »&lt;&lt; Ich weiß nicht. Meine Moral vie... | diePest | 2 | . 4 ins Gesicht, wandte sich von ihrem traurigen Ausdruckangewidert ab, und nachdem er zum hundertsten Maldie Aushängeschilder der gegenüberliegenden Geschäfte, die Werbung für die schon nicht mehr erhält—lichen bekannten Aperitifmarken gelesen hatte, stander auf und lief ziellos durch die gelben Straßen derStadt. Er schleppte sich von einsamen Spaziergängen inCafés und von Cafés in Restaurants und erreichte soden Abend. An einem solchen Abend sah Rieux denJournalisten zögernd vor der Tür eines Cafés stehen. Erschien sich zu entschließen, ging hinein und setzte sichhinten hin. Es war um die Ze... | diePest | 2 | . And that&#39;s it, let&#39;s save this dataframe and we&#39;re ready to move on to the model training! . df.to_csv(p/&#39;datasets/text_df.csv&#39;, encoding=&#39;utf8&#39;, index=False) . I hope you enjoyed this blogpost and stay tuned for the next one! . Lasse .",
            "url": "https://lschmiddey.github.io/fastpages_/2020/09/22/Build_Dataset_from_Images-Part1.html",
            "relUrl": "/2020/09/22/Build_Dataset_from_Images-Part1.html",
            "date": " • Sep 22, 2020"
        }
        
    
  
    
        ,"post22": {
            "title": "How to classify Lego figures",
            "content": "What better way to impress your significant other? . Build a Lego Classifier with fastai . !pip install kaggle . We want to save the dataset into the folder /notebooks/storage/data/Lego-Classification: . !kaggle datasets download -d ihelon/lego-minifigures-classification -p /notebooks/storage/data/Lego-Classification . Unzip data using Pythons pathlib library . from pathlib import Path p = Path(&#39;/notebooks/storage/data/Lego-Classification&#39;) filename = Path(&#39;/notebooks/storage/data/Lego-Classification/lego-minifigures-classification.zip&#39;) . Just as before, we can use bash commands from within Jupyter Notebook. So let&#39;s do that to unzip our data. -q is quiet mode, -d points to the direction where to unzip the data. Just see how well Pythons pathlib and bash work together! . !unzip -q {str(filename)} -d {str(p/&quot;train&quot;)} . Imports . from fastbook import * from fastai.vision.widgets import * import pandas as pd . Let&#39;s now use fastai&#39;s &quot;get_image_files()&quot; function to see how the unzipped data looks like in our destination path: . fns = get_image_files(p/&quot;train&quot;) fns . (#316) [Path(&#39;/notebooks/storage/data/Lego-Classification/train/jurassic-world/0002/009.jpg&#39;),Path(&#39;/notebooks/storage/data/Lego-Classification/train/jurassic-world/0002/010.jpg&#39;),Path(&#39;/notebooks/storage/data/Lego-Classification/train/jurassic-world/0002/006.jpg&#39;),Path(&#39;/notebooks/storage/data/Lego-Classification/train/jurassic-world/0002/001.jpg&#39;),Path(&#39;/notebooks/storage/data/Lego-Classification/train/jurassic-world/0002/011.jpg&#39;),Path(&#39;/notebooks/storage/data/Lego-Classification/train/jurassic-world/0002/005.jpg&#39;),Path(&#39;/notebooks/storage/data/Lego-Classification/train/jurassic-world/0002/004.jpg&#39;),Path(&#39;/notebooks/storage/data/Lego-Classification/train/jurassic-world/0002/013.jpg&#39;),Path(&#39;/notebooks/storage/data/Lego-Classification/train/jurassic-world/0002/007.jpg&#39;),Path(&#39;/notebooks/storage/data/Lego-Classification/train/jurassic-world/0002/008.jpg&#39;)...] . Remember, we put the data into our directory &#39;/notebooks/storage/data/Lego-Classification&#39;. After having a quick look at our data it looks like the data is stored as follows: first the genre of our image (marvel/jurassic-world), then the classification of the figure (0001/0002 etc.). Within these folders we find many different pictures of that figure (001.jpg/002.jpg and so on). Let&#39;s confirm this by looking at the metadata. . df = pd.read_csv(f&#39;{p}/index.csv&#39;, index_col=0) df.tail(5) . path class_id train-valid . 311 marvel/0014/008.jpg | 28 | valid | . 312 marvel/0014/009.jpg | 28 | valid | . 313 marvel/0014/010.jpg | 28 | valid | . 314 marvel/0014/011.jpg | 28 | valid | . 315 marvel/0014/012.jpg | 28 | valid | . df_metadata = pd.read_csv(f&#39;{p}/metadata.csv&#39;, usecols=[&#39;class_id&#39;, &#39;lego_names&#39;, &#39;minifigure_name&#39;]) df_metadata.head() . class_id lego_names minifigure_name . 0 1 | [&#39;Spider Mech vs. Venom&#39;] | SPIDER-MAN | . 1 2 | [&#39;Spider Mech vs. Venom&#39;] | VENOM | . 2 3 | [&#39;Spider Mech vs. Venom&#39;] | AUNT MAY | . 3 4 | [&#39;Spider Mech vs. Venom&#39;] | GHOST SPIDER | . 4 5 | [&quot;Yoda&#39;s Hut&quot;] | YODA | . Indeed, that&#39;s how this dataset is structured. What we want is a data structure with which fastai&#39;s data block can easily work with. So what we need is something that gives us the filename, the label and a label which data is for training and which one is for validation. Luckily we can get exactly this by combining the meta-data: . datablock_df = pd.merge(df, df_metadata, left_on=&#39;class_id&#39;, right_on=&#39;class_id&#39;).loc[:,[&#39;path&#39;, &#39;class_id&#39;, &#39;minifigure_name&#39;, &#39;train-valid&#39;]] datablock_df[&#39;is_valid&#39;] = datablock_df[&#39;train-valid&#39;]==&#39;valid&#39; datablock_df.head() . path class_id minifigure_name train-valid is_valid . 0 marvel/0001/001.jpg | 1 | SPIDER-MAN | train | False | . 1 marvel/0001/002.jpg | 1 | SPIDER-MAN | valid | True | . 2 marvel/0001/003.jpg | 1 | SPIDER-MAN | train | False | . 3 marvel/0001/004.jpg | 1 | SPIDER-MAN | train | False | . 4 marvel/0001/005.jpg | 1 | SPIDER-MAN | train | False | . fastai gives us a brief overview of what to check before we can make optimal use of the datablock: . what are the types of our inputs and targets? Images and labels. where is the data? In a dataframe. how do we know if a sample is in the training or the validation set? A column of our dataframe. how do we get an image? By looking at the column path. how do we know the label of an image? By looking at the column minifigure_name. do we want to apply a function to a given sample? Yes, we need to resize everything to a given size. do we want to apply a function to a batch after it&#39;s created? Yes, we want data augmentation. . lego_block = DataBlock(blocks=(ImageBlock, CategoryBlock), splitter=ColSplitter(), get_x=lambda x:p/&quot;train&quot;/f&#39;{x[0]}&#39;, get_y=lambda x:x[2], item_tfms=Resize(224), batch_tfms=aug_transforms()) . Now our datablock is called lego_block. See how it perfectly matches together? . Let me briefly explain what the different steps within our lego_block are doing: first we tell the lego_block on what we want to split our data on (the default here is col=&#39;is_valid&#39;), then we simply put our path column (x[0]) and combine it with our path p and the folder &#39;train&#39; in which is is located in. get_y tells the lego_block where to find the labels in our dataset (x[2]), we then make all of our images the same size and apply transformation on them (checkout fastai for more information). . dls = lego_block.dataloaders(datablock_df) dls.show_batch() . Glorious! . fastai tries to make our life easier. This blog is intended to show you guys how to easily and quickly manage to get a great classifier with it. In the upcoming blogs I will try to better explain what is going on behind the scenes. But for now, let&#39;s enjoy how fast we can build our classifier with fastai! . learn = cnn_learner(dls, resnet34, metrics=error_rate) learn.fine_tune(20) . epoch train_loss valid_loss error_rate time . 0 | 5.044340 | 7.069784 | 0.980263 | 00:04 | . epoch train_loss valid_loss error_rate time . 0 | 4.333549 | 5.407881 | 0.960526 | 00:05 | . 1 | 4.193551 | 4.404543 | 0.947368 | 00:04 | . 2 | 3.994802 | 3.605752 | 0.907895 | 00:04 | . 3 | 3.721432 | 2.941005 | 0.802632 | 00:04 | . 4 | 3.428093 | 2.336661 | 0.638158 | 00:05 | . 5 | 3.092875 | 1.841397 | 0.532895 | 00:04 | . 6 | 2.779624 | 1.470707 | 0.434211 | 00:05 | . 7 | 2.484196 | 1.200388 | 0.348684 | 00:05 | . 8 | 2.216630 | 1.011226 | 0.263158 | 00:05 | . 9 | 1.988927 | 0.901224 | 0.236842 | 00:04 | . 10 | 1.794780 | 0.819948 | 0.217105 | 00:05 | . 11 | 1.624516 | 0.756500 | 0.184211 | 00:04 | . 12 | 1.478024 | 0.716581 | 0.157895 | 00:05 | . 13 | 1.354157 | 0.688189 | 0.164474 | 00:04 | . 14 | 1.244102 | 0.673431 | 0.164474 | 00:05 | . 15 | 1.149104 | 0.662224 | 0.164474 | 00:04 | . 16 | 1.062147 | 0.652154 | 0.164474 | 00:04 | . 17 | 0.985224 | 0.654423 | 0.177632 | 00:04 | . 18 | 0.917764 | 0.653068 | 0.177632 | 00:05 | . 19 | 0.858115 | 0.652137 | 0.184211 | 00:04 | . interp = ClassificationInterpretation.from_learner(learn) interp.plot_confusion_matrix(figsize=(12,12), dpi=60) . interp.most_confused(min_val=2) . [(&#39;RON WEASLEY&#39;, &#39;HARRY POTTER&#39;, 2), (&#39;SPIDER-MAN&#39;, &#39;FIREFIGHTER&#39;, 2)] . Not to bad I would say. However, seeing an image of Ronald Weasley and predicting it to be Harry Potter - I&#39;m not sure how much this will impress your significant other. On the other hand, Captain America is correctly predicted 100%. . But we can still try to improve our model by unfreezing the weights, to make the model even better. Let&#39;s check this out: . learn.fit_one_cycle(3, 3e-3) . epoch train_loss valid_loss error_rate time . 0 | 0.061034 | 0.536347 | 0.151316 | 00:05 | . 1 | 0.046480 | 0.631286 | 0.157895 | 00:04 | . 2 | 0.039729 | 0.572698 | 0.157895 | 00:05 | . Then we will unfreeze the parameters and learn at a slightly lower learning rate: . learn.unfreeze() . learn.fit_one_cycle(2, lr_max=1e-5) . epoch train_loss valid_loss error_rate time . 0 | 0.014817 | 0.483588 | 0.125000 | 00:05 | . 1 | 0.016834 | 0.425858 | 0.098684 | 00:04 | . Wow! Down to only 10% error rate. I think that&#39;s quite impressive! Let&#39;s see the confusion matrix: . interp = ClassificationInterpretation.from_learner(learn) interp.plot_confusion_matrix(figsize=(12,12), dpi=60) . With these results I am sure you will impress your significant other! . In one of the next posts I will show you how to use Jupyter to easily set up a small Web App with the help of Binder. So stay tuned! . Lasse .",
            "url": "https://lschmiddey.github.io/fastpages_/2020/09/16/Lego-Classification.html",
            "relUrl": "/2020/09/16/Lego-Classification.html",
            "date": " • Sep 16, 2020"
        }
        
    
  
    
        ,"post23": {
            "title": "How to get the kaggle API started",
            "content": "Easy way to download datasets from kaggle from your terminal . In this blog post I would like to show you how to use kaggles api. And not only that, I will show you how to directly use this API from Jupyter. It&#39;s straightforward and shouldn&#39;t take longer than 5 minutes. Let&#39;s get started! . First of all, log in into your kaggle account and go to &quot;Your Account&quot;. Scroll down until you find the section API. Click on &quot;Create New API Token&quot;. . . Next, upload your downloaded token into a directory to which you have access to. In this blogpost, I use my Cloud Working Space on Paperspace (how to easily set up your own working space in Paperspace click here. . . Note however, that kaggle expects your token to be at a specific folder: ~/.kaggle/kaggle.json on Linux, OSX, and other UNIX-based operating systems, and at C: Users&lt;Windows-username.kaggle kaggle.json on Windows. So that&#39;s what we will do next. Just open your Terminal and move your token to the expected folder. . . And that&#39;s it, you can now use the kaggle API! If you (like me) use a remote computing instance, we don&#39;t want other user to possible use our token. We can prevent this by typing: . . Let&#39;s see how the kaggle API works. First of all, we need to pip install the package. . . If you are looking for a specific dataset, you can now use the kaggle API and simply type: . . If you want to download data from this API, you write: . . In that way you can easily access kaggle datasets and make that work even on cloud computing instances. . Stay tuned for the next blogpost! . Lasse .",
            "url": "https://lschmiddey.github.io/fastpages_/2020/09/15/get-kaggle-api-started.html",
            "relUrl": "/2020/09/15/get-kaggle-api-started.html",
            "date": " • Sep 15, 2020"
        }
        
    
  
    
        ,"post24": {
            "title": "Setup Paperspace",
            "content": "Kostenlose (und bessere?) Alternative zu Google Colab . Die meisten Machine Learning bzw. Deep Learning Projekte will man nicht auf seinem eigenem PC/Laptop rechnen lassen. Dies hat viele gute Gründe. Zum einen hat nicht jeder Laptop eine geeignete Grafikkarte (GPU), auf der sich DeepLearning Modelle berechnen lassen. Außerdem ist das administrieren der verschiedenen Treiber und das Setup der GPU für Jupyter Notebooks nichts, was super einfach ist. Im Gegenteil. Zudem kostet eine gute Grafikkarte viel Geld. Alles Gründe, weswegen man sich lieber nach kostengünstigen Alternativen umsehen sollte, die einem den administrativen Aufwand abnehmen. . Eine solche Alternative ist Paperspace. Paperspace Gradient stellt ähnlich zu Google Colab eine kostenlose Alternative, wie sich in der Cloud Rechner mit GPUs benutzen lassen. Außerdem hat Paperspace Gradient den Vorteil, dass sich auch Daten wie Datensätze, Bilder, Modelle kostenlos speichern lassen, und nicht nach beenden der Instanz gelöscht werden (wie zum Beispiel in Google Colab). . In diesem Blog will ich zeigen, wie sich über Paperspace eine kostenlose Instanz anlegen lässt, die auch mit GPUs läuft, und wie sich die erstellten Notebooks einfach mit einem bestehenden github Repo verbinden lassen. . Zunächst muss man sich auf der Paperspace-Seite registrieren. Nach der einmaligen Registrierung öffnet sich Folgendes: . . Hier muss zunächst der Container gewählt werden. Das bedeutet nichts anderes, als dass man ein für ein bestimmtes Projekt benötigtes Grund-Setup schon für einen vorinstalliert bekommt - wie wunderbar! Man muss sich über keine Abhängigkeiten kümmern, ist sich sicher, dass die Packages auf dem aktuellsten Stand sind und falls benötigt kann man später immer noch selbst Packages hinzufügen. Was für ein Luxus! Wenn man z.B. ein Projekt mit PyTorch bauen will, so klickt man einfach auf den PyTorch Container. . . Als nächstes wählt man die Maschine, auf der das Projekt laufen soll. Das Beste hierbei: es gibt Maschinen, die von Paperspace komplett umsonst zur Verfügung gestellt werden, sogar mit GPU! Diese sind die letzten 3 Auswahlmöglichkeiten. Und wenn man mehr Power braucht, so kann man auch im Nachhinein noch aufrüsten. . Des weiteren kann man ganz einfach ein bestehendes eigenes git-Repo mit der Instanz verbinden. Dafür einfach den git-Link zum Repo einfügen. . . Zuletzt muss noch eine gültige Kreditkarte hinterlegt werden (wie schon beschrieben, die Kreditkarte wird nur belastet, wenn eine der nicht kotenlosen Alternativen gewählt wird). Danach kann auf &quot;Create new Instance&quot; geklickt werden und schon geht es los! . . Jetzt kann auf &quot;Open&quot; geklickt werden und schon startet sich ein Jupyter Notebook. Das Ganze sollte dann in etwa so aussehen (das README.md stammt schon aus dem verlinkten github-Repo): . . Wie erwähnt ist mein github Repo schon mit der Instanz verbunden. So sieht bislang mein neu angelegtes Repo in github aus: . . Dann lasst uns ein neues Jupyter Notebook anlegen. Einfach auf &quot;New&quot; -&gt; &quot;Python 3&quot; klicken, und es öffnet sich ein Notebook: . . Als nächstes will ich zeigen, wie sich mit Hilfe des Terminals ganz einfach neue packages installieren lassen (über pip), und wie sich das bestehende github Repo aus dem Terminal ansteuern lässt. Dafür muss man bei Jupyter einfach auf &quot;New&quot; und dann -&gt; &quot;Terminal&quot; klicken. . . Mit dem Befehl installieren wir aus fastai das fastbook. Dies funktioniert über pip install. . Jetzt will ich zeigen, wie sich das Terminal ganz einfach mit git verbinden lässt. Über git clone können wir öffentliche git-Repos direkt auf unsere Instanz klonen/kopieren: . . Dies finden wir auch direkt in Jupyter wieder: . . Jetzt wollen wir das Ganze in unser mit der Instanz verbundenem github Repo laden. Dies funktioniert über git add, git commit und git push im Terminal. . . Anschließend muss noch der User Name zum Repo angegeben werden und das dazugehörige Passwort. Das war&#39;s schon. Wie großartig ist das? So sieht das geupdatete github Repo aus: . . Als weitere großartige Möglichkeit bietet Paperspace in den extra dedizierten Ordnern &quot;datasets&quot; und &quot;storage&quot; an, eigene Dateien umsonst in Paperspace zu speichern. Das bedeutet, dass sich bei Neustarten der Instanzen oder neu anlegen der Instanzen diese Dateien immer da sind! Diese Funktionalität bietet Google Colab zum Beispiel nicht an. . Ich hoffe dieser Blog war hilfreich und ihr seid wenigstens halb so begeistert wie ich es bin. . Bleibt dran für die nächsten Posts! . Euer Lasse .",
            "url": "https://lschmiddey.github.io/fastpages_/2020/09/12/Setup-Paperspace.html",
            "relUrl": "/2020/09/12/Setup-Paperspace.html",
            "date": " • Sep 12, 2020"
        }
        
    
  
    
        ,"post25": {
            "title": "Was ist Gradient Descent und wie funktioniert es?",
            "content": "Eine Coding Anleitung . (dieser Beitrag basiert lose auf dem von fastai zur Verfügung gestellten fastbook) . Dieser Blog Post ist nicht dafür gedacht aufzuzeigen, wie die mathematische Berechnung hinter Gradient Descent funktioniert. Denn zum Glück gibt es genau dafür Computer, die das Ganze wahrscheinlich millionenfach schneller berechnen können als wir. Ich will eine intuitive Erklärung für Gradient Descent liefern, wofür wir Gradient Descent überhaupt brauchen und wie wir mit simplen Python Code unseren eigenen auf Gradient Descent beruhenden Algorithmus bauen können. . Ich erinnere mich, dass ich zu Schulzeiten (und mehr als Abi-Mathe wird für diesen Post wahrhaftig nicht gebraucht) die Ableitungsregeln gelernt und auf Funktionen angewandt habe, aber wirklich Sinn und Zweck habe ich in dem Ganzen nie gesehen. Im besten Fall hat sich die Lehrerin einen an den Haaren herbeigezogenen Fall ausgedacht, um nicht einfach stumpf die Funktion zu liefern, die abgeleitet werden soll. Ich hoffe nach diesem Blog wird klarer, weswegen Ableitungen bzw. die dazugehörigen Gradienten doch eine ziemlich coole und nützliche Sache sind. . Zunächst einmal möchte ich zeigen, was Gradient Descent kann: . . Ein Algorithmus, der erkennen kann, was für ein Bär auf einem gegebenem Bild zu sehen ist? Was zur Hölle hat das mit Gradient Descent zu tun? Wenn du es bis zum Ende des Posts aushältst, wirst du das hoffentlich verstehen. . Gradient Descent hilft Computern dabei zu lernen. Das Ganze sollten wir uns vielleicht in einem Schaubild einmal näher anschauen: . . Die Idee ist dabei wie folgt: Wir haben ein Modell, welches anhand von Bildern erkennen soll, welche Art von Bär hier zu sehen ist. Nachdem wir genügend Bilder von verschiedenen Bären gesammelt haben, fangen wir an unser Modell zu fragen, was es glaubt für eine Art von Bären zu sehen (predict). Wir können uns nun Metriken überlegen, an denen wir erkennen können, wie gut diese Vorhersage unseres Modells ist, zum Beispiel wie häufig das Modell die richtige Bärenart vorhergesagt hat und wie häufig es falsch lag. Wir können daraus einen sogenannten Loss berechnen, was nichts anderes ist als das, was die Lehrer uns immer als Funktion beschrieben haben. Wir haben also eine Funktion die uns angibt, wie gut/schlecht unser Modell Bärenarten vorhersagen kann. Diese Funktion kann zum Beispiel eine simple quadratische Funktion sein, sie kann aber theoretisch jede nur erdenkliche Form annehmen. . Wir wollen unseren Loss minimieren, sprich unsere Funktion soll so gut wie es nur kann die Funktion lernen, wie es möglichst gut Bärenarten voneinander unterscheiden kann. Lass uns eine Sekunde darüber nachdenken. Wir benutzen eine Loss-Funktion, damit wir unserem Modell Feedback geben, wie gut/schlecht es die bisherige Aufgabe gelöst hat. Mithilfe dieser Loss-Funktion lernt unser Modell, die verschiedenen Bärenarten besser zu unterscheiden. Doch wie &quot;lernt&quot; das Modell? Hier kommt Gradient Descent ins Spiel. . Der Gradient, also die Ableitung, gibt uns an, um wie viel die Funktion größer wird, wenn wir (optisch gesprochen) einen kleinen Schritt nach rechts bzw. einen kleinen Schritt nach links gehen von dem Punkt, an dem wir uns gerade befinden. Dies ist die Steigung von dem Punkt, an welchem wir uns gerade befinden. Doch was bringt uns das? . Ich hoffe, du hast einen Moment darüber nachgedacht. Was wir wollen, ist möglichst gut die Bärenarten voneinander zu unterscheiden. Dies steuern wir über unsere Loss-Funktion. Und je geringer unsere Loss-Funktion, desto besser sind wir im Vorhersagen, was für eine Bärenart wir hier gerade haben. Durch den Gradienten wissen wir, in welche Richtung wir uns bewegen müssen, um unsere Loss-Funktion kleiner zu machen. . Noch mag das Ganze recht abstrakt klingen, schon in Kürze folgt hier das Beispiel in Python. Ich will das Ganze aber noch einmal zusammenfassen. Wir wollen etwas optimieren, zum Beispiel möglichst genau die Bärenart vorhersagen. Um diese Funktion zu optimieren, brauchen wir die Loss-Funktion, die uns angibt, wie gut/schlecht unser Modell/unsere Zielfunktion performt. Diese Funktionen können jegliche erdenkliche Formen annehmen. Dem Gradienten ist dies jedoch egal. Der Gradient kann uns zu jedem Ort, an welchem wir uns in der Funktion befinden sagen, was mit unser Loss-Funktion passiert, wenn wir uns ein kleines Stück in eine beliebeige Richtung bewegen. Dies nutzen wir als Feedback, um die Parameter der Zielfunktion so anzupassen, dass die Loss-Funktion kleiner wird, wir also besser die Bärenarten voneinander unterscheiden können. . Dies sind die Schritte, die in dem Schaubild erklärt sind: wir initialisieren die Werte unserer Zielfunktion (anfangs zufällig, weil wir nicht wissen, wie die richtige Funktion aussieht), wir lassen unser Modell Vorhersagen treffen, berechnen daraufhin den Loss und die dazugehörigen Gradienten, um dann durch die Gradienten die Parameter des Modells anzupassen. Diesen Prozess wiederholen wir solange, bis wir mit dem Endergebnis zufrieden sind .Dies sollte auf einem sogenannten Validierungs-Set festgelegt werden, also auf Bildern von Bären, die unser Modell im Trainingsloop nicht sieht. Vielleicht wäre es hier angebracht einmal darüber nachzudenken, warum wir nicht einfach den Trainingsloop solange wiederholen, bis wir alle Bärenarten durch Gradient Descent korrekt vorhersagen können (Stichwort: Overfitting). . Genug geredet, jetzt wollen wir das Ganze auch in Code sehen! . Code Beispiel . Wir wollen mit Hilfe des oben beschriebenen Prozesses eine Funktion finden, die möglichst genau den Verlauf folgender Funktion beschrieben kann: . import torch import matplotlib.pyplot as plt . x = torch.arange(-5,20).float(); x y = 0.75*(x-4)**2 + 0.5*x + 1 plt.scatter(x,y); . Was wir wollen ist die Parameter dieser Funktion zu schätzen. Vom ansehen der Daten können wir bereits auf die funktionale Form schließen - ein Polynom 3ten Grades. Was wir an diesem Beispiel schon erkennen können ist, dass die angenommene Zielfunktion eine große Rolle spielt. Hätten wir von den Daten auf eine quadratische Funktion geschlossen, würden wir die &quot;wahre&quot; Form der Funktion nie richtig bestimmen können. Deep Learning überkommt dieses &quot;Problem&quot;, indem es jede nur erdenkliche Funktion annehmen kann (dazu mehr in einem späteren Post). . def f(x, params): a,b,c,d = params return a*(x-b)**2 + (c*x) + d . Jetzt benötigen wir noch unsere Loss-Funktion (und ich hoffe hier wird klar, wie Loss-Funktion und Zielfunktion miteinander &quot;kommunizieren&quot;): . def mse(preds, targets): return ((preds-targets)**2).mean() . params = torch.randn(4).requires_grad_() params . tensor([ 1.1514, 0.2004, -0.8726, 0.5281], requires_grad=True) . Wir starten unsere Vorhersagen: . preds = f(x, params) plt.scatter(x,preds.detach().numpy()) . &lt;matplotlib.collections.PathCollection at 0x7fd49eb1e580&gt; . Wie gut sehen unsere Vorhersagen aus? . def show_preds(preds, ax=None): if ax is None: ax=plt.subplots()[1] ax.scatter(x, y) ax.scatter(x, preds.detach().numpy(), color=&#39;red&#39;) ax.set_ylim(-10,100) ax.set_xlim(-5,20) . show_preds(preds) . Wow! Ziemlich miserabel. Wie miserabel zeigt uns unser loss. . loss = mse(preds, y) loss . tensor(8606.2266, grad_fn=&lt;MeanBackward0&gt;) . Auf geht&#39;s Gradient! Zeig uns, wie wir unsere Parameter updaten müssen, damit der Loss kleiner wird. . loss.backward() params.grad . tensor([26820.2754, -4137.0151, 1819.5073, 114.5496]) . Dann lass uns unsere Paramter anpassen (wir multiplizieren den Gradienten mit der sogenannten Learning Rate, dazu in einem weiteren Blog Posts mehr). . lr = 1e-5 params.data -= lr * params.grad.data params.grad = None params . tensor([ 0.8832, 0.2418, -0.8908, 0.5269], requires_grad=True) . Ist unser Loss geringer geworden? . preds = f(x,params) mse(preds, y) . tensor(2857.6997, grad_fn=&lt;MeanBackward0&gt;) . show_preds(preds) . Zum Glück ja. . Wir wollen die steps wiederholen, sodass wir langsam und mithilfe von Gradient Descent unsere Zielfunktion finden. . def apply_step(params, prn=True): preds = f(x, params) loss = mse(preds, y) loss.backward() params.data -= lr * params.grad.data params.grad = None if prn: print(loss.item()) return preds lr=1e-5 for i in range(20): apply_step(params) . 204.3289794921875 201.9536590576172 201.0904083251953 200.72898864746094 200.5342254638672 200.39480590820312 200.27386474609375 200.1591033935547 200.0463104248047 199.9343719482422 199.82254028320312 199.71095275878906 199.59934997558594 199.4879150390625 199.3763885498047 199.26504516601562 199.1535186767578 199.04220581054688 198.93089294433594 198.8196258544922 . _,axs = plt.subplots(1,6,figsize=(24,3)) for ax in axs: show_preds(apply_step(params, False), ax) plt.tight_layout() . Wie man sieht, passt sich die rote Kurve, also unsere Vorhersagen, immer mehr der wahren Kurve an. Alles aufgrund von Gradient Descent! Und genau diese Technik und diese Schritte, die hier in diesem Blog Post aufgezeigt wurden, sind auch die Schritte, die dabei helfen, Neuronale Netze zu trainieren. Die dann wiederum Bären auseinander halten können. . Ich hoffe, durch diesen Post ist die Idee hinter Gradient Descent ein wenig greifbarer geworden und der Sinn und Zweck von Ableitungen könnte von einer anderen Seite vielleicht ein wenig verständlicher betrachtet werden. . Bleibt dran für die nächsten Posts! . Euer Lasse .",
            "url": "https://lschmiddey.github.io/fastpages_/2020/09/01/Gradient-Descent.html",
            "relUrl": "/2020/09/01/Gradient-Descent.html",
            "date": " • Sep 1, 2020"
        }
        
    
  

  
  

  
      ,"page1": {
          "title": "About Me",
          "content": ". Ich bin Lasse, ein Data Science Enthusiast! .",
          "url": "https://lschmiddey.github.io/fastpages_/about/",
          "relUrl": "/about/",
          "date": ""
      }
      
  

  

  
  

  

  
  

  

  
  

  
  

  

  
  

  
      ,"page11": {
          "title": "",
          "content": "Sitemap: {{ “sitemap.xml” | absolute_url }} | .",
          "url": "https://lschmiddey.github.io/fastpages_/robots.txt",
          "relUrl": "/robots.txt",
          "date": ""
      }
      
  

}